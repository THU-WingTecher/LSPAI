[
    {
      "symbolName": "authenticate_redirect",
      "sourceCode": "def authenticate_redirect(\n        self,\n        callback_uri: Optional[str] = None,\n        ax_attrs: List[str] = [\"name\", \"email\", \"language\", \"username\"],\n    ) -> None:\n        \"\"\"Redirects to the authentication URL for this service.\n\n        After authentication, the service will redirect back to the given\n        callback URI with additional parameters including ``openid.mode``.\n\n        We request the given attributes for the authenticated user by\n        default (name, email, language, and username). If you don't need\n        all those attributes for your app, you can request fewer with\n        the ax_attrs keyword argument.\n\n        .. versionchanged:: 6.0\n\n            The ``callback`` argument was removed and this method no\n            longer returns an awaitable object. It is now an ordinary\n            synchronous function.\n        \"\"\"\n        handler = cast(RequestHandler, self)\n        callback_uri = callback_uri or handler.request.uri\n        assert callback_uri is not None\n        args = self._openid_args(callback_uri, ax_attrs=ax_attrs)\n        endpoint = self._OPENID_ENDPOINT  # type: ignore\n        handler.redirect(endpoint + \"?\" + urllib.parse.urlencode(args))",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 26,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "get_authenticated_user",
      "sourceCode": "async def get_authenticated_user(\n        self, http_client: Optional[httpclient.AsyncHTTPClient] = None\n    ) -> Dict[str, Any]:\n        \"\"\"Fetches the authenticated user data upon redirect.\n\n        This method should be called by the handler that receives the\n        redirect from the `authenticate_redirect()` method (which is\n        often the same as the one that calls it; in that case you would\n        call `get_authenticated_user` if the ``openid.mode`` parameter\n        is present and `authenticate_redirect` if it is not).\n\n        The result of this method will generally be used to set a cookie.\n\n        .. versionchanged:: 6.0\n\n            The ``callback`` argument was removed. Use the returned\n            awaitable object instead.\n        \"\"\"\n        handler = cast(RequestHandler, self)\n        # Verify the OpenID response via direct request to the OP\n        args = {\n            k: v[-1] for k, v in handler.request.arguments.items()\n        }  # type: Dict[str, Union[str, bytes]]\n        args[\"openid.mode\"] = \"check_authentication\"\n        url = self._OPENID_ENDPOINT  # type: ignore\n        if http_client is None:\n            http_client = self.get_auth_http_client()\n        resp = await http_client.fetch(\n            url, method=\"POST\", body=urllib.parse.urlencode(args)\n        )\n        return self._on_authentication_verified(resp)",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 30,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "_openid_args",
      "sourceCode": "def _openid_args(\n        self,\n        callback_uri: str,\n        ax_attrs: Iterable[str] = [],\n        oauth_scope: Optional[str] = None,\n    ) -> Dict[str, str]:\n        handler = cast(RequestHandler, self)\n        url = urllib.parse.urljoin(handler.request.full_url(), callback_uri)\n        args = {\n            \"openid.ns\": \"http://specs.openid.net/auth/2.0\",\n            \"openid.claimed_id\": \"http://specs.openid.net/auth/2.0/identifier_select\",\n            \"openid.identity\": \"http://specs.openid.net/auth/2.0/identifier_select\",\n            \"openid.return_to\": url,\n            \"openid.realm\": urllib.parse.urljoin(url, \"/\"),\n            \"openid.mode\": \"checkid_setup\",\n        }\n        if ax_attrs:\n            args.update(\n                {\n                    \"openid.ns.ax\": \"http://openid.net/srv/ax/1.0\",\n                    \"openid.ax.mode\": \"fetch_request\",\n                }\n            )\n            ax_attrs = set(ax_attrs)\n            required = []  # type: List[str]\n            if \"name\" in ax_attrs:\n                ax_attrs -= {\"name\", \"firstname\", \"fullname\", \"lastname\"}\n                required += [\"firstname\", \"fullname\", \"lastname\"]\n                args.update(\n                    {\n                        \"openid.ax.type.firstname\": \"http://axschema.org/namePerson/first\",\n                        \"openid.ax.type.fullname\": \"http://axschema.org/namePerson\",\n                        \"openid.ax.type.lastname\": \"http://axschema.org/namePerson/last\",\n                    }\n                )\n            known_attrs = {\n                \"email\": \"http://axschema.org/contact/email\",\n                \"language\": \"http://axschema.org/pref/language\",\n                \"username\": \"http://axschema.org/namePerson/friendly\",\n            }\n            for name in ax_attrs:\n                args[\"openid.ax.type.\" + name] = known_attrs[name]\n                required.append(name)\n            args[\"openid.ax.required\"] = \",\".join(required)\n        if oauth_scope:\n            args.update(\n                {\n                    \"openid.ns.oauth\": \"http://specs.openid.net/extensions/oauth/1.0\",\n                    \"openid.oauth.consumer\": handler.request.host.split(\":\")[0],\n                    \"openid.oauth.scope\": oauth_scope,\n                }\n            )\n        return args",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 52,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "_on_authentication_verified",
      "sourceCode": "def _on_authentication_verified(\n        self, response: httpclient.HTTPResponse\n    ) -> Dict[str, Any]:\n        handler = cast(RequestHandler, self)\n        if b\"is_valid:true\" not in response.body:\n            raise AuthError(\"Invalid OpenID response: %r\" % response.body)\n\n        # Make sure we got back at least an email from attribute exchange\n        ax_ns = None\n        for key in handler.request.arguments:\n            if (\n                key.startswith(\"openid.ns.\")\n                and handler.get_argument(key) == \"http://openid.net/srv/ax/1.0\"\n            ):\n                ax_ns = key[10:]\n                break\n\n        def get_ax_arg(uri: str) -> str:\n            if not ax_ns:\n                return \"\"\n            prefix = \"openid.\" + ax_ns + \".type.\"\n            ax_name = None\n            for name in handler.request.arguments.keys():\n                if handler.get_argument(name) == uri and name.startswith(prefix):\n                    part = name[len(prefix) :]\n                    ax_name = \"openid.\" + ax_ns + \".value.\" + part\n                    break\n            if not ax_name:\n                return \"\"\n            return handler.get_argument(ax_name, \"\")\n\n        email = get_ax_arg(\"http://axschema.org/contact/email\")\n        name = get_ax_arg(\"http://axschema.org/namePerson\")\n        first_name = get_ax_arg(\"http://axschema.org/namePerson/first\")\n        last_name = get_ax_arg(\"http://axschema.org/namePerson/last\")\n        username = get_ax_arg(\"http://axschema.org/namePerson/friendly\")\n        locale = get_ax_arg(\"http://axschema.org/pref/language\").lower()\n        user = dict()\n        name_parts = []\n        if first_name:\n            user[\"first_name\"] = first_name\n            name_parts.append(first_name)\n        if last_name:\n            user[\"last_name\"] = last_name\n            name_parts.append(last_name)\n        if name:\n            user[\"name\"] = name\n        elif name_parts:\n            user[\"name\"] = \" \".join(name_parts)\n        elif email:\n            user[\"name\"] = email.split(\"@\")[0]\n        if email:\n            user[\"email\"] = email\n        if locale:\n            user[\"locale\"] = locale\n        if username:\n            user[\"username\"] = username\n        claimed_id = handler.get_argument(\"openid.claimed_id\", None)\n        if claimed_id:\n            user[\"claimed_id\"] = claimed_id\n        return user",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 60,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "get_ax_arg",
      "sourceCode": "def get_ax_arg(uri: str) -> str:\n            if not ax_ns:\n                return \"\"\n            prefix = \"openid.\" + ax_ns + \".type.\"\n            ax_name = None\n            for name in handler.request.arguments.keys():\n                if handler.get_argument(name) == uri and name.startswith(prefix):\n                    part = name[len(prefix) :]\n                    ax_name = \"openid.\" + ax_ns + \".value.\" + part\n                    break\n            if not ax_name:\n                return \"\"\n            return handler.get_argument(ax_name, \"\")",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "authorize_redirect",
      "sourceCode": "async def authorize_redirect(\n        self,\n        callback_uri: Optional[str] = None,\n        extra_params: Optional[Dict[str, Any]] = None,\n        http_client: Optional[httpclient.AsyncHTTPClient] = None,\n    ) -> None:\n        \"\"\"Redirects the user to obtain OAuth authorization for this service.\n\n        The ``callback_uri`` may be omitted if you have previously\n        registered a callback URI with the third-party service. For\n        some services, you must use a previously-registered callback\n        URI and cannot specify a callback via this method.\n\n        This method sets a cookie called ``_oauth_request_token`` which is\n        subsequently used (and cleared) in `get_authenticated_user` for\n        security purposes.\n\n        This method is asynchronous and must be called with ``await``\n        or ``yield`` (This is different from other ``auth*_redirect``\n        methods defined in this module). It calls\n        `.RequestHandler.finish` for you so you should not write any\n        other response after it returns.\n\n        .. versionchanged:: 3.1\n           Now returns a `.Future` and takes an optional callback, for\n           compatibility with `.gen.coroutine`.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           awaitable object instead.\n\n        \"\"\"\n        if callback_uri and getattr(self, \"_OAUTH_NO_CALLBACKS\", False):\n            raise Exception(\"This service does not support oauth_callback\")\n        if http_client is None:\n            http_client = self.get_auth_http_client()\n        assert http_client is not None\n        if getattr(self, \"_OAUTH_VERSION\", \"1.0a\") == \"1.0a\":\n            response = await http_client.fetch(\n                self._oauth_request_token_url(\n                    callback_uri=callback_uri, extra_params=extra_params\n                )\n            )\n        else:\n            response = await http_client.fetch(self._oauth_request_token_url())\n        url = self._OAUTH_AUTHORIZE_URL  # type: ignore\n        self._on_request_token(url, callback_uri, response)",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 47,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "get_authenticated_user",
      "sourceCode": "async def get_authenticated_user(\n        self, http_client: Optional[httpclient.AsyncHTTPClient] = None\n    ) -> Dict[str, Any]:\n        \"\"\"Gets the OAuth authorized user and access token.\n\n        This method should be called from the handler for your\n        OAuth callback URL to complete the registration process. We run the\n        callback with the authenticated user dictionary.  This dictionary\n        will contain an ``access_key`` which can be used to make authorized\n        requests to this service on behalf of the user.  The dictionary will\n        also contain other fields such as ``name``, depending on the service\n        used.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           awaitable object instead.\n        \"\"\"\n        handler = cast(RequestHandler, self)\n        request_key = escape.utf8(handler.get_argument(\"oauth_token\"))\n        oauth_verifier = handler.get_argument(\"oauth_verifier\", None)\n        request_cookie = handler.get_cookie(\"_oauth_request_token\")\n        if not request_cookie:\n            raise AuthError(\"Missing OAuth request token cookie\")\n        handler.clear_cookie(\"_oauth_request_token\")\n        cookie_key, cookie_secret = (\n            base64.b64decode(escape.utf8(i)) for i in request_cookie.split(\"|\")\n        )\n        if cookie_key != request_key:\n            raise AuthError(\"Request token does not match cookie\")\n        token = dict(\n            key=cookie_key, secret=cookie_secret\n        )  # type: Dict[str, Union[str, bytes]]\n        if oauth_verifier:\n            token[\"verifier\"] = oauth_verifier\n        if http_client is None:\n            http_client = self.get_auth_http_client()\n        assert http_client is not None\n        response = await http_client.fetch(self._oauth_access_token_url(token))\n        access_token = _oauth_parse_response(response.body)\n        user = await self._oauth_get_user_future(access_token)\n        if not user:\n            raise AuthError(\"Error getting user\")\n        user[\"access_token\"] = access_token\n        return user",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 44,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "_oauth_request_token_url",
      "sourceCode": "def _oauth_request_token_url(\n        self,\n        callback_uri: Optional[str] = None,\n        extra_params: Optional[Dict[str, Any]] = None,\n    ) -> str:\n        handler = cast(RequestHandler, self)\n        consumer_token = self._oauth_consumer_token()\n        url = self._OAUTH_REQUEST_TOKEN_URL  # type: ignore\n        args = dict(\n            oauth_consumer_key=escape.to_basestring(consumer_token[\"key\"]),\n            oauth_signature_method=\"HMAC-SHA1\",\n            oauth_timestamp=str(int(time.time())),\n            oauth_nonce=escape.to_basestring(binascii.b2a_hex(uuid.uuid4().bytes)),\n            oauth_version=\"1.0\",\n        )\n        if getattr(self, \"_OAUTH_VERSION\", \"1.0a\") == \"1.0a\":\n            if callback_uri == \"oob\":\n                args[\"oauth_callback\"] = \"oob\"\n            elif callback_uri:\n                args[\"oauth_callback\"] = urllib.parse.urljoin(\n                    handler.request.full_url(), callback_uri\n                )\n            if extra_params:\n                args.update(extra_params)\n            signature = _oauth10a_signature(consumer_token, \"GET\", url, args)\n        else:\n            signature = _oauth_signature(consumer_token, \"GET\", url, args)\n\n        args[\"oauth_signature\"] = signature\n        return url + \"?\" + urllib.parse.urlencode(args)",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 29,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "_on_request_token",
      "sourceCode": "def _on_request_token(\n        self,\n        authorize_url: str,\n        callback_uri: Optional[str],\n        response: httpclient.HTTPResponse,\n    ) -> None:\n        handler = cast(RequestHandler, self)\n        request_token = _oauth_parse_response(response.body)\n        data = (\n            base64.b64encode(escape.utf8(request_token[\"key\"]))\n            + b\"|\"\n            + base64.b64encode(escape.utf8(request_token[\"secret\"]))\n        )\n        handler.set_cookie(\"_oauth_request_token\", data)\n        args = dict(oauth_token=request_token[\"key\"])\n        if callback_uri == \"oob\":\n            handler.finish(authorize_url + \"?\" + urllib.parse.urlencode(args))\n            return\n        elif callback_uri:\n            args[\"oauth_callback\"] = urllib.parse.urljoin(\n                handler.request.full_url(), callback_uri\n            )\n        handler.redirect(authorize_url + \"?\" + urllib.parse.urlencode(args))",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 22,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "_oauth_access_token_url",
      "sourceCode": "def _oauth_access_token_url(self, request_token: Dict[str, Any]) -> str:\n        consumer_token = self._oauth_consumer_token()\n        url = self._OAUTH_ACCESS_TOKEN_URL  # type: ignore\n        args = dict(\n            oauth_consumer_key=escape.to_basestring(consumer_token[\"key\"]),\n            oauth_token=escape.to_basestring(request_token[\"key\"]),\n            oauth_signature_method=\"HMAC-SHA1\",\n            oauth_timestamp=str(int(time.time())),\n            oauth_nonce=escape.to_basestring(binascii.b2a_hex(uuid.uuid4().bytes)),\n            oauth_version=\"1.0\",\n        )\n        if \"verifier\" in request_token:\n            args[\"oauth_verifier\"] = request_token[\"verifier\"]\n\n        if getattr(self, \"_OAUTH_VERSION\", \"1.0a\") == \"1.0a\":\n            signature = _oauth10a_signature(\n                consumer_token, \"GET\", url, args, request_token\n            )\n        else:\n            signature = _oauth_signature(\n                consumer_token, \"GET\", url, args, request_token\n            )\n\n        args[\"oauth_signature\"] = signature\n        return url + \"?\" + urllib.parse.urlencode(args)",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 24,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "_oauth_get_user_future",
      "sourceCode": "async def _oauth_get_user_future(\n        self, access_token: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"Subclasses must override this to get basic information about the\n        user.\n\n        Should be a coroutine whose result is a dictionary\n        containing information about the user, which may have been\n        retrieved by using ``access_token`` to make a request to the\n        service.\n\n        The access token will be added to the returned dictionary to make\n        the result of `get_authenticated_user`.\n\n        .. versionchanged:: 5.1\n\n           Subclasses may also define this method with ``async def``.\n\n        .. versionchanged:: 6.0\n\n           A synchronous fallback to ``_oauth_get_user`` was removed.\n        \"\"\"\n        raise NotImplementedError()",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 22,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "_oauth_request_parameters",
      "sourceCode": "def _oauth_request_parameters(\n        self,\n        url: str,\n        access_token: Dict[str, Any],\n        parameters: Dict[str, Any] = {},\n        method: str = \"GET\",\n    ) -> Dict[str, Any]:\n        \"\"\"Returns the OAuth parameters as a dict for the given request.\n\n        parameters should include all POST arguments and query string arguments\n        that will be sent with the request.\n        \"\"\"\n        consumer_token = self._oauth_consumer_token()\n        base_args = dict(\n            oauth_consumer_key=escape.to_basestring(consumer_token[\"key\"]),\n            oauth_token=escape.to_basestring(access_token[\"key\"]),\n            oauth_signature_method=\"HMAC-SHA1\",\n            oauth_timestamp=str(int(time.time())),\n            oauth_nonce=escape.to_basestring(binascii.b2a_hex(uuid.uuid4().bytes)),\n            oauth_version=\"1.0\",\n        )\n        args = {}\n        args.update(base_args)\n        args.update(parameters)\n        if getattr(self, \"_OAUTH_VERSION\", \"1.0a\") == \"1.0a\":\n            signature = _oauth10a_signature(\n                consumer_token, method, url, args, access_token\n            )\n        else:\n            signature = _oauth_signature(\n                consumer_token, method, url, args, access_token\n            )\n        base_args[\"oauth_signature\"] = escape.to_basestring(signature)\n        return base_args",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 33,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "authorize_redirect",
      "sourceCode": "def authorize_redirect(\n        self,\n        redirect_uri: Optional[str] = None,\n        client_id: Optional[str] = None,\n        client_secret: Optional[str] = None,\n        extra_params: Optional[Dict[str, Any]] = None,\n        scope: Optional[List[str]] = None,\n        response_type: str = \"code\",\n    ) -> None:\n        \"\"\"Redirects the user to obtain OAuth authorization for this service.\n\n        Some providers require that you register a redirect URL with\n        your application instead of passing one via this method. You\n        should call this method to log the user in, and then call\n        ``get_authenticated_user`` in the handler for your\n        redirect URL to complete the authorization process.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument and returned awaitable were removed;\n           this is now an ordinary synchronous function.\n\n        .. deprecated:: 6.4\n           The ``client_secret`` argument (which has never had any effect)\n           is deprecated and will be removed in Tornado 7.0.\n        \"\"\"\n        if client_secret is not None:\n            warnings.warn(\"client_secret argument is deprecated\", DeprecationWarning)\n        handler = cast(RequestHandler, self)\n        args = {\"response_type\": response_type}\n        if redirect_uri is not None:\n            args[\"redirect_uri\"] = redirect_uri\n        if client_id is not None:\n            args[\"client_id\"] = client_id\n        if extra_params:\n            args.update(extra_params)\n        if scope:\n            args[\"scope\"] = \" \".join(scope)\n        url = self._OAUTH_AUTHORIZE_URL  # type: ignore\n        handler.redirect(url_concat(url, args))",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 39,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "_oauth_request_token_url",
      "sourceCode": "def _oauth_request_token_url(\n        self,\n        redirect_uri: Optional[str] = None,\n        client_id: Optional[str] = None,\n        client_secret: Optional[str] = None,\n        code: Optional[str] = None,\n        extra_params: Optional[Dict[str, Any]] = None,\n    ) -> str:\n        url = self._OAUTH_ACCESS_TOKEN_URL  # type: ignore\n        args = {}  # type: Dict[str, str]\n        if redirect_uri is not None:\n            args[\"redirect_uri\"] = redirect_uri\n        if code is not None:\n            args[\"code\"] = code\n        if client_id is not None:\n            args[\"client_id\"] = client_id\n        if client_secret is not None:\n            args[\"client_secret\"] = client_secret\n        if extra_params:\n            args.update(extra_params)\n        return url_concat(url, args)",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "oauth2_request",
      "sourceCode": "async def oauth2_request(\n        self,\n        url: str,\n        access_token: Optional[str] = None,\n        post_args: Optional[Dict[str, Any]] = None,\n        **args: Any,\n    ) -> Any:\n        \"\"\"Fetches the given URL auth an OAuth2 access token.\n\n        If the request is a POST, ``post_args`` should be provided. Query\n        string arguments should be given as keyword arguments.\n\n        Example usage:\n\n        ..testcode::\n\n            class MainHandler(tornado.web.RequestHandler,\n                              tornado.auth.FacebookGraphMixin):\n                @tornado.web.authenticated\n                async def get(self):\n                    new_entry = await self.oauth2_request(\n                        \"https://graph.facebook.com/me/feed\",\n                        post_args={\"message\": \"I am posting from my Tornado application!\"},\n                        access_token=self.current_user[\"access_token\"])\n\n                    if not new_entry:\n                        # Call failed; perhaps missing permission?\n                        self.authorize_redirect()\n                        return\n                    self.finish(\"Posted a message!\")\n\n        .. versionadded:: 4.3\n\n        .. versionchanged::: 6.0\n\n           The ``callback`` argument was removed. Use the returned awaitable object instead.\n        \"\"\"\n        all_args = {}\n        if access_token:\n            all_args[\"access_token\"] = access_token\n            all_args.update(args)\n\n        if all_args:\n            url += \"?\" + urllib.parse.urlencode(all_args)\n        http = self.get_auth_http_client()\n        if post_args is not None:\n            response = await http.fetch(\n                url, method=\"POST\", body=urllib.parse.urlencode(post_args)\n            )\n        else:\n            response = await http.fetch(url)\n        return escape.json_decode(response.body)",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 51,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "authenticate_redirect",
      "sourceCode": "async def authenticate_redirect(self, callback_uri: Optional[str] = None) -> None:\n        \"\"\"Just like `~OAuthMixin.authorize_redirect`, but\n        auto-redirects if authorized.\n\n        This is generally the right interface to use if you are using\n        Twitter for single-sign on.\n\n        .. versionchanged:: 3.1\n           Now returns a `.Future` and takes an optional callback, for\n           compatibility with `.gen.coroutine`.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           awaitable object instead.\n        \"\"\"\n        http = self.get_auth_http_client()\n        response = await http.fetch(\n            self._oauth_request_token_url(callback_uri=callback_uri)\n        )\n        self._on_request_token(self._OAUTH_AUTHENTICATE_URL, None, response)",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "twitter_request",
      "sourceCode": "async def twitter_request(\n        self,\n        path: str,\n        access_token: Dict[str, Any],\n        post_args: Optional[Dict[str, Any]] = None,\n        **args: Any,\n    ) -> Any:\n        \"\"\"Fetches the given API path, e.g., ``statuses/user_timeline/btaylor``\n\n        The path should not include the format or API version number.\n        (we automatically use JSON format and API version 1).\n\n        If the request is a POST, ``post_args`` should be provided. Query\n        string arguments should be given as keyword arguments.\n\n        All the Twitter methods are documented at http://dev.twitter.com/\n\n        Many methods require an OAuth access token which you can\n        obtain through `~OAuthMixin.authorize_redirect` and\n        `~OAuthMixin.get_authenticated_user`. The user returned through that\n        process includes an 'access_token' attribute that can be used\n        to make authenticated requests via this method. Example\n        usage:\n\n        .. testcode::\n\n            class MainHandler(tornado.web.RequestHandler,\n                              tornado.auth.TwitterMixin):\n                @tornado.web.authenticated\n                async def get(self):\n                    new_entry = await self.twitter_request(\n                        \"/statuses/update\",\n                        post_args={\"status\": \"Testing Tornado Web Server\"},\n                        access_token=self.current_user[\"access_token\"])\n                    if not new_entry:\n                        # Call failed; perhaps missing permission?\n                        await self.authorize_redirect()\n                        return\n                    self.finish(\"Posted a message!\")\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           awaitable object instead.\n        \"\"\"\n        if path.startswith(\"http:\") or path.startswith(\"https:\"):\n            # Raw urls are useful for e.g. search which doesn't follow the\n            # usual pattern: http://search.twitter.com/search.json\n            url = path\n        else:\n            url = self._TWITTER_BASE_URL + path + \".json\"\n        # Add the OAuth resource request signature if we have credentials\n        if access_token:\n            all_args = {}\n            all_args.update(args)\n            all_args.update(post_args or {})\n            method = \"POST\" if post_args is not None else \"GET\"\n            oauth = self._oauth_request_parameters(\n                url, access_token, all_args, method=method\n            )\n            args.update(oauth)\n        if args:\n            url += \"?\" + urllib.parse.urlencode(args)\n        http = self.get_auth_http_client()\n        if post_args is not None:\n            response = await http.fetch(\n                url, method=\"POST\", body=urllib.parse.urlencode(post_args)\n            )\n        else:\n            response = await http.fetch(url)\n        return escape.json_decode(response.body)",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 70,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "get_google_oauth_settings",
      "sourceCode": "def get_google_oauth_settings(self) -> Dict[str, str]:\n        \"\"\"Return the Google OAuth 2.0 credentials that you created with\n        [Google Cloud\n        Platform](https://console.cloud.google.com/apis/credentials). The dict\n        format is::\n\n            {\n                \"key\": \"your_client_id\", \"secret\": \"your_client_secret\"\n            }\n\n        If your credentials are stored differently (e.g. in a db) you can\n        override this method for custom provision.\n        \"\"\"\n        handler = cast(RequestHandler, self)\n        return handler.settings[self._OAUTH_SETTINGS_KEY]",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "get_authenticated_user",
      "sourceCode": "async def get_authenticated_user(\n        self,\n        redirect_uri: str,\n        code: str,\n        client_id: Optional[str] = None,\n        client_secret: Optional[str] = None,\n    ) -> Dict[str, Any]:\n        \"\"\"Handles the login for the Google user, returning an access token.\n\n        The result is a dictionary containing an ``access_token`` field\n        ([among others](https://developers.google.com/identity/protocols/OAuth2WebServer#handlingtheresponse)).\n        Unlike other ``get_authenticated_user`` methods in this package,\n        this method does not return any additional information about the user.\n        The returned access token can be used with `OAuth2Mixin.oauth2_request`\n        to request additional information (perhaps from\n        ``https://www.googleapis.com/oauth2/v2/userinfo``)\n\n        Example usage:\n\n        .. testsetup::\n\n            import urllib\n\n        .. testcode::\n\n            class GoogleOAuth2LoginHandler(tornado.web.RequestHandler,\n                                           tornado.auth.GoogleOAuth2Mixin):\n                async def get(self):\n                    # Google requires an exact match for redirect_uri, so it's\n                    # best to get it from your app configuration instead of from\n                    # self.request.full_uri().\n                    redirect_uri = urllib.parse.urljoin(self.application.settings['redirect_base_uri'],\n                        self.reverse_url('google_oauth'))\n                    async def get(self):\n                        if self.get_argument('code', False):\n                            access = await self.get_authenticated_user(\n                                redirect_uri=redirect_uri,\n                                code=self.get_argument('code'))\n                            user = await self.oauth2_request(\n                                \"https://www.googleapis.com/oauth2/v1/userinfo\",\n                                access_token=access[\"access_token\"])\n                            # Save the user and access token. For example:\n                            user_cookie = dict(id=user[\"id\"], access_token=access[\"access_token\"])\n                            self.set_signed_cookie(\"user\", json.dumps(user_cookie))\n                            self.redirect(\"/\")\n                        else:\n                            self.authorize_redirect(\n                                redirect_uri=redirect_uri,\n                                client_id=self.get_google_oauth_settings()['key'],\n                                scope=['profile', 'email'],\n                                response_type='code',\n                                extra_params={'approval_prompt': 'auto'})\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned awaitable object instead.\n        \"\"\"  # noqa: E501\n\n        if client_id is None or client_secret is None:\n            settings = self.get_google_oauth_settings()\n            if client_id is None:\n                client_id = settings[\"key\"]\n            if client_secret is None:\n                client_secret = settings[\"secret\"]\n        http = self.get_auth_http_client()\n        body = urllib.parse.urlencode(\n            {\n                \"redirect_uri\": redirect_uri,\n                \"code\": code,\n                \"client_id\": client_id,\n                \"client_secret\": client_secret,\n                \"grant_type\": \"authorization_code\",\n            }\n        )\n\n        response = await http.fetch(\n            self._OAUTH_ACCESS_TOKEN_URL,\n            method=\"POST\",\n            headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n            body=body,\n        )\n        return escape.json_decode(response.body)",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 81,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "get_authenticated_user",
      "sourceCode": "async def get_authenticated_user(\n        self,\n        redirect_uri: str,\n        client_id: str,\n        client_secret: str,\n        code: str,\n        extra_fields: Optional[Dict[str, Any]] = None,\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"Handles the login for the Facebook user, returning a user object.\n\n        Example usage:\n\n        .. testcode::\n\n            class FacebookGraphLoginHandler(tornado.web.RequestHandler,\n                                            tornado.auth.FacebookGraphMixin):\n              async def get(self):\n                redirect_uri = urllib.parse.urljoin(\n                    self.application.settings['redirect_base_uri'],\n                    self.reverse_url('facebook_oauth'))\n                if self.get_argument(\"code\", False):\n                    user = await self.get_authenticated_user(\n                        redirect_uri=redirect_uri,\n                        client_id=self.settings[\"facebook_api_key\"],\n                        client_secret=self.settings[\"facebook_secret\"],\n                        code=self.get_argument(\"code\"))\n                    # Save the user with e.g. set_signed_cookie\n                else:\n                    self.authorize_redirect(\n                        redirect_uri=redirect_uri,\n                        client_id=self.settings[\"facebook_api_key\"],\n                        extra_params={\"scope\": \"user_posts\"})\n\n        This method returns a dictionary which may contain the following fields:\n\n        * ``access_token``, a string which may be passed to `facebook_request`\n        * ``session_expires``, an integer encoded as a string representing\n          the time until the access token expires in seconds. This field should\n          be used like ``int(user['session_expires'])``; in a future version of\n          Tornado it will change from a string to an integer.\n        * ``id``, ``name``, ``first_name``, ``last_name``, ``locale``, ``picture``,\n          ``link``, plus any fields named in the ``extra_fields`` argument. These\n          fields are copied from the Facebook graph API\n          `user object <https://developers.facebook.com/docs/graph-api/reference/user>`_\n\n        .. versionchanged:: 4.5\n           The ``session_expires`` field was updated to support changes made to the\n           Facebook API in March 2017.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned awaitable object instead.\n        \"\"\"\n        http = self.get_auth_http_client()\n        args = {\n            \"redirect_uri\": redirect_uri,\n            \"code\": code,\n            \"client_id\": client_id,\n            \"client_secret\": client_secret,\n        }\n\n        fields = {\"id\", \"name\", \"first_name\", \"last_name\", \"locale\", \"picture\", \"link\"}\n        if extra_fields:\n            fields.update(extra_fields)\n\n        response = await http.fetch(\n            self._oauth_request_token_url(**args)  # type: ignore\n        )\n        args = escape.json_decode(response.body)\n        session = {\n            \"access_token\": args.get(\"access_token\"),\n            \"expires_in\": args.get(\"expires_in\"),\n        }\n        assert session[\"access_token\"] is not None\n\n        user = await self.facebook_request(\n            path=\"/me\",\n            access_token=session[\"access_token\"],\n            appsecret_proof=hmac.new(\n                key=client_secret.encode(\"utf8\"),\n                msg=session[\"access_token\"].encode(\"utf8\"),\n                digestmod=hashlib.sha256,\n            ).hexdigest(),\n            fields=\",\".join(fields),\n        )\n\n        if user is None:\n            return None\n\n        fieldmap = {}\n        for field in fields:\n            fieldmap[field] = user.get(field)\n\n        # session_expires is converted to str for compatibility with\n        # older versions in which the server used url-encoding and\n        # this code simply returned the string verbatim.\n        # This should change in Tornado 5.0.\n        fieldmap.update(\n            {\n                \"access_token\": session[\"access_token\"],\n                \"session_expires\": str(session.get(\"expires_in\")),\n            }\n        )\n        return fieldmap",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 103,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "facebook_request",
      "sourceCode": "async def facebook_request(\n        self,\n        path: str,\n        access_token: Optional[str] = None,\n        post_args: Optional[Dict[str, Any]] = None,\n        **args: Any,\n    ) -> Any:\n        \"\"\"Fetches the given relative API path, e.g., \"/btaylor/picture\"\n\n        If the request is a POST, ``post_args`` should be provided. Query\n        string arguments should be given as keyword arguments.\n\n        An introduction to the Facebook Graph API can be found at\n        http://developers.facebook.com/docs/api\n\n        Many methods require an OAuth access token which you can\n        obtain through `~OAuth2Mixin.authorize_redirect` and\n        `get_authenticated_user`. The user returned through that\n        process includes an ``access_token`` attribute that can be\n        used to make authenticated requests via this method.\n\n        Example usage:\n\n        .. testcode::\n\n            class MainHandler(tornado.web.RequestHandler,\n                              tornado.auth.FacebookGraphMixin):\n                @tornado.web.authenticated\n                async def get(self):\n                    new_entry = await self.facebook_request(\n                        \"/me/feed\",\n                        post_args={\"message\": \"I am posting from my Tornado application!\"},\n                        access_token=self.current_user[\"access_token\"])\n\n                    if not new_entry:\n                        # Call failed; perhaps missing permission?\n                        self.authorize_redirect()\n                        return\n                    self.finish(\"Posted a message!\")\n\n        The given path is relative to ``self._FACEBOOK_BASE_URL``,\n        by default \"https://graph.facebook.com\".\n\n        This method is a wrapper around `OAuth2Mixin.oauth2_request`;\n        the only difference is that this method takes a relative path,\n        while ``oauth2_request`` takes a complete url.\n\n        .. versionchanged:: 3.1\n           Added the ability to override ``self._FACEBOOK_BASE_URL``.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned awaitable object instead.\n        \"\"\"\n        url = self._FACEBOOK_BASE_URL + path\n        return await self.oauth2_request(\n            url, access_token=access_token, post_args=post_args, **args\n        )",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 57,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "_oauth_signature",
      "sourceCode": "def _oauth_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:\n    \"\"\"Calculates the HMAC-SHA1 OAuth signature for the given request.\n\n    See http://oauth.net/core/1.0/#signing_process\n    \"\"\"\n    parts = urllib.parse.urlparse(url)\n    scheme, netloc, path = parts[:3]\n    normalized_url = scheme.lower() + \"://\" + netloc.lower() + path\n\n    base_elems = []\n    base_elems.append(method.upper())\n    base_elems.append(normalized_url)\n    base_elems.append(\n        \"&\".join(f\"{k}={_oauth_escape(str(v))}\" for k, v in sorted(parameters.items()))\n    )\n    base_string = \"&\".join(_oauth_escape(e) for e in base_elems)\n\n    key_elems = [escape.utf8(consumer_token[\"secret\"])]\n    key_elems.append(escape.utf8(token[\"secret\"] if token else \"\"))\n    key = b\"&\".join(key_elems)\n\n    hash = hmac.new(key, escape.utf8(base_string), hashlib.sha1)\n    return binascii.b2a_base64(hash.digest())[:-1]",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 28,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "_oauth10a_signature",
      "sourceCode": "def _oauth10a_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:\n    \"\"\"Calculates the HMAC-SHA1 OAuth 1.0a signature for the given request.\n\n    See http://oauth.net/core/1.0a/#signing_process\n    \"\"\"\n    parts = urllib.parse.urlparse(url)\n    scheme, netloc, path = parts[:3]\n    normalized_url = scheme.lower() + \"://\" + netloc.lower() + path\n\n    base_elems = []\n    base_elems.append(method.upper())\n    base_elems.append(normalized_url)\n    base_elems.append(\n        \"&\".join(f\"{k}={_oauth_escape(str(v))}\" for k, v in sorted(parameters.items()))\n    )\n\n    base_string = \"&\".join(_oauth_escape(e) for e in base_elems)\n    key_elems = [escape.utf8(urllib.parse.quote(consumer_token[\"secret\"], safe=\"~\"))]\n    key_elems.append(\n        escape.utf8(urllib.parse.quote(token[\"secret\"], safe=\"~\") if token else \"\")\n    )\n    key = b\"&\".join(key_elems)\n\n    hash = hmac.new(key, escape.utf8(base_string), hashlib.sha1)\n    return binascii.b2a_base64(hash.digest())[:-1]",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 30,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "_oauth_parse_response",
      "sourceCode": "def _oauth_parse_response(body: bytes) -> Dict[str, Any]:\n    # I can't find an officially-defined encoding for oauth responses and\n    # have never seen anyone use non-ascii.  Leave the response in a byte\n    # string for python 2, and use utf8 on python 3.\n    body_str = escape.native_str(body)\n    p = urllib.parse.parse_qs(body_str, keep_blank_values=False)\n    token = dict(key=p[\"oauth_token\"][0], secret=p[\"oauth_token_secret\"][0])\n\n    # Add the extra parameters the Provider included to the token\n    special = (\"oauth_token\", \"oauth_token_secret\")\n    token.update((k, p[k][0]) for k in p if k not in special)\n    return token",
      "importString": "import base64\nimport binascii\nimport hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\nimport warnings\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/auth.py"
    },
    {
      "symbolName": "start",
      "sourceCode": "def start(check_time: int = 500) -> None:\n    \"\"\"Begins watching source files for changes.\n\n    .. versionchanged:: 5.0\n       The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n    \"\"\"\n    io_loop = ioloop.IOLoop.current()\n    if io_loop in _io_loops:\n        return\n    _io_loops[io_loop] = True\n    if len(_io_loops) > 1:\n        gen_log.warning(\"tornado.autoreload started more than once in the same process\")\n    modify_times: Dict[str, float] = {}\n    callback = functools.partial(_reload_on_update, modify_times)\n    scheduler = ioloop.PeriodicCallback(callback, check_time)\n    scheduler.start()",
      "importString": "import os\nimport sys\nimport functools\nimport importlib.abc\nimport os\nimport pkgutil\nimport sys\nimport traceback\nimport types\nimport subprocess\nimport weakref\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado import process\nfrom typing import Callable, Dict, Optional, List, Union",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/autoreload.py"
    },
    {
      "symbolName": "_reload_on_update",
      "sourceCode": "def _reload_on_update(modify_times: Dict[str, float]) -> None:\n    if _reload_attempted:\n        # We already tried to reload and it didn't work, so don't try again.\n        return\n    if process.task_id() is not None:\n        # We're in a child process created by fork_processes.  If child\n        # processes restarted themselves, they'd all restart and then\n        # all call fork_processes again.\n        return\n    for module in list(sys.modules.values()):\n        # Some modules play games with sys.modules (e.g. email/__init__.py\n        # in the standard library), and occasionally this can cause strange\n        # failures in getattr.  Just ignore anything that's not an ordinary\n        # module.\n        if not isinstance(module, types.ModuleType):\n            continue\n        path = getattr(module, \"__file__\", None)\n        if not path:\n            continue\n        if path.endswith(\".pyc\") or path.endswith(\".pyo\"):\n            path = path[:-1]\n        _check_file(modify_times, path)\n    for path in _watched_files:\n        _check_file(modify_times, path)",
      "importString": "import os\nimport sys\nimport functools\nimport importlib.abc\nimport os\nimport pkgutil\nimport sys\nimport traceback\nimport types\nimport subprocess\nimport weakref\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado import process\nfrom typing import Callable, Dict, Optional, List, Union",
      "lineNum": 23,
      "relativeDocumentPath": "tornado/autoreload.py"
    },
    {
      "symbolName": "_check_file",
      "sourceCode": "def _check_file(modify_times: Dict[str, float], path: str) -> None:\n    try:\n        modified = os.stat(path).st_mtime\n    except Exception:\n        return\n    if path not in modify_times:\n        modify_times[path] = modified\n        return\n    if modify_times[path] != modified:\n        gen_log.info(\"%s modified; restarting server\", path)\n        _reload()",
      "importString": "import os\nimport sys\nimport functools\nimport importlib.abc\nimport os\nimport pkgutil\nimport sys\nimport traceback\nimport types\nimport subprocess\nimport weakref\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado import process\nfrom typing import Callable, Dict, Optional, List, Union",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/autoreload.py"
    },
    {
      "symbolName": "_reload",
      "sourceCode": "def _reload() -> None:\n    global _reload_attempted\n    _reload_attempted = True\n    for fn in _reload_hooks:\n        fn()\n    if sys.platform != \"win32\":\n        # Clear the alarm signal set by\n        # ioloop.set_blocking_log_threshold so it doesn't fire\n        # after the exec.\n        signal.setitimer(signal.ITIMER_REAL, 0, 0)\n    # sys.path fixes: see comments at top of file.  If __main__.__spec__\n    # exists, we were invoked with -m and the effective path is about to\n    # change on re-exec.  Reconstruct the original command line to\n    # ensure that the new process sees the same path we did.\n    if _autoreload_is_main:\n        assert _original_argv is not None\n        spec = _original_spec\n        argv = _original_argv\n    else:\n        spec = getattr(sys.modules[\"__main__\"], \"__spec__\", None)\n        argv = sys.argv\n    if spec and spec.name != \"__main__\":\n        # __spec__ is set in two cases: when running a module, and when running a directory. (when\n        # running a file, there is no spec). In the former case, we must pass -m to maintain the\n        # module-style behavior (setting sys.path), even though python stripped -m from its argv at\n        # startup. If sys.path is exactly __main__, we're running a directory and should fall\n        # through to the non-module behavior.\n        #\n        # Some of this, including the use of exactly __main__ as a spec for directory mode,\n        # is documented at https://docs.python.org/3/library/runpy.html#runpy.run_path\n        argv = [\"-m\", spec.name] + argv[1:]\n\n    if not _has_execv:\n        subprocess.Popen([sys.executable] + argv)\n        os._exit(0)\n    else:\n        os.execv(sys.executable, [sys.executable] + argv)",
      "importString": "import os\nimport sys\nimport functools\nimport importlib.abc\nimport os\nimport pkgutil\nimport sys\nimport traceback\nimport types\nimport subprocess\nimport weakref\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado import process\nfrom typing import Callable, Dict, Optional, List, Union",
      "lineNum": 36,
      "relativeDocumentPath": "tornado/autoreload.py"
    },
    {
      "symbolName": "main",
      "sourceCode": "def main() -> None:\n    \"\"\"Command-line wrapper to re-run a script whenever its source changes.\n\n    Scripts may be specified by filename or module name::\n\n        python -m tornado.autoreload -m tornado.test.runtests\n        python -m tornado.autoreload tornado/test/runtests.py\n\n    Running a script with this wrapper is similar to calling\n    `tornado.autoreload.wait` at the end of the script, but this wrapper\n    can catch import-time problems like syntax errors that would otherwise\n    prevent the script from reaching its call to `wait`.\n    \"\"\"\n    # Remember that we were launched with autoreload as main.\n    # The main module can be tricky; set the variables both in our globals\n    # (which may be __main__) and the real importable version.\n    #\n    # We use optparse instead of the newer argparse because we want to\n    # mimic the python command-line interface which requires stopping\n    # parsing at the first positional argument. optparse supports\n    # this but as far as I can tell argparse does not.\n    import optparse\n    import tornado.autoreload\n\n    global _autoreload_is_main\n    global _original_argv, _original_spec\n    tornado.autoreload._autoreload_is_main = _autoreload_is_main = True\n    original_argv = sys.argv\n    tornado.autoreload._original_argv = _original_argv = original_argv\n    original_spec = getattr(sys.modules[\"__main__\"], \"__spec__\", None)\n    tornado.autoreload._original_spec = _original_spec = original_spec\n\n    parser = optparse.OptionParser(\n        prog=\"python -m tornado.autoreload\",\n        usage=_USAGE,\n        epilog=\"Either -m or a path must be specified, but not both\",\n    )\n    parser.disable_interspersed_args()\n    parser.add_option(\"-m\", dest=\"module\", metavar=\"module\", help=\"module to run\")\n    parser.add_option(\n        \"--until-success\",\n        action=\"store_true\",\n        help=\"stop reloading after the program exist successfully (status code 0)\",\n    )\n    opts, rest = parser.parse_args()\n    if opts.module is None:\n        if not rest:\n            print(\"Either -m or a path must be specified\", file=sys.stderr)\n            sys.exit(1)\n        path = rest[0]\n        sys.argv = rest[:]\n    else:\n        path = None\n        sys.argv = [sys.argv[0]] + rest\n\n    # SystemExit.code is typed funny: https://github.com/python/typeshed/issues/8513\n    # All we care about is truthiness\n    exit_status: Union[int, str, None] = 1\n    try:\n        import runpy\n\n        if opts.module is not None:\n            runpy.run_module(opts.module, run_name=\"__main__\", alter_sys=True)\n        else:\n            assert path is not None\n            runpy.run_path(path, run_name=\"__main__\")\n    except SystemExit as e:\n        exit_status = e.code\n        gen_log.info(\"Script exited with status %s\", e.code)\n    except Exception as e:\n        gen_log.warning(\"Script exited with uncaught exception\", exc_info=True)\n        # If an exception occurred at import time, the file with the error\n        # never made it into sys.modules and so we won't know to watch it.\n        # Just to make sure we've covered everything, walk the stack trace\n        # from the exception and watch every file.\n        for filename, lineno, name, line in traceback.extract_tb(sys.exc_info()[2]):\n            watch(filename)\n        if isinstance(e, SyntaxError):\n            # SyntaxErrors are special:  their innermost stack frame is fake\n            # so extract_tb won't see it and we have to get the filename\n            # from the exception object.\n            if e.filename is not None:\n                watch(e.filename)\n    else:\n        exit_status = 0\n        gen_log.info(\"Script exited normally\")\n    # restore sys.argv so subsequent executions will include autoreload\n    sys.argv = original_argv\n\n    if opts.module is not None:\n        assert opts.module is not None\n        # runpy did a fake import of the module as __main__, but now it's\n        # no longer in sys.modules.  Figure out where it is and watch it.\n        loader = pkgutil.get_loader(opts.module)\n        if loader is not None and isinstance(loader, importlib.abc.FileLoader):\n            watch(loader.get_filename())\n    if opts.until_success and not exit_status:\n        return\n    wait()",
      "importString": "import os\nimport sys\nimport functools\nimport importlib.abc\nimport os\nimport pkgutil\nimport sys\nimport traceback\nimport types\nimport subprocess\nimport weakref\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado import process\nfrom typing import Callable, Dict, Optional, List, Union",
      "lineNum": 98,
      "relativeDocumentPath": "tornado/autoreload.py"
    },
    {
      "symbolName": "run_on_executor",
      "sourceCode": "def run_on_executor(*args: Any, **kwargs: Any) -> Callable:\n    \"\"\"Decorator to run a synchronous method asynchronously on an executor.\n\n    Returns a future.\n\n    The executor to be used is determined by the ``executor``\n    attributes of ``self``. To use a different attribute name, pass a\n    keyword argument to the decorator::\n\n        @run_on_executor(executor='_thread_pool')\n        def foo(self):\n            pass\n\n    This decorator should not be confused with the similarly-named\n    `.IOLoop.run_in_executor`. In general, using ``run_in_executor``\n    when *calling* a blocking method is recommended instead of using\n    this decorator when *defining* a method. If compatibility with older\n    versions of Tornado is required, consider defining an executor\n    and using ``executor.submit()`` at the call site.\n\n    .. versionchanged:: 4.2\n       Added keyword arguments to use alternative attributes.\n\n    .. versionchanged:: 5.0\n       Always uses the current IOLoop instead of ``self.io_loop``.\n\n    .. versionchanged:: 5.1\n       Returns a `.Future` compatible with ``await`` instead of a\n       `concurrent.futures.Future`.\n\n    .. deprecated:: 5.1\n\n       The ``callback`` argument is deprecated and will be removed in\n       6.0. The decorator itself is discouraged in new code but will\n       not be removed in 6.0.\n\n    .. versionchanged:: 6.0\n\n       The ``callback`` argument was removed.\n    \"\"\"\n\n    # Fully type-checking decorators is tricky, and this one is\n    # discouraged anyway so it doesn't have all the generic magic.\n    def run_on_executor_decorator(fn: Callable) -> Callable[..., Future]:\n        executor = kwargs.get(\"executor\", \"executor\")\n\n        @functools.wraps(fn)\n        def wrapper(self: Any, *args: Any, **kwargs: Any) -> Future:\n            async_future = Future()  # type: Future\n            conc_future = getattr(self, executor).submit(fn, self, *args, **kwargs)\n            chain_future(conc_future, async_future)\n            return async_future\n\n        return wrapper\n\n    if args and kwargs:\n        raise ValueError(\"cannot combine positional and keyword args\")\n    if len(args) == 1:\n        return run_on_executor_decorator(args[0])\n    elif len(args) != 0:\n        raise ValueError(\"expected 1 argument, got %d\", len(args))\n    return run_on_executor_decorator",
      "importString": "from concurrent import futures\nimport functools\nimport sys\nimport types\n\nfrom tornado.log import app_log\n\nimport typing\nfrom typing import Any, Callable, Optional, Tuple, Union",
      "lineNum": 61,
      "relativeDocumentPath": "tornado/concurrent.py"
    },
    {
      "symbolName": "run_on_executor_decorator",
      "sourceCode": "def run_on_executor_decorator(fn: Callable) -> Callable[..., Future]:\n        executor = kwargs.get(\"executor\", \"executor\")\n\n        @functools.wraps(fn)\n        def wrapper(self: Any, *args: Any, **kwargs: Any) -> Future:\n            async_future = Future()  # type: Future\n            conc_future = getattr(self, executor).submit(fn, self, *args, **kwargs)\n            chain_future(conc_future, async_future)\n            return async_future\n\n        return wrapper",
      "importString": "from concurrent import futures\nimport functools\nimport sys\nimport types\n\nfrom tornado.log import app_log\n\nimport typing\nfrom typing import Any, Callable, Optional, Tuple, Union",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/concurrent.py"
    },
    {
      "symbolName": "chain_future",
      "sourceCode": "def chain_future(\n    a: Union[\"Future[_T]\", \"futures.Future[_T]\"],\n    b: Union[\"Future[_T]\", \"futures.Future[_T]\"],\n) -> None:\n    \"\"\"Chain two futures together so that when one completes, so does the other.\n\n    The result (success or failure) of ``a`` will be copied to ``b``, unless\n    ``b`` has already been completed or cancelled by the time ``a`` finishes.\n\n    .. versionchanged:: 5.0\n\n       Now accepts both Tornado/asyncio `Future` objects and\n       `concurrent.futures.Future`.\n\n    \"\"\"\n\n    def copy(a: \"Future[_T]\") -> None:\n        if b.done():\n            return\n        if hasattr(a, \"exc_info\") and a.exc_info() is not None:  # type: ignore\n            future_set_exc_info(b, a.exc_info())  # type: ignore\n        else:\n            a_exc = a.exception()\n            if a_exc is not None:\n                b.set_exception(a_exc)\n            else:\n                b.set_result(a.result())\n\n    if isinstance(a, Future):\n        future_add_done_callback(a, copy)\n    else:\n        # concurrent.futures.Future\n        from tornado.ioloop import IOLoop\n\n        IOLoop.current().add_future(a, copy)",
      "importString": "from concurrent import futures\nimport functools\nimport sys\nimport types\n\nfrom tornado.log import app_log\n\nimport typing\nfrom typing import Any, Callable, Optional, Tuple, Union",
      "lineNum": 34,
      "relativeDocumentPath": "tornado/concurrent.py"
    },
    {
      "symbolName": "copy",
      "sourceCode": "def copy(a: \"Future[_T]\") -> None:\n        if b.done():\n            return\n        if hasattr(a, \"exc_info\") and a.exc_info() is not None:  # type: ignore\n            future_set_exc_info(b, a.exc_info())  # type: ignore\n        else:\n            a_exc = a.exception()\n            if a_exc is not None:\n                b.set_exception(a_exc)\n            else:\n                b.set_result(a.result())",
      "importString": "from concurrent import futures\nimport functools\nimport sys\nimport types\n\nfrom tornado.log import app_log\n\nimport typing\nfrom typing import Any, Callable, Optional, Tuple, Union",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/concurrent.py"
    },
    {
      "symbolName": "future_set_result_unless_cancelled",
      "sourceCode": "def future_set_result_unless_cancelled(\n    future: \"Union[futures.Future[_T], Future[_T]]\", value: _T\n) -> None:\n    \"\"\"Set the given ``value`` as the `Future`'s result, if not cancelled.\n\n    Avoids ``asyncio.InvalidStateError`` when calling ``set_result()`` on\n    a cancelled `asyncio.Future`.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    if not future.cancelled():\n        future.set_result(value)",
      "importString": "from concurrent import futures\nimport functools\nimport sys\nimport types\n\nfrom tornado.log import app_log\n\nimport typing\nfrom typing import Any, Callable, Optional, Tuple, Union",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/concurrent.py"
    },
    {
      "symbolName": "future_set_exception_unless_cancelled",
      "sourceCode": "def future_set_exception_unless_cancelled(\n    future: \"Union[futures.Future[_T], Future[_T]]\", exc: BaseException\n) -> None:\n    \"\"\"Set the given ``exc`` as the `Future`'s exception.\n\n    If the Future is already canceled, logs the exception instead. If\n    this logging is not desired, the caller should explicitly check\n    the state of the Future and call ``Future.set_exception`` instead of\n    this wrapper.\n\n    Avoids ``asyncio.InvalidStateError`` when calling ``set_exception()`` on\n    a cancelled `asyncio.Future`.\n\n    .. versionadded:: 6.0\n\n    \"\"\"\n    if not future.cancelled():\n        future.set_exception(exc)\n    else:\n        app_log.error(\"Exception after Future was cancelled\", exc_info=exc)",
      "importString": "from concurrent import futures\nimport functools\nimport sys\nimport types\n\nfrom tornado.log import app_log\n\nimport typing\nfrom typing import Any, Callable, Optional, Tuple, Union",
      "lineNum": 19,
      "relativeDocumentPath": "tornado/concurrent.py"
    },
    {
      "symbolName": "future_set_exc_info",
      "sourceCode": "def future_set_exc_info(\n    future: \"Union[futures.Future[_T], Future[_T]]\",\n    exc_info: Tuple[\n        Optional[type], Optional[BaseException], Optional[types.TracebackType]\n    ],\n) -> None:\n    \"\"\"Set the given ``exc_info`` as the `Future`'s exception.\n\n    Understands both `asyncio.Future` and the extensions in older\n    versions of Tornado to enable better tracebacks on Python 2.\n\n    .. versionadded:: 5.0\n\n    .. versionchanged:: 6.0\n\n       If the future is already cancelled, this function is a no-op.\n       (previously ``asyncio.InvalidStateError`` would be raised)\n\n    \"\"\"\n    if exc_info[1] is None:\n        raise Exception(\"future_set_exc_info called with no exception\")\n    future_set_exception_unless_cancelled(future, exc_info[1])",
      "importString": "from concurrent import futures\nimport functools\nimport sys\nimport types\n\nfrom tornado.log import app_log\n\nimport typing\nfrom typing import Any, Callable, Optional, Tuple, Union",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/concurrent.py"
    },
    {
      "symbolName": "future_add_done_callback",
      "sourceCode": "def future_add_done_callback(  # noqa: F811\n    future: \"Union[futures.Future[_T], Future[_T]]\", callback: Callable[..., None]\n) -> None:\n    \"\"\"Arrange to call ``callback`` when ``future`` is complete.\n\n    ``callback`` is invoked with one argument, the ``future``.\n\n    If ``future`` is already done, ``callback`` is invoked immediately.\n    This may differ from the behavior of ``Future.add_done_callback``,\n    which makes no such guarantee.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    if future.done():\n        callback(future)\n    else:\n        future.add_done_callback(callback)",
      "importString": "from concurrent import futures\nimport functools\nimport sys\nimport types\n\nfrom tornado.log import app_log\n\nimport typing\nfrom typing import Any, Callable, Optional, Tuple, Union",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/concurrent.py"
    },
    {
      "symbolName": "initialize",
      "sourceCode": "def initialize(  # type: ignore\n        self, max_clients: int = 10, defaults: Optional[Dict[str, Any]] = None\n    ) -> None:\n        super().initialize(defaults=defaults)\n        # Typeshed is incomplete for CurlMulti, so just use Any for now.\n        self._multi = pycurl.CurlMulti()  # type: Any\n        self._multi.setopt(pycurl.M_TIMERFUNCTION, self._set_timeout)\n        self._multi.setopt(pycurl.M_SOCKETFUNCTION, self._handle_socket)\n        self._curls = [self._curl_create() for i in range(max_clients)]\n        self._free_list = self._curls[:]\n        self._requests = (\n            collections.deque()\n        )  # type: Deque[Tuple[HTTPRequest, Callable[[HTTPResponse], None], float]]\n        self._fds = {}  # type: Dict[int, int]\n        self._timeout = None  # type: Optional[object]\n\n        # libcurl has bugs that sometimes cause it to not report all\n        # relevant file descriptors and timeouts to TIMERFUNCTION/\n        # SOCKETFUNCTION.  Mitigate the effects of such bugs by\n        # forcing a periodic scan of all active requests.\n        self._force_timeout_callback = ioloop.PeriodicCallback(\n            self._handle_force_timeout, 1000\n        )\n        self._force_timeout_callback.start()\n\n        # Work around a bug in libcurl 7.29.0: Some fields in the curl\n        # multi object are initialized lazily, and its destructor will\n        # segfault if it is destroyed without having been used.  Add\n        # and remove a dummy handle to make sure everything is\n        # initialized.\n        dummy_curl_handle = pycurl.Curl()\n        self._multi.add_handle(dummy_curl_handle)\n        self._multi.remove_handle(dummy_curl_handle)",
      "importString": "import collections\nimport functools\nimport logging\nimport pycurl\nimport re\nimport threading\nimport time\nfrom io import BytesIO\n\nfrom tornado import httputil\nfrom tornado import ioloop\n\nfrom tornado.escape import utf8, native_str\nfrom tornado.httpclient import (\nHTTPRequest\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n)\nfrom tornado.log import app_log\n\nfrom typing import Dict, Any, Callable, Union, Optional\nimport typing",
      "lineNum": 32,
      "relativeDocumentPath": "tornado/curl_httpclient.py"
    },
    {
      "symbolName": "close",
      "sourceCode": "def close(self) -> None:\n        self._force_timeout_callback.stop()\n        if self._timeout is not None:\n            self.io_loop.remove_timeout(self._timeout)\n        for curl in self._curls:\n            curl.close()\n        self._multi.close()\n        super().close()\n\n        # Set below properties to None to reduce the reference count of current\n        # instance, because those properties hold some methods of current\n        # instance that will case circular reference.\n        self._force_timeout_callback = None  # type: ignore\n        self._multi = None",
      "importString": "import collections\nimport functools\nimport logging\nimport pycurl\nimport re\nimport threading\nimport time\nfrom io import BytesIO\n\nfrom tornado import httputil\nfrom tornado import ioloop\n\nfrom tornado.escape import utf8, native_str\nfrom tornado.httpclient import (\nHTTPRequest\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n)\nfrom tornado.log import app_log\n\nfrom typing import Dict, Any, Callable, Union, Optional\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/curl_httpclient.py"
    },
    {
      "symbolName": "_handle_socket",
      "sourceCode": "def _handle_socket(self, event: int, fd: int, multi: Any, data: bytes) -> None:\n        \"\"\"Called by libcurl when it wants to change the file descriptors\n        it cares about.\n        \"\"\"\n        event_map = {\n            pycurl.POLL_NONE: ioloop.IOLoop.NONE,\n            pycurl.POLL_IN: ioloop.IOLoop.READ,\n            pycurl.POLL_OUT: ioloop.IOLoop.WRITE,\n            pycurl.POLL_INOUT: ioloop.IOLoop.READ | ioloop.IOLoop.WRITE,\n        }\n        if event == pycurl.POLL_REMOVE:\n            if fd in self._fds:\n                self.io_loop.remove_handler(fd)\n                del self._fds[fd]\n        else:\n            ioloop_event = event_map[event]\n            # libcurl sometimes closes a socket and then opens a new\n            # one using the same FD without giving us a POLL_NONE in\n            # between.  This is a problem with the epoll IOLoop,\n            # because the kernel can tell when a socket is closed and\n            # removes it from the epoll automatically, causing future\n            # update_handler calls to fail.  Since we can't tell when\n            # this has happened, always use remove and re-add\n            # instead of update.\n            if fd in self._fds:\n                self.io_loop.remove_handler(fd)\n            self.io_loop.add_handler(fd, self._handle_events, ioloop_event)\n            self._fds[fd] = ioloop_event",
      "importString": "import collections\nimport functools\nimport logging\nimport pycurl\nimport re\nimport threading\nimport time\nfrom io import BytesIO\n\nfrom tornado import httputil\nfrom tornado import ioloop\n\nfrom tornado.escape import utf8, native_str\nfrom tornado.httpclient import (\nHTTPRequest\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n)\nfrom tornado.log import app_log\n\nfrom typing import Dict, Any, Callable, Union, Optional\nimport typing",
      "lineNum": 27,
      "relativeDocumentPath": "tornado/curl_httpclient.py"
    },
    {
      "symbolName": "_handle_events",
      "sourceCode": "def _handle_events(self, fd: int, events: int) -> None:\n        \"\"\"Called by IOLoop when there is activity on one of our\n        file descriptors.\n        \"\"\"\n        action = 0\n        if events & ioloop.IOLoop.READ:\n            action |= pycurl.CSELECT_IN\n        if events & ioloop.IOLoop.WRITE:\n            action |= pycurl.CSELECT_OUT\n        while True:\n            try:\n                ret, num_handles = self._multi.socket_action(fd, action)\n            except pycurl.error as e:\n                ret = e.args[0]\n            if ret != pycurl.E_CALL_MULTI_PERFORM:\n                break\n        self._finish_pending_requests()",
      "importString": "import collections\nimport functools\nimport logging\nimport pycurl\nimport re\nimport threading\nimport time\nfrom io import BytesIO\n\nfrom tornado import httputil\nfrom tornado import ioloop\n\nfrom tornado.escape import utf8, native_str\nfrom tornado.httpclient import (\nHTTPRequest\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n)\nfrom tornado.log import app_log\n\nfrom typing import Dict, Any, Callable, Union, Optional\nimport typing",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/curl_httpclient.py"
    },
    {
      "symbolName": "_handle_timeout",
      "sourceCode": "def _handle_timeout(self) -> None:\n        \"\"\"Called by IOLoop when the requested timeout has passed.\"\"\"\n        self._timeout = None\n        while True:\n            try:\n                ret, num_handles = self._multi.socket_action(pycurl.SOCKET_TIMEOUT, 0)\n            except pycurl.error as e:\n                ret = e.args[0]\n            if ret != pycurl.E_CALL_MULTI_PERFORM:\n                break\n        self._finish_pending_requests()\n\n        # In theory, we shouldn't have to do this because curl will\n        # call _set_timeout whenever the timeout changes.  However,\n        # sometimes after _handle_timeout we will need to reschedule\n        # immediately even though nothing has changed from curl's\n        # perspective.  This is because when socket_action is\n        # called with SOCKET_TIMEOUT, libcurl decides internally which\n        # timeouts need to be processed by using a monotonic clock\n        # (where available) while tornado uses python's time.time()\n        # to decide when timeouts have occurred.  When those clocks\n        # disagree on elapsed time (as they will whenever there is an\n        # NTP adjustment), tornado might call _handle_timeout before\n        # libcurl is ready.  After each timeout, resync the scheduled\n        # timeout with libcurl's current state.\n        new_timeout = self._multi.timeout()\n        if new_timeout >= 0:\n            self._set_timeout(new_timeout)",
      "importString": "import collections\nimport functools\nimport logging\nimport pycurl\nimport re\nimport threading\nimport time\nfrom io import BytesIO\n\nfrom tornado import httputil\nfrom tornado import ioloop\n\nfrom tornado.escape import utf8, native_str\nfrom tornado.httpclient import (\nHTTPRequest\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n)\nfrom tornado.log import app_log\n\nfrom typing import Dict, Any, Callable, Union, Optional\nimport typing",
      "lineNum": 27,
      "relativeDocumentPath": "tornado/curl_httpclient.py"
    },
    {
      "symbolName": "_handle_force_timeout",
      "sourceCode": "def _handle_force_timeout(self) -> None:\n        \"\"\"Called by IOLoop periodically to ask libcurl to process any\n        events it may have forgotten about.\n        \"\"\"\n        while True:\n            try:\n                ret, num_handles = self._multi.socket_all()\n            except pycurl.error as e:\n                ret = e.args[0]\n            if ret != pycurl.E_CALL_MULTI_PERFORM:\n                break\n        self._finish_pending_requests()",
      "importString": "import collections\nimport functools\nimport logging\nimport pycurl\nimport re\nimport threading\nimport time\nfrom io import BytesIO\n\nfrom tornado import httputil\nfrom tornado import ioloop\n\nfrom tornado.escape import utf8, native_str\nfrom tornado.httpclient import (\nHTTPRequest\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n)\nfrom tornado.log import app_log\n\nfrom typing import Dict, Any, Callable, Union, Optional\nimport typing",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/curl_httpclient.py"
    },
    {
      "symbolName": "_finish_pending_requests",
      "sourceCode": "def _finish_pending_requests(self) -> None:\n        \"\"\"Process any requests that were completed by the last\n        call to multi.socket_action.\n        \"\"\"\n        while True:\n            num_q, ok_list, err_list = self._multi.info_read()\n            for curl in ok_list:\n                self._finish(curl)\n            for curl, errnum, errmsg in err_list:\n                self._finish(curl, errnum, errmsg)\n            if num_q == 0:\n                break\n        self._process_queue()",
      "importString": "import collections\nimport functools\nimport logging\nimport pycurl\nimport re\nimport threading\nimport time\nfrom io import BytesIO\n\nfrom tornado import httputil\nfrom tornado import ioloop\n\nfrom tornado.escape import utf8, native_str\nfrom tornado.httpclient import (\nHTTPRequest\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n)\nfrom tornado.log import app_log\n\nfrom typing import Dict, Any, Callable, Union, Optional\nimport typing",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/curl_httpclient.py"
    },
    {
      "symbolName": "_process_queue",
      "sourceCode": "def _process_queue(self) -> None:\n        while True:\n            started = 0\n            while self._free_list and self._requests:\n                started += 1\n                curl = self._free_list.pop()\n                (request, callback, queue_start_time) = self._requests.popleft()\n                # TODO: Don't smuggle extra data on an attribute of the Curl object.\n                curl.info = {  # type: ignore\n                    \"headers\": httputil.HTTPHeaders(),\n                    \"buffer\": BytesIO(),\n                    \"request\": request,\n                    \"callback\": callback,\n                    \"queue_start_time\": queue_start_time,\n                    \"curl_start_time\": time.time(),\n                    \"curl_start_ioloop_time\": self.io_loop.current().time(),  # type: ignore\n                }\n                try:\n                    self._curl_setup_request(\n                        curl,\n                        request,\n                        curl.info[\"buffer\"],  # type: ignore\n                        curl.info[\"headers\"],  # type: ignore\n                    )\n                except Exception as e:\n                    # If there was an error in setup, pass it on\n                    # to the callback. Note that allowing the\n                    # error to escape here will appear to work\n                    # most of the time since we are still in the\n                    # caller's original stack frame, but when\n                    # _process_queue() is called from\n                    # _finish_pending_requests the exceptions have\n                    # nowhere to go.\n                    self._free_list.append(curl)\n                    callback(HTTPResponse(request=request, code=599, error=e))\n                else:\n                    self._multi.add_handle(curl)\n\n            if not started:\n                break",
      "importString": "import collections\nimport functools\nimport logging\nimport pycurl\nimport re\nimport threading\nimport time\nfrom io import BytesIO\n\nfrom tornado import httputil\nfrom tornado import ioloop\n\nfrom tornado.escape import utf8, native_str\nfrom tornado.httpclient import (\nHTTPRequest\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n)\nfrom tornado.log import app_log\n\nfrom typing import Dict, Any, Callable, Union, Optional\nimport typing",
      "lineNum": 39,
      "relativeDocumentPath": "tornado/curl_httpclient.py"
    },
    {
      "symbolName": "_finish",
      "sourceCode": "def _finish(\n        self,\n        curl: pycurl.Curl,\n        curl_error: Optional[int] = None,\n        curl_message: Optional[str] = None,\n    ) -> None:\n        info = curl.info  # type: ignore\n        curl.info = None  # type: ignore\n        self._multi.remove_handle(curl)\n        self._free_list.append(curl)\n        buffer = info[\"buffer\"]\n        if curl_error:\n            assert curl_message is not None\n            error = CurlError(curl_error, curl_message)  # type: Optional[CurlError]\n            assert error is not None\n            code = error.code\n            effective_url = None\n            buffer.close()\n            buffer = None\n        else:\n            error = None\n            code = curl.getinfo(pycurl.HTTP_CODE)\n            effective_url = curl.getinfo(pycurl.EFFECTIVE_URL)\n            buffer.seek(0)\n        # the various curl timings are documented at\n        # http://curl.haxx.se/libcurl/c/curl_easy_getinfo.html\n        time_info = dict(\n            queue=info[\"curl_start_ioloop_time\"] - info[\"queue_start_time\"],\n            namelookup=curl.getinfo(pycurl.NAMELOOKUP_TIME),\n            connect=curl.getinfo(pycurl.CONNECT_TIME),\n            appconnect=curl.getinfo(pycurl.APPCONNECT_TIME),\n            pretransfer=curl.getinfo(pycurl.PRETRANSFER_TIME),\n            starttransfer=curl.getinfo(pycurl.STARTTRANSFER_TIME),\n            total=curl.getinfo(pycurl.TOTAL_TIME),\n            redirect=curl.getinfo(pycurl.REDIRECT_TIME),\n        )\n        try:\n            info[\"callback\"](\n                HTTPResponse(\n                    request=info[\"request\"],\n                    code=code,\n                    headers=info[\"headers\"],\n                    buffer=buffer,\n                    effective_url=effective_url,\n                    error=error,\n                    reason=info[\"headers\"].get(\"X-Http-Reason\", None),\n                    request_time=self.io_loop.time() - info[\"curl_start_ioloop_time\"],\n                    start_time=info[\"curl_start_time\"],\n                    time_info=time_info,\n                )\n            )\n        except Exception:\n            self.handle_callback_exception(info[\"callback\"])",
      "importString": "import collections\nimport functools\nimport logging\nimport pycurl\nimport re\nimport threading\nimport time\nfrom io import BytesIO\n\nfrom tornado import httputil\nfrom tornado import ioloop\n\nfrom tornado.escape import utf8, native_str\nfrom tornado.httpclient import (\nHTTPRequest\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n)\nfrom tornado.log import app_log\n\nfrom typing import Dict, Any, Callable, Union, Optional\nimport typing",
      "lineNum": 52,
      "relativeDocumentPath": "tornado/curl_httpclient.py"
    },
    {
      "symbolName": "_curl_create",
      "sourceCode": "def _curl_create(self) -> pycurl.Curl:\n        curl = pycurl.Curl()\n        if curl_log.isEnabledFor(logging.DEBUG):\n            curl.setopt(pycurl.VERBOSE, 1)\n            curl.setopt(pycurl.DEBUGFUNCTION, self._curl_debug)\n        if hasattr(\n            pycurl, \"PROTOCOLS\"\n        ):  # PROTOCOLS first appeared in pycurl 7.19.5 (2014-07-12)\n            curl.setopt(pycurl.PROTOCOLS, pycurl.PROTO_HTTP | pycurl.PROTO_HTTPS)\n            curl.setopt(pycurl.REDIR_PROTOCOLS, pycurl.PROTO_HTTP | pycurl.PROTO_HTTPS)\n        return curl",
      "importString": "import collections\nimport functools\nimport logging\nimport pycurl\nimport re\nimport threading\nimport time\nfrom io import BytesIO\n\nfrom tornado import httputil\nfrom tornado import ioloop\n\nfrom tornado.escape import utf8, native_str\nfrom tornado.httpclient import (\nHTTPRequest\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n)\nfrom tornado.log import app_log\n\nfrom typing import Dict, Any, Callable, Union, Optional\nimport typing",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/curl_httpclient.py"
    },
    {
      "symbolName": "_curl_setup_request",
      "sourceCode": "def _curl_setup_request(\n        self,\n        curl: pycurl.Curl,\n        request: HTTPRequest,\n        buffer: BytesIO,\n        headers: httputil.HTTPHeaders,\n    ) -> None:\n        curl.setopt(pycurl.URL, native_str(request.url))\n\n        # libcurl's magic \"Expect: 100-continue\" behavior causes delays\n        # with servers that don't support it (which include, among others,\n        # Google's OpenID endpoint).  Additionally, this behavior has\n        # a bug in conjunction with the curl_multi_socket_action API\n        # (https://sourceforge.net/tracker/?func=detail&atid=100976&aid=3039744&group_id=976),\n        # which increases the delays.  It's more trouble than it's worth,\n        # so just turn off the feature (yes, setting Expect: to an empty\n        # value is the official way to disable this)\n        if \"Expect\" not in request.headers:\n            request.headers[\"Expect\"] = \"\"\n\n        # libcurl adds Pragma: no-cache by default; disable that too\n        if \"Pragma\" not in request.headers:\n            request.headers[\"Pragma\"] = \"\"\n\n        encoded_headers = [\n            b\"%s: %s\"\n            % (native_str(k).encode(\"ASCII\"), native_str(v).encode(\"ISO8859-1\"))\n            for k, v in request.headers.get_all()\n        ]\n        for line in encoded_headers:\n            if CR_OR_LF_RE.search(line):\n                raise ValueError(\"Illegal characters in header (CR or LF): %r\" % line)\n        curl.setopt(pycurl.HTTPHEADER, encoded_headers)\n\n        curl.setopt(\n            pycurl.HEADERFUNCTION,\n            functools.partial(\n                self._curl_header_callback, headers, request.header_callback\n            ),\n        )\n        if request.streaming_callback:\n\n            def write_function(b: Union[bytes, bytearray]) -> int:\n                assert request.streaming_callback is not None\n                self.io_loop.add_callback(request.streaming_callback, b)\n                return len(b)\n\n        else:\n            write_function = buffer.write  # type: ignore\n        curl.setopt(pycurl.WRITEFUNCTION, write_function)\n        curl.setopt(pycurl.FOLLOWLOCATION, request.follow_redirects)\n        curl.setopt(pycurl.MAXREDIRS, request.max_redirects)\n        assert request.connect_timeout is not None\n        curl.setopt(pycurl.CONNECTTIMEOUT_MS, int(1000 * request.connect_timeout))\n        assert request.request_timeout is not None\n        curl.setopt(pycurl.TIMEOUT_MS, int(1000 * request.request_timeout))\n        if request.user_agent:\n            curl.setopt(pycurl.USERAGENT, native_str(request.user_agent))\n        else:\n            curl.setopt(pycurl.USERAGENT, \"Mozilla/5.0 (compatible; pycurl)\")\n        if request.network_interface:\n            curl.setopt(pycurl.INTERFACE, request.network_interface)\n        if request.decompress_response:\n            curl.setopt(pycurl.ENCODING, \"gzip,deflate\")\n        else:\n            curl.setopt(pycurl.ENCODING, None)\n        if request.proxy_host and request.proxy_port:\n            curl.setopt(pycurl.PROXY, request.proxy_host)\n            curl.setopt(pycurl.PROXYPORT, request.proxy_port)\n            if request.proxy_username:\n                assert request.proxy_password is not None\n                credentials = httputil.encode_username_password(\n                    request.proxy_username, request.proxy_password\n                )\n                curl.setopt(pycurl.PROXYUSERPWD, credentials)\n\n            if request.proxy_auth_mode is None or request.proxy_auth_mode == \"basic\":\n                curl.setopt(pycurl.PROXYAUTH, pycurl.HTTPAUTH_BASIC)\n            elif request.proxy_auth_mode == \"digest\":\n                curl.setopt(pycurl.PROXYAUTH, pycurl.HTTPAUTH_DIGEST)\n            else:\n                raise ValueError(\n                    \"Unsupported proxy_auth_mode %s\" % request.proxy_auth_mode\n                )\n        else:\n            try:\n                curl.unsetopt(pycurl.PROXY)\n            except TypeError:  # not supported, disable proxy\n                curl.setopt(pycurl.PROXY, \"\")\n            curl.unsetopt(pycurl.PROXYUSERPWD)\n        if request.validate_cert:\n            curl.setopt(pycurl.SSL_VERIFYPEER, 1)\n            curl.setopt(pycurl.SSL_VERIFYHOST, 2)\n        else:\n            curl.setopt(pycurl.SSL_VERIFYPEER, 0)\n            curl.setopt(pycurl.SSL_VERIFYHOST, 0)\n        if request.ca_certs is not None:\n            curl.setopt(pycurl.CAINFO, request.ca_certs)\n        else:\n            # There is no way to restore pycurl.CAINFO to its default value\n            # (Using unsetopt makes it reject all certificates).\n            # I don't see any way to read the default value from python so it\n            # can be restored later.  We'll have to just leave CAINFO untouched\n            # if no ca_certs file was specified, and require that if any\n            # request uses a custom ca_certs file, they all must.\n            pass\n\n        if request.allow_ipv6 is False:\n            # Curl behaves reasonably when DNS resolution gives an ipv6 address\n            # that we can't reach, so allow ipv6 unless the user asks to disable.\n            curl.setopt(pycurl.IPRESOLVE, pycurl.IPRESOLVE_V4)\n        else:\n            curl.setopt(pycurl.IPRESOLVE, pycurl.IPRESOLVE_WHATEVER)\n\n        # Set the request method through curl's irritating interface which makes\n        # up names for almost every single method\n        curl_options = {\n            \"GET\": pycurl.HTTPGET,\n            \"POST\": pycurl.POST,\n            \"PUT\": pycurl.UPLOAD,\n            \"HEAD\": pycurl.NOBODY,\n        }\n        custom_methods = {\"DELETE\", \"OPTIONS\", \"PATCH\"}\n        for o in curl_options.values():\n            curl.setopt(o, False)\n        if request.method in curl_options:\n            curl.unsetopt(pycurl.CUSTOMREQUEST)\n            curl.setopt(curl_options[request.method], True)\n        elif request.allow_nonstandard_methods or request.method in custom_methods:\n            curl.setopt(pycurl.CUSTOMREQUEST, request.method)\n        else:\n            raise KeyError(\"unknown method \" + request.method)\n\n        body_expected = request.method in (\"POST\", \"PATCH\", \"PUT\")\n        body_present = request.body is not None\n        if not request.allow_nonstandard_methods:\n            # Some HTTP methods nearly always have bodies while others\n            # almost never do. Fail in this case unless the user has\n            # opted out of sanity checks with allow_nonstandard_methods.\n            if (body_expected and not body_present) or (\n                body_present and not body_expected\n            ):\n                raise ValueError(\n                    \"Body must %sbe None for method %s (unless \"\n                    \"allow_nonstandard_methods is true)\"\n                    % (\"not \" if body_expected else \"\", request.method)\n                )\n\n        if body_expected or body_present:\n            if request.method == \"GET\":\n                # Even with `allow_nonstandard_methods` we disallow\n                # GET with a body (because libcurl doesn't allow it\n                # unless we use CUSTOMREQUEST). While the spec doesn't\n                # forbid clients from sending a body, it arguably\n                # disallows the server from doing anything with them.\n                raise ValueError(\"Body must be None for GET request\")\n            request_buffer = BytesIO(utf8(request.body or \"\"))\n\n            def ioctl(cmd: int) -> None:\n                if cmd == curl.IOCMD_RESTARTREAD:  # type: ignore\n                    request_buffer.seek(0)\n\n            curl.setopt(pycurl.READFUNCTION, request_buffer.read)\n            curl.setopt(pycurl.IOCTLFUNCTION, ioctl)\n            if request.method == \"POST\":\n                curl.setopt(pycurl.POSTFIELDSIZE, len(request.body or \"\"))\n            else:\n                curl.setopt(pycurl.UPLOAD, True)\n                curl.setopt(pycurl.INFILESIZE, len(request.body or \"\"))\n\n        if request.auth_username is not None:\n            assert request.auth_password is not None\n            if request.auth_mode is None or request.auth_mode == \"basic\":\n                curl.setopt(pycurl.HTTPAUTH, pycurl.HTTPAUTH_BASIC)\n            elif request.auth_mode == \"digest\":\n                curl.setopt(pycurl.HTTPAUTH, pycurl.HTTPAUTH_DIGEST)\n            else:\n                raise ValueError(\"Unsupported auth_mode %s\" % request.auth_mode)\n\n            userpwd = httputil.encode_username_password(\n                request.auth_username, request.auth_password\n            )\n            curl.setopt(pycurl.USERPWD, userpwd)\n            curl_log.debug(\n                \"%s %s (username: %r)\",\n                request.method,\n                request.url,\n                request.auth_username,\n            )\n        else:\n            curl.unsetopt(pycurl.USERPWD)\n            curl_log.debug(\"%s %s\", request.method, request.url)\n\n        if request.client_cert is not None:\n            curl.setopt(pycurl.SSLCERT, request.client_cert)\n\n        if request.client_key is not None:\n            curl.setopt(pycurl.SSLKEY, request.client_key)\n\n        if request.ssl_options is not None:\n            raise ValueError(\"ssl_options not supported in curl_httpclient\")\n\n        if threading.active_count() > 1:\n            # libcurl/pycurl is not thread-safe by default.  When multiple threads\n            # are used, signals should be disabled.  This has the side effect\n            # of disabling DNS timeouts in some environments (when libcurl is\n            # not linked against ares), so we don't do it when there is only one\n            # thread.  Applications that use many short-lived threads may need\n            # to set NOSIGNAL manually in a prepare_curl_callback since\n            # there may not be any other threads running at the time we call\n            # threading.activeCount.\n            curl.setopt(pycurl.NOSIGNAL, 1)\n        if request.prepare_curl_callback is not None:\n            request.prepare_curl_callback(curl)",
      "importString": "import collections\nimport functools\nimport logging\nimport pycurl\nimport re\nimport threading\nimport time\nfrom io import BytesIO\n\nfrom tornado import httputil\nfrom tornado import ioloop\n\nfrom tornado.escape import utf8, native_str\nfrom tornado.httpclient import (\nHTTPRequest\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n)\nfrom tornado.log import app_log\n\nfrom typing import Dict, Any, Callable, Union, Optional\nimport typing",
      "lineNum": 213,
      "relativeDocumentPath": "tornado/curl_httpclient.py"
    },
    {
      "symbolName": "_curl_header_callback",
      "sourceCode": "def _curl_header_callback(\n        self,\n        headers: httputil.HTTPHeaders,\n        header_callback: Optional[Callable[[str], None]],\n        header_line_bytes: bytes,\n    ) -> None:\n        header_line = native_str(header_line_bytes.decode(\"latin1\"))\n        if header_callback is not None:\n            self.io_loop.add_callback(header_callback, header_line)\n        # header_line as returned by curl includes the end-of-line characters.\n        # whitespace at the start should be preserved to allow multi-line headers\n        header_line = header_line.rstrip()\n        if header_line.startswith(\"HTTP/\"):\n            headers.clear()\n            try:\n                (_version, _code, reason) = httputil.parse_response_start_line(\n                    header_line\n                )\n                header_line = \"X-Http-Reason: %s\" % reason\n            except httputil.HTTPInputError:\n                return\n        if not header_line:\n            return\n        headers.parse_line(header_line)",
      "importString": "import collections\nimport functools\nimport logging\nimport pycurl\nimport re\nimport threading\nimport time\nfrom io import BytesIO\n\nfrom tornado import httputil\nfrom tornado import ioloop\n\nfrom tornado.escape import utf8, native_str\nfrom tornado.httpclient import (\nHTTPRequest\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n)\nfrom tornado.log import app_log\n\nfrom typing import Dict, Any, Callable, Union, Optional\nimport typing",
      "lineNum": 23,
      "relativeDocumentPath": "tornado/curl_httpclient.py"
    },
    {
      "symbolName": "_curl_debug",
      "sourceCode": "def _curl_debug(self, debug_type: int, debug_msg: str) -> None:\n        debug_types = (\"I\", \"<\", \">\", \"<\", \">\")\n        if debug_type == 0:\n            debug_msg = native_str(debug_msg)\n            curl_log.debug(\"%s\", debug_msg.strip())\n        elif debug_type in (1, 2):\n            debug_msg = native_str(debug_msg)\n            for line in debug_msg.splitlines():\n                curl_log.debug(\"%s %s\", debug_types[debug_type], line)\n        elif debug_type == 4:\n            curl_log.debug(\"%s %r\", debug_types[debug_type], debug_msg)",
      "importString": "import collections\nimport functools\nimport logging\nimport pycurl\nimport re\nimport threading\nimport time\nfrom io import BytesIO\n\nfrom tornado import httputil\nfrom tornado import ioloop\n\nfrom tornado.escape import utf8, native_str\nfrom tornado.httpclient import (\nHTTPRequest\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n)\nfrom tornado.log import app_log\n\nfrom typing import Dict, Any, Callable, Union, Optional\nimport typing",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/curl_httpclient.py"
    },
    {
      "symbolName": "xhtml_escape",
      "sourceCode": "def xhtml_escape(value: Union[str, bytes]) -> str:\n    \"\"\"Escapes a string so it is valid within HTML or XML.\n\n    Escapes the characters ``<``, ``>``, ``\"``, ``'``, and ``&``.\n    When used in attribute values the escaped strings must be enclosed\n    in quotes.\n\n    Equivalent to `html.escape` except that this function always returns\n    type `str` while `html.escape` returns `bytes` if its input is `bytes`.\n\n    .. versionchanged:: 3.2\n\n       Added the single quote to the list of escaped characters.\n\n    .. versionchanged:: 6.4\n\n       Now simply wraps `html.escape`. This is equivalent to the old behavior\n       except that single quotes are now escaped as ``&#x27;`` instead of\n       ``&#39;`` and performance may be different.\n    \"\"\"\n    return html.escape(to_unicode(value))",
      "importString": "import html\nimport json\nimport re\nimport urllib.parse\nfrom tornado.util import unicode_type\n\nimport typing\nfrom typing import Union, Any, Optional, Dict, List, Callable",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/escape.py"
    },
    {
      "symbolName": "xhtml_unescape",
      "sourceCode": "def xhtml_unescape(value: Union[str, bytes]) -> str:\n    \"\"\"Un-escapes an XML-escaped string.\n\n    Equivalent to `html.unescape` except that this function always returns\n    type `str` while `html.unescape` returns `bytes` if its input is `bytes`.\n\n    .. versionchanged:: 6.4\n\n       Now simply wraps `html.unescape`. This changes behavior for some inputs\n       as required by the HTML 5 specification\n       https://html.spec.whatwg.org/multipage/parsing.html#numeric-character-reference-end-state\n\n       Some invalid inputs such as surrogates now raise an error, and numeric\n       references to certain ISO-8859-1 characters are now handled correctly.\n    \"\"\"\n    return html.unescape(to_unicode(value))",
      "importString": "import html\nimport json\nimport re\nimport urllib.parse\nfrom tornado.util import unicode_type\n\nimport typing\nfrom typing import Union, Any, Optional, Dict, List, Callable",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/escape.py"
    },
    {
      "symbolName": "json_encode",
      "sourceCode": "def json_encode(value: Any) -> str:\n    \"\"\"JSON-encodes the given Python object.\n\n    Equivalent to `json.dumps` with the additional guarantee that the output\n    will never contain the character sequence ``</`` which can be problematic\n    when JSON is embedded in an HTML ``<script>`` tag.\n    \"\"\"\n    # JSON permits but does not require forward slashes to be escaped.\n    # This is useful when json data is emitted in a <script> tag\n    # in HTML, as it prevents </script> tags from prematurely terminating\n    # the JavaScript.  Some json libraries do this escaping by default,\n    # although python's standard library does not, so we do it here.\n    # http://stackoverflow.com/questions/1580647/json-why-are-forward-slashes-escaped\n    return json.dumps(value).replace(\"</\", \"<\\\\/\")",
      "importString": "import html\nimport json\nimport re\nimport urllib.parse\nfrom tornado.util import unicode_type\n\nimport typing\nfrom typing import Union, Any, Optional, Dict, List, Callable",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/escape.py"
    },
    {
      "symbolName": "url_escape",
      "sourceCode": "def url_escape(value: Union[str, bytes], plus: bool = True) -> str:\n    \"\"\"Returns a URL-encoded version of the given value.\n\n    Equivalent to either `urllib.parse.quote_plus` or `urllib.parse.quote` depending on the ``plus``\n    argument.\n\n    If ``plus`` is true (the default), spaces will be represented as ``+`` and slashes will be\n    represented as ``%2F``.  This is appropriate for query strings. If ``plus`` is false, spaces\n    will be represented as ``%20`` and slashes are left as-is. This is appropriate for the path\n    component of a URL. Note that the default of ``plus=True`` is effectively the\n    reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n        The ``plus`` argument\n    \"\"\"\n    quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n    return quote(value)",
      "importString": "import html\nimport json\nimport re\nimport urllib.parse\nfrom tornado.util import unicode_type\n\nimport typing\nfrom typing import Union, Any, Optional, Dict, List, Callable",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/escape.py"
    },
    {
      "symbolName": "url_unescape",
      "sourceCode": "def url_unescape(\n    value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n) -> Union[str, bytes]:\n    \"\"\"Decodes the given value from a URL.\n\n    The argument may be either a byte or unicode string.\n\n    If encoding is None, the result will be a byte string and this function is equivalent to\n    `urllib.parse.unquote_to_bytes` if ``plus=False``.  Otherwise, the result is a unicode string in\n    the specified encoding and this function is equivalent to either `urllib.parse.unquote_plus` or\n    `urllib.parse.unquote` except that this function also accepts `bytes` as input.\n\n    If ``plus`` is true (the default), plus signs will be interpreted as spaces (literal plus signs\n    must be represented as \"%2B\").  This is appropriate for query strings and form-encoded values\n    but not for the path component of a URL.  Note that this default is the reverse of Python's\n    urllib module.\n\n    .. versionadded:: 3.1\n       The ``plus`` argument\n    \"\"\"\n    if encoding is None:\n        if plus:\n            # unquote_to_bytes doesn't have a _plus variant\n            value = to_basestring(value).replace(\"+\", \" \")\n        return urllib.parse.unquote_to_bytes(value)\n    else:\n        unquote = urllib.parse.unquote_plus if plus else urllib.parse.unquote\n        return unquote(to_basestring(value), encoding=encoding)",
      "importString": "import html\nimport json\nimport re\nimport urllib.parse\nfrom tornado.util import unicode_type\n\nimport typing\nfrom typing import Union, Any, Optional, Dict, List, Callable",
      "lineNum": 27,
      "relativeDocumentPath": "tornado/escape.py"
    },
    {
      "symbolName": "parse_qs_bytes",
      "sourceCode": "def parse_qs_bytes(\n    qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n) -> Dict[str, List[bytes]]:\n    \"\"\"Parses a query string like urlparse.parse_qs,\n    but takes bytes and returns the values as byte strings.\n\n    Keys still become type str (interpreted as latin1 in python3!)\n    because it's too painful to keep them as byte strings in\n    python3 and in practice they're nearly always ascii anyway.\n    \"\"\"\n    # This is gross, but python3 doesn't give us another way.\n    # Latin1 is the universal donor of character encodings.\n    if isinstance(qs, bytes):\n        qs = qs.decode(\"latin1\")\n    result = urllib.parse.parse_qs(\n        qs, keep_blank_values, strict_parsing, encoding=\"latin1\", errors=\"strict\"\n    )\n    encoded = {}\n    for k, v in result.items():\n        encoded[k] = [i.encode(\"latin1\") for i in v]\n    return encoded",
      "importString": "import html\nimport json\nimport re\nimport urllib.parse\nfrom tornado.util import unicode_type\n\nimport typing\nfrom typing import Union, Any, Optional, Dict, List, Callable",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/escape.py"
    },
    {
      "symbolName": "utf8",
      "sourceCode": "def utf8(value: Union[None, str, bytes]) -> Optional[bytes]:\n    \"\"\"Converts a string argument to a byte string.\n\n    If the argument is already a byte string or None, it is returned unchanged.\n    Otherwise it must be a unicode string and is encoded as utf8.\n    \"\"\"\n    if isinstance(value, _UTF8_TYPES):\n        return value\n    if not isinstance(value, unicode_type):\n        raise TypeError(\"Expected bytes, unicode, or None; got %r\" % type(value))\n    return value.encode(\"utf-8\")",
      "importString": "import html\nimport json\nimport re\nimport urllib.parse\nfrom tornado.util import unicode_type\n\nimport typing\nfrom typing import Union, Any, Optional, Dict, List, Callable",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/escape.py"
    },
    {
      "symbolName": "to_unicode",
      "sourceCode": "def to_unicode(value: Union[None, str, bytes]) -> Optional[str]:\n    \"\"\"Converts a string argument to a unicode string.\n\n    If the argument is already a unicode string or None, it is returned\n    unchanged.  Otherwise it must be a byte string and is decoded as utf8.\n    \"\"\"\n    if isinstance(value, _TO_UNICODE_TYPES):\n        return value\n    if not isinstance(value, bytes):\n        raise TypeError(\"Expected bytes, unicode, or None; got %r\" % type(value))\n    return value.decode(\"utf-8\")",
      "importString": "import html\nimport json\nimport re\nimport urllib.parse\nfrom tornado.util import unicode_type\n\nimport typing\nfrom typing import Union, Any, Optional, Dict, List, Callable",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/escape.py"
    },
    {
      "symbolName": "recursive_unicode",
      "sourceCode": "def recursive_unicode(obj: Any) -> Any:\n    \"\"\"Walks a simple data structure, converting byte strings to unicode.\n\n    Supports lists, tuples, and dictionaries.\n    \"\"\"\n    if isinstance(obj, dict):\n        return {recursive_unicode(k): recursive_unicode(v) for (k, v) in obj.items()}\n    elif isinstance(obj, list):\n        return list(recursive_unicode(i) for i in obj)\n    elif isinstance(obj, tuple):\n        return tuple(recursive_unicode(i) for i in obj)\n    elif isinstance(obj, bytes):\n        return to_unicode(obj)\n    else:\n        return obj",
      "importString": "import html\nimport json\nimport re\nimport urllib.parse\nfrom tornado.util import unicode_type\n\nimport typing\nfrom typing import Union, Any, Optional, Dict, List, Callable",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/escape.py"
    },
    {
      "symbolName": "linkify",
      "sourceCode": "def linkify(\n    text: Union[str, bytes],\n    shorten: bool = False,\n    extra_params: Union[str, Callable[[str], str]] = \"\",\n    require_protocol: bool = False,\n    permitted_protocols: List[str] = [\"http\", \"https\"],\n) -> str:\n    \"\"\"Converts plain text into HTML with links.\n\n    For example: ``linkify(\"Hello http://tornadoweb.org!\")`` would return\n    ``Hello <a href=\"http://tornadoweb.org\">http://tornadoweb.org</a>!``\n\n    Parameters:\n\n    * ``shorten``: Long urls will be shortened for display.\n\n    * ``extra_params``: Extra text to include in the link tag, or a callable\n      taking the link as an argument and returning the extra text\n      e.g. ``linkify(text, extra_params='rel=\"nofollow\" class=\"external\"')``,\n      or::\n\n          def extra_params_cb(url):\n              if url.startswith(\"http://example.com\"):\n                  return 'class=\"internal\"'\n              else:\n                  return 'class=\"external\" rel=\"nofollow\"'\n          linkify(text, extra_params=extra_params_cb)\n\n    * ``require_protocol``: Only linkify urls which include a protocol. If\n      this is False, urls such as www.facebook.com will also be linkified.\n\n    * ``permitted_protocols``: List (or set) of protocols which should be\n      linkified, e.g. ``linkify(text, permitted_protocols=[\"http\", \"ftp\",\n      \"mailto\"])``. It is very unsafe to include protocols such as\n      ``javascript``.\n    \"\"\"\n    if extra_params and not callable(extra_params):\n        extra_params = \" \" + extra_params.strip()\n\n    def make_link(m: typing.Match) -> str:\n        url = m.group(1)\n        proto = m.group(2)\n        if require_protocol and not proto:\n            return url  # not protocol, no linkify\n\n        if proto and proto not in permitted_protocols:\n            return url  # bad protocol, no linkify\n\n        href = m.group(1)\n        if not proto:\n            href = \"http://\" + href  # no proto specified, use http\n\n        if callable(extra_params):\n            params = \" \" + extra_params(href).strip()\n        else:\n            params = extra_params\n\n        # clip long urls. max_len is just an approximation\n        max_len = 30\n        if shorten and len(url) > max_len:\n            before_clip = url\n            if proto:\n                proto_len = len(proto) + 1 + len(m.group(3) or \"\")  # +1 for :\n            else:\n                proto_len = 0\n\n            parts = url[proto_len:].split(\"/\")\n            if len(parts) > 1:\n                # Grab the whole host part plus the first bit of the path\n                # The path is usually not that interesting once shortened\n                # (no more slug, etc), so it really just provides a little\n                # extra indication of shortening.\n                url = (\n                    url[:proto_len]\n                    + parts[0]\n                    + \"/\"\n                    + parts[1][:8].split(\"?\")[0].split(\".\")[0]\n                )\n\n            if len(url) > max_len * 1.5:  # still too long\n                url = url[:max_len]\n\n            if url != before_clip:\n                amp = url.rfind(\"&\")\n                # avoid splitting html char entities\n                if amp > max_len - 5:\n                    url = url[:amp]\n                url += \"...\"\n\n                if len(url) >= len(before_clip):\n                    url = before_clip\n                else:\n                    # full url is visible on mouse-over (for those who don't\n                    # have a status bar, such as Safari by default)\n                    params += ' title=\"%s\"' % href\n\n        return f'<a href=\"{href}\"{params}>{url}</a>'\n\n    # First HTML-escape so that our strings are all safe.\n    # The regex is modified to avoid character entites other than &amp; so\n    # that we won't pick up &quot;, etc.\n    text = _unicode(xhtml_escape(text))\n    return _URL_RE.sub(make_link, text)",
      "importString": "import html\nimport json\nimport re\nimport urllib.parse\nfrom tornado.util import unicode_type\n\nimport typing\nfrom typing import Union, Any, Optional, Dict, List, Callable",
      "lineNum": 102,
      "relativeDocumentPath": "tornado/escape.py"
    },
    {
      "symbolName": "make_link",
      "sourceCode": "def make_link(m: typing.Match) -> str:\n        url = m.group(1)\n        proto = m.group(2)\n        if require_protocol and not proto:\n            return url  # not protocol, no linkify\n\n        if proto and proto not in permitted_protocols:\n            return url  # bad protocol, no linkify\n\n        href = m.group(1)\n        if not proto:\n            href = \"http://\" + href  # no proto specified, use http\n\n        if callable(extra_params):\n            params = \" \" + extra_params(href).strip()\n        else:\n            params = extra_params\n\n        # clip long urls. max_len is just an approximation\n        max_len = 30\n        if shorten and len(url) > max_len:\n            before_clip = url\n            if proto:\n                proto_len = len(proto) + 1 + len(m.group(3) or \"\")  # +1 for :\n            else:\n                proto_len = 0\n\n            parts = url[proto_len:].split(\"/\")\n            if len(parts) > 1:\n                # Grab the whole host part plus the first bit of the path\n                # The path is usually not that interesting once shortened\n                # (no more slug, etc), so it really just provides a little\n                # extra indication of shortening.\n                url = (\n                    url[:proto_len]\n                    + parts[0]\n                    + \"/\"\n                    + parts[1][:8].split(\"?\")[0].split(\".\")[0]\n                )\n\n            if len(url) > max_len * 1.5:  # still too long\n                url = url[:max_len]\n\n            if url != before_clip:\n                amp = url.rfind(\"&\")\n                # avoid splitting html char entities\n                if amp > max_len - 5:\n                    url = url[:amp]\n                url += \"...\"\n\n                if len(url) >= len(before_clip):\n                    url = before_clip\n                else:\n                    # full url is visible on mouse-over (for those who don't\n                    # have a status bar, such as Safari by default)\n                    params += ' title=\"%s\"' % href\n\n        return f'<a href=\"{href}\"{params}>{url}</a>'",
      "importString": "import html\nimport json\nimport re\nimport urllib.parse\nfrom tornado.util import unicode_type\n\nimport typing\nfrom typing import Union, Any, Optional, Dict, List, Callable",
      "lineNum": 57,
      "relativeDocumentPath": "tornado/escape.py"
    },
    {
      "symbolName": "_value_from_stopiteration",
      "sourceCode": "def _value_from_stopiteration(e: Union[StopIteration, \"Return\"]) -> Any:\n    try:\n        # StopIteration has a value attribute beginning in py33.\n        # So does our Return class.\n        return e.value\n    except AttributeError:\n        pass\n    try:\n        # Cython backports coroutine functionality by putting the value in\n        # e.args[0].\n        return e.args[0]\n    except (AttributeError, IndexError):\n        return None",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "_create_future",
      "sourceCode": "def _create_future() -> Future:\n    future = Future()  # type: Future\n    # Fixup asyncio debug info by removing extraneous stack entries\n    source_traceback = getattr(future, \"_source_traceback\", ())\n    while source_traceback:\n        # Each traceback entry is equivalent to a\n        # (filename, self.lineno, self.name, self.line) tuple\n        filename = source_traceback[-1][0]\n        if filename == __file__:\n            del source_traceback[-1]\n        else:\n            break\n    return future",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "coroutine",
      "sourceCode": "def coroutine(\n    func: Union[Callable[..., \"Generator[Any, Any, _T]\"], Callable[..., _T]],\n) -> Callable[..., \"Future[_T]\"]:\n    \"\"\"Decorator for asynchronous generators.\n\n    For compatibility with older versions of Python, coroutines may\n    also \"return\" by raising the special exception `Return(value)\n    <Return>`.\n\n    Functions with this decorator return a `.Future`.\n\n    .. warning::\n\n       When exceptions occur inside a coroutine, the exception\n       information will be stored in the `.Future` object. You must\n       examine the result of the `.Future` object, or the exception\n       may go unnoticed by your code. This means yielding the function\n       if called from another coroutine, using something like\n       `.IOLoop.run_sync` for top-level calls, or passing the `.Future`\n       to `.IOLoop.add_future`.\n\n    .. versionchanged:: 6.0\n\n       The ``callback`` argument was removed. Use the returned\n       awaitable object instead.\n\n    \"\"\"\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        # type: (*Any, **Any) -> Future[_T]\n        # This function is type-annotated with a comment to work around\n        # https://bitbucket.org/pypy/pypy/issues/2868/segfault-with-args-type-annotation-in\n        future = _create_future()\n        if contextvars is not None:\n            ctx_run = contextvars.copy_context().run  # type: Callable\n        else:\n            ctx_run = _fake_ctx_run\n        try:\n            result = ctx_run(func, *args, **kwargs)\n        except (Return, StopIteration) as e:\n            result = _value_from_stopiteration(e)\n        except Exception:\n            future_set_exc_info(future, sys.exc_info())\n            try:\n                return future\n            finally:\n                # Avoid circular references\n                future = None  # type: ignore\n        else:\n            if isinstance(result, Generator):\n                # Inline the first iteration of Runner.run.  This lets us\n                # avoid the cost of creating a Runner when the coroutine\n                # never actually yields, which in turn allows us to\n                # use \"optional\" coroutines in critical path code without\n                # performance penalty for the synchronous case.\n                try:\n                    yielded = ctx_run(next, result)\n                except (StopIteration, Return) as e:\n                    future_set_result_unless_cancelled(\n                        future, _value_from_stopiteration(e)\n                    )\n                except Exception:\n                    future_set_exc_info(future, sys.exc_info())\n                else:\n                    # Provide strong references to Runner objects as long\n                    # as their result future objects also have strong\n                    # references (typically from the parent coroutine's\n                    # Runner). This keeps the coroutine's Runner alive.\n                    # We do this by exploiting the public API\n                    # add_done_callback() instead of putting a private\n                    # attribute on the Future.\n                    # (GitHub issues #1769, #2229).\n                    runner = Runner(ctx_run, result, future, yielded)\n                    future.add_done_callback(lambda _: runner)\n                yielded = None\n                try:\n                    return future\n                finally:\n                    # Subtle memory optimization: if next() raised an exception,\n                    # the future's exc_info contains a traceback which\n                    # includes this stack frame.  This creates a cycle,\n                    # which will be collected at the next full GC but has\n                    # been shown to greatly increase memory usage of\n                    # benchmarks (relative to the refcount-based scheme\n                    # used in the absence of cycles).  We can avoid the\n                    # cycle by clearing the local variable after we return it.\n                    future = None  # type: ignore\n        future_set_result_unless_cancelled(future, result)\n        return future\n\n    wrapper.__wrapped__ = func  # type: ignore\n    wrapper.__tornado_coroutine__ = True  # type: ignore\n    return wrapper",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 93,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "wrapper",
      "sourceCode": "@functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        # type: (*Any, **Any) -> Future[_T]\n        # This function is type-annotated with a comment to work around\n        # https://bitbucket.org/pypy/pypy/issues/2868/segfault-with-args-type-annotation-in\n        future = _create_future()\n        if contextvars is not None:\n            ctx_run = contextvars.copy_context().run  # type: Callable\n        else:\n            ctx_run = _fake_ctx_run\n        try:\n            result = ctx_run(func, *args, **kwargs)\n        except (Return, StopIteration) as e:\n            result = _value_from_stopiteration(e)\n        except Exception:\n            future_set_exc_info(future, sys.exc_info())\n            try:\n                return future\n            finally:\n                # Avoid circular references\n                future = None  # type: ignore\n        else:\n            if isinstance(result, Generator):\n                # Inline the first iteration of Runner.run.  This lets us\n                # avoid the cost of creating a Runner when the coroutine\n                # never actually yields, which in turn allows us to\n                # use \"optional\" coroutines in critical path code without\n                # performance penalty for the synchronous case.\n                try:\n                    yielded = ctx_run(next, result)\n                except (StopIteration, Return) as e:\n                    future_set_result_unless_cancelled(\n                        future, _value_from_stopiteration(e)\n                    )\n                except Exception:\n                    future_set_exc_info(future, sys.exc_info())\n                else:\n                    # Provide strong references to Runner objects as long\n                    # as their result future objects also have strong\n                    # references (typically from the parent coroutine's\n                    # Runner). This keeps the coroutine's Runner alive.\n                    # We do this by exploiting the public API\n                    # add_done_callback() instead of putting a private\n                    # attribute on the Future.\n                    # (GitHub issues #1769, #2229).\n                    runner = Runner(ctx_run, result, future, yielded)\n                    future.add_done_callback(lambda _: runner)\n                yielded = None\n                try:\n                    return future\n                finally:\n                    # Subtle memory optimization: if next() raised an exception,\n                    # the future's exc_info contains a traceback which\n                    # includes this stack frame.  This creates a cycle,\n                    # which will be collected at the next full GC but has\n                    # been shown to greatly increase memory usage of\n                    # benchmarks (relative to the refcount-based scheme\n                    # used in the absence of cycles).  We can avoid the\n                    # cycle by clearing the local variable after we return it.\n                    future = None  # type: ignore\n        future_set_result_unless_cancelled(future, result)\n        return future",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 61,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(self, *args: Future, **kwargs: Future) -> None:\n        if args and kwargs:\n            raise ValueError(\"You must provide args or kwargs, not both\")\n\n        if kwargs:\n            self._unfinished = {f: k for (k, f) in kwargs.items()}\n            futures = list(kwargs.values())  # type: Sequence[Future]\n        else:\n            self._unfinished = {f: i for (i, f) in enumerate(args)}\n            futures = args\n\n        self._finished = collections.deque()  # type: Deque[Future]\n        self.current_index = None  # type: Optional[Union[str, int]]\n        self.current_future = None  # type: Optional[Future]\n        self._running_future = None  # type: Optional[Future]\n\n        for future in futures:\n            future_add_done_callback(future, self._done_callback)",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 17,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "next",
      "sourceCode": "def next(self) -> Future:\n        \"\"\"Returns a `.Future` that will yield the next available result.\n\n        Note that this `.Future` will not be the same object as any of\n        the inputs.\n        \"\"\"\n        self._running_future = Future()\n\n        if self._finished:\n            return self._return_result(self._finished.popleft())\n\n        return self._running_future",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "_return_result",
      "sourceCode": "def _return_result(self, done: Future) -> Future:\n        \"\"\"Called set the returned future's state that of the future\n        we yielded, and set the current future for the iterator.\n        \"\"\"\n        if self._running_future is None:\n            raise Exception(\"no future is running\")\n        chain_future(done, self._running_future)\n\n        res = self._running_future\n        self._running_future = None\n        self.current_future = done\n        self.current_index = self._unfinished.pop(done)\n\n        return res",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "multi",
      "sourceCode": "def multi(\n    children: Union[Sequence[_Yieldable], Mapping[Any, _Yieldable]],\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> \"Union[Future[List], Future[Dict]]\":\n    \"\"\"Runs multiple asynchronous operations in parallel.\n\n    ``children`` may either be a list or a dict whose values are\n    yieldable objects. ``multi()`` returns a new yieldable\n    object that resolves to a parallel structure containing their\n    results. If ``children`` is a list, the result is a list of\n    results in the same order; if it is a dict, the result is a dict\n    with the same keys.\n\n    That is, ``results = yield multi(list_of_futures)`` is equivalent\n    to::\n\n        results = []\n        for future in list_of_futures:\n            results.append(yield future)\n\n    If any children raise exceptions, ``multi()`` will raise the first\n    one. All others will be logged, unless they are of types\n    contained in the ``quiet_exceptions`` argument.\n\n    In a ``yield``-based coroutine, it is not normally necessary to\n    call this function directly, since the coroutine runner will\n    do it automatically when a list or dict is yielded. However,\n    it is necessary in ``await``-based coroutines, or to pass\n    the ``quiet_exceptions`` argument.\n\n    This function is available under the names ``multi()`` and ``Multi()``\n    for historical reasons.\n\n    Cancelling a `.Future` returned by ``multi()`` does not cancel its\n    children. `asyncio.gather` is similar to ``multi()``, but it does\n    cancel its children.\n\n    .. versionchanged:: 4.2\n       If multiple yieldables fail, any exceptions after the first\n       (which is raised) will be logged. Added the ``quiet_exceptions``\n       argument to suppress this logging for selected exception types.\n\n    .. versionchanged:: 4.3\n       Replaced the class ``Multi`` and the function ``multi_future``\n       with a unified function ``multi``. Added support for yieldables\n       other than ``YieldPoint`` and `.Future`.\n\n    \"\"\"\n    return multi_future(children, quiet_exceptions=quiet_exceptions)",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 48,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "multi_future",
      "sourceCode": "def multi_future(\n    children: Union[Sequence[_Yieldable], Mapping[Any, _Yieldable]],\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> \"Union[Future[List], Future[Dict]]\":\n    \"\"\"Wait for multiple asynchronous futures in parallel.\n\n    Since Tornado 6.0, this function is exactly the same as `multi`.\n\n    .. versionadded:: 4.0\n\n    .. versionchanged:: 4.2\n       If multiple ``Futures`` fail, any exceptions after the first (which is\n       raised) will be logged. Added the ``quiet_exceptions``\n       argument to suppress this logging for selected exception types.\n\n    .. deprecated:: 4.3\n       Use `multi` instead.\n    \"\"\"\n    if isinstance(children, dict):\n        keys = list(children.keys())  # type: Optional[List]\n        children_seq = children.values()  # type: Iterable\n    else:\n        keys = None\n        children_seq = children\n    children_futs = list(map(convert_yielded, children_seq))\n    assert all(is_future(i) or isinstance(i, _NullFuture) for i in children_futs)\n    unfinished_children = set(children_futs)\n\n    future = _create_future()\n    if not children_futs:\n        future_set_result_unless_cancelled(future, {} if keys is not None else [])\n\n    def callback(fut: Future) -> None:\n        unfinished_children.remove(fut)\n        if not unfinished_children:\n            result_list = []\n            for f in children_futs:\n                try:\n                    result_list.append(f.result())\n                except Exception as e:\n                    if future.done():\n                        if not isinstance(e, quiet_exceptions):\n                            app_log.error(\n                                \"Multiple exceptions in yield list\", exc_info=True\n                            )\n                    else:\n                        future_set_exc_info(future, sys.exc_info())\n            if not future.done():\n                if keys is not None:\n                    future_set_result_unless_cancelled(\n                        future, dict(zip(keys, result_list))\n                    )\n                else:\n                    future_set_result_unless_cancelled(future, result_list)\n\n    listening = set()  # type: Set[Future]\n    for f in children_futs:\n        if f not in listening:\n            listening.add(f)\n            future_add_done_callback(f, callback)\n    return future",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 60,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "callback",
      "sourceCode": "def callback(fut: Future) -> None:\n        unfinished_children.remove(fut)\n        if not unfinished_children:\n            result_list = []\n            for f in children_futs:\n                try:\n                    result_list.append(f.result())\n                except Exception as e:\n                    if future.done():\n                        if not isinstance(e, quiet_exceptions):\n                            app_log.error(\n                                \"Multiple exceptions in yield list\", exc_info=True\n                            )\n                    else:\n                        future_set_exc_info(future, sys.exc_info())\n            if not future.done():\n                if keys is not None:\n                    future_set_result_unless_cancelled(\n                        future, dict(zip(keys, result_list))\n                    )\n                else:\n                    future_set_result_unless_cancelled(future, result_list)",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "maybe_future",
      "sourceCode": "def maybe_future(x: Any) -> Future:\n    \"\"\"Converts ``x`` into a `.Future`.\n\n    If ``x`` is already a `.Future`, it is simply returned; otherwise\n    it is wrapped in a new `.Future`.  This is suitable for use as\n    ``result = yield gen.maybe_future(f())`` when you don't know whether\n    ``f()`` returns a `.Future` or not.\n\n    .. deprecated:: 4.3\n       This function only handles ``Futures``, not other yieldable objects.\n       Instead of `maybe_future`, check for the non-future result types\n       you expect (often just ``None``), and ``yield`` anything unknown.\n    \"\"\"\n    if is_future(x):\n        return x\n    else:\n        fut = _create_future()\n        fut.set_result(x)\n        return fut",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 18,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "with_timeout",
      "sourceCode": "def with_timeout(\n    timeout: Union[float, datetime.timedelta],\n    future: _Yieldable,\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> Future:\n    \"\"\"Wraps a `.Future` (or other yieldable object) in a timeout.\n\n    Raises `tornado.util.TimeoutError` if the input future does not\n    complete before ``timeout``, which may be specified in any form\n    allowed by `.IOLoop.add_timeout` (i.e. a `datetime.timedelta` or\n    an absolute time relative to `.IOLoop.time`)\n\n    If the wrapped `.Future` fails after it has timed out, the exception\n    will be logged unless it is either of a type contained in\n    ``quiet_exceptions`` (which may be an exception type or a sequence of\n    types), or an ``asyncio.CancelledError``.\n\n    The wrapped `.Future` is not canceled when the timeout expires,\n    permitting it to be reused. `asyncio.wait_for` is similar to this\n    function but it does cancel the wrapped `.Future` on timeout.\n\n    .. versionadded:: 4.0\n\n    .. versionchanged:: 4.1\n       Added the ``quiet_exceptions`` argument and the logging of unhandled\n       exceptions.\n\n    .. versionchanged:: 4.4\n       Added support for yieldable objects other than `.Future`.\n\n    .. versionchanged:: 6.0.3\n       ``asyncio.CancelledError`` is now always considered \"quiet\".\n\n    .. versionchanged:: 6.2\n       ``tornado.util.TimeoutError`` is now an alias to ``asyncio.TimeoutError``.\n\n    \"\"\"\n    # It's tempting to optimize this by cancelling the input future on timeout\n    # instead of creating a new one, but A) we can't know if we are the only\n    # one waiting on the input future, so cancelling it might disrupt other\n    # callers and B) concurrent futures can only be cancelled while they are\n    # in the queue, so cancellation cannot reliably bound our waiting time.\n    future_converted = convert_yielded(future)\n    result = _create_future()\n    chain_future(future_converted, result)\n    io_loop = IOLoop.current()\n\n    def error_callback(future: Future) -> None:\n        try:\n            future.result()\n        except asyncio.CancelledError:\n            pass\n        except Exception as e:\n            if not isinstance(e, quiet_exceptions):\n                app_log.error(\n                    \"Exception in Future %r after timeout\", future, exc_info=True\n                )\n\n    def timeout_callback() -> None:\n        if not result.done():\n            result.set_exception(TimeoutError(\"Timeout\"))\n        # In case the wrapped future goes on to fail, log it.\n        future_add_done_callback(future_converted, error_callback)\n\n    timeout_handle = io_loop.add_timeout(timeout, timeout_callback)\n    if isinstance(future_converted, Future):\n        # We know this future will resolve on the IOLoop, so we don't\n        # need the extra thread-safety of IOLoop.add_future (and we also\n        # don't care about StackContext here.\n        future_add_done_callback(\n            future_converted, lambda future: io_loop.remove_timeout(timeout_handle)\n        )\n    else:\n        # concurrent.futures.Futures may resolve on any thread, so we\n        # need to route them back to the IOLoop.\n        io_loop.add_future(\n            future_converted, lambda future: io_loop.remove_timeout(timeout_handle)\n        )\n    return result",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 78,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "sleep",
      "sourceCode": "def sleep(duration: float) -> \"Future[None]\":\n    \"\"\"Return a `.Future` that resolves after the given number of seconds.\n\n    When used with ``yield`` in a coroutine, this is a non-blocking\n    analogue to `time.sleep` (which should not be used in coroutines\n    because it is blocking)::\n\n        yield gen.sleep(0.5)\n\n    Note that calling this function on its own does nothing; you must\n    wait on the `.Future` it returns (usually by yielding it).\n\n    .. versionadded:: 4.1\n    \"\"\"\n    f = _create_future()\n    IOLoop.current().call_later(\n        duration, lambda: future_set_result_unless_cancelled(f, None)\n    )\n    return f",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 18,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        ctx_run: Callable,\n        gen: \"Generator[_Yieldable, Any, _T]\",\n        result_future: \"Future[_T]\",\n        first_yielded: _Yieldable,\n    ) -> None:\n        self.ctx_run = ctx_run\n        self.gen = gen\n        self.result_future = result_future\n        self.future = _null_future  # type: Union[None, Future]\n        self.running = False\n        self.finished = False\n        self.io_loop = IOLoop.current()\n        if self.ctx_run(self.handle_yield, first_yielded):\n            gen = result_future = first_yielded = None  # type: ignore\n            self.ctx_run(self.run)",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "run",
      "sourceCode": "def run(self) -> None:\n        \"\"\"Starts or resumes the generator, running until it reaches a\n        yield point that is not ready.\n        \"\"\"\n        if self.running or self.finished:\n            return\n        try:\n            self.running = True\n            while True:\n                future = self.future\n                if future is None:\n                    raise Exception(\"No pending future\")\n                if not future.done():\n                    return\n                self.future = None\n                try:\n                    try:\n                        value = future.result()\n                    except Exception as e:\n                        # Save the exception for later. It's important that\n                        # gen.throw() not be called inside this try/except block\n                        # because that makes sys.exc_info behave unexpectedly.\n                        exc: Optional[Exception] = e\n                    else:\n                        exc = None\n                    finally:\n                        future = None\n\n                    if exc is not None:\n                        try:\n                            yielded = self.gen.throw(exc)\n                        finally:\n                            # Break up a circular reference for faster GC on\n                            # CPython.\n                            del exc\n                    else:\n                        yielded = self.gen.send(value)\n\n                except (StopIteration, Return) as e:\n                    self.finished = True\n                    self.future = _null_future\n                    future_set_result_unless_cancelled(\n                        self.result_future, _value_from_stopiteration(e)\n                    )\n                    self.result_future = None  # type: ignore\n                    return\n                except Exception:\n                    self.finished = True\n                    self.future = _null_future\n                    future_set_exc_info(self.result_future, sys.exc_info())\n                    self.result_future = None  # type: ignore\n                    return\n                if not self.handle_yield(yielded):\n                    return\n                yielded = None\n        finally:\n            self.running = False",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 56,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "handle_yield",
      "sourceCode": "def handle_yield(self, yielded: _Yieldable) -> bool:\n        try:\n            self.future = convert_yielded(yielded)\n        except BadYieldError:\n            self.future = Future()\n            future_set_exc_info(self.future, sys.exc_info())\n\n        if self.future is moment:\n            self.io_loop.add_callback(self.ctx_run, self.run)\n            return False\n        elif self.future is None:\n            raise Exception(\"no pending future\")\n        elif not self.future.done():\n\n            def inner(f: Any) -> None:\n                # Break a reference cycle to speed GC.\n                f = None  # noqa: F841\n                self.ctx_run(self.run)\n\n            self.io_loop.add_future(self.future, inner)\n            return False\n        return True",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "_wrap_awaitable",
      "sourceCode": "def _wrap_awaitable(awaitable: Awaitable) -> Future:\n    # Convert Awaitables into Futures.\n    # Note that we use ensure_future, which handles both awaitables\n    # and coroutines, rather than create_task, which only accepts\n    # coroutines. (ensure_future calls create_task if given a coroutine)\n    fut = asyncio.ensure_future(awaitable)\n    # See comments on IOLoop._pending_tasks.\n    loop = IOLoop.current()\n    loop._register_task(fut)\n    fut.add_done_callback(lambda f: loop._unregister_task(f))\n    return fut",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "convert_yielded",
      "sourceCode": "def convert_yielded(yielded: _Yieldable) -> Future:\n    \"\"\"Convert a yielded object into a `.Future`.\n\n    The default implementation accepts lists, dictionaries, and\n    Futures. This has the side effect of starting any coroutines that\n    did not start themselves, similar to `asyncio.ensure_future`.\n\n    If the `~functools.singledispatch` library is available, this function\n    may be extended to support additional types. For example::\n\n        @convert_yielded.register(asyncio.Future)\n        def _(asyncio_future):\n            return tornado.platform.asyncio.to_tornado_future(asyncio_future)\n\n    .. versionadded:: 4.1\n\n    \"\"\"\n    if yielded is None or yielded is moment:\n        return moment\n    elif yielded is _null_future:\n        return _null_future\n    elif isinstance(yielded, (list, dict)):\n        return multi(yielded)  # type: ignore\n    elif is_future(yielded):\n        return typing.cast(Future, yielded)\n    elif isawaitable(yielded):\n        return _wrap_awaitable(yielded)  # type: ignore\n    else:\n        raise BadYieldError(f\"yielded unknown object {yielded!r}\")",
      "importString": "import builtins\nimport collections\nfrom collections.abc import Generator\nimport concurrent.futures\nimport datetime\nimport functools\nfrom functools import singledispatch\nfrom inspect import isawaitable\nimport sys\nimport types\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import app_log\nfrom tornado.util import TimeoutError\nimport typing\nfrom typing import (\nMapping\nUnion\nAny\nCallable\nList\nType\nTuple\nAwaitable\nDict\nSequence\noverload\n)",
      "lineNum": 28,
      "relativeDocumentPath": "tornado/gen.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        no_keep_alive: bool = False,\n        chunk_size: Optional[int] = None,\n        max_header_size: Optional[int] = None,\n        header_timeout: Optional[float] = None,\n        max_body_size: Optional[int] = None,\n        body_timeout: Optional[float] = None,\n        decompress: bool = False,\n    ) -> None:\n        \"\"\"\n        :arg bool no_keep_alive: If true, always close the connection after\n            one request.\n        :arg int chunk_size: how much data to read into memory at once\n        :arg int max_header_size:  maximum amount of data for HTTP headers\n        :arg float header_timeout: how long to wait for all headers (seconds)\n        :arg int max_body_size: maximum amount of data for body\n        :arg float body_timeout: how long to wait while reading body (seconds)\n        :arg bool decompress: if true, decode incoming\n            ``Content-Encoding: gzip``\n        \"\"\"\n        self.no_keep_alive = no_keep_alive\n        self.chunk_size = chunk_size or 65536\n        self.max_header_size = max_header_size or 65536\n        self.header_timeout = header_timeout\n        self.max_body_size = max_body_size\n        self.body_timeout = body_timeout\n        self.decompress = decompress",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 27,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        stream: iostream.IOStream,\n        is_client: bool,\n        params: Optional[HTTP1ConnectionParameters] = None,\n        context: Optional[object] = None,\n    ) -> None:\n        \"\"\"\n        :arg stream: an `.IOStream`\n        :arg bool is_client: client or server\n        :arg params: a `.HTTP1ConnectionParameters` instance or ``None``\n        :arg context: an opaque application-defined object that can be accessed\n            as ``connection.context``.\n        \"\"\"\n        self.is_client = is_client\n        self.stream = stream\n        if params is None:\n            params = HTTP1ConnectionParameters()\n        self.params = params\n        self.context = context\n        self.no_keep_alive = params.no_keep_alive\n        # The body limits can be altered by the delegate, so save them\n        # here instead of just referencing self.params later.\n        self._max_body_size = (\n            self.params.max_body_size\n            if self.params.max_body_size is not None\n            else self.stream.max_buffer_size\n        )\n        self._body_timeout = self.params.body_timeout\n        # _write_finished is set to True when finish() has been called,\n        # i.e. there will be no more data sent.  Data may still be in the\n        # stream's write buffer.\n        self._write_finished = False\n        # True when we have read the entire incoming body.\n        self._read_finished = False\n        # _finish_future resolves when all data has been written and flushed\n        # to the IOStream.\n        self._finish_future = Future()  # type: Future[None]\n        # If true, the connection should be closed after this request\n        # (after the response has been written in the server side,\n        # and after it has been read in the client)\n        self._disconnect_on_finish = False\n        self._clear_callbacks()\n        # Save the start lines after we read or write them; they\n        # affect later processing (e.g. 304 responses and HEAD methods\n        # have content-length but no bodies)\n        self._request_start_line = None  # type: Optional[httputil.RequestStartLine]\n        self._response_start_line = None  # type: Optional[httputil.ResponseStartLine]\n        self._request_headers = None  # type: Optional[httputil.HTTPHeaders]\n        # True if we are writing output with chunked encoding.\n        self._chunking_output = False\n        # While reading a body with a content-length, this is the\n        # amount left to read.\n        self._expected_content_remaining = None  # type: Optional[int]\n        # A Future for our outgoing writes, returned by IOStream.write.\n        self._pending_write = None  # type: Optional[Future[None]]",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 55,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "read_response",
      "sourceCode": "def read_response(self, delegate: httputil.HTTPMessageDelegate) -> Awaitable[bool]:\n        \"\"\"Read a single HTTP response.\n\n        Typical client-mode usage is to write a request using `write_headers`,\n        `write`, and `finish`, and then call ``read_response``.\n\n        :arg delegate: a `.HTTPMessageDelegate`\n\n        Returns a `.Future` that resolves to a bool after the full response has\n        been read. The result is true if the stream is still open.\n        \"\"\"\n        if self.params.decompress:\n            delegate = _GzipMessageDelegate(delegate, self.params.chunk_size)\n        return self._read_message(delegate)",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "_read_message",
      "sourceCode": "async def _read_message(self, delegate: httputil.HTTPMessageDelegate) -> bool:\n        need_delegate_close = False\n        try:\n            header_future = self.stream.read_until_regex(\n                b\"\\r?\\n\\r?\\n\", max_bytes=self.params.max_header_size\n            )\n            if self.params.header_timeout is None:\n                header_data = await header_future\n            else:\n                try:\n                    header_data = await gen.with_timeout(\n                        self.stream.io_loop.time() + self.params.header_timeout,\n                        header_future,\n                        quiet_exceptions=iostream.StreamClosedError,\n                    )\n                except gen.TimeoutError:\n                    self.close()\n                    return False\n            start_line_str, headers = self._parse_headers(header_data)\n            if self.is_client:\n                resp_start_line = httputil.parse_response_start_line(start_line_str)\n                self._response_start_line = resp_start_line\n                start_line = (\n                    resp_start_line\n                )  # type: Union[httputil.RequestStartLine, httputil.ResponseStartLine]\n                # TODO: this will need to change to support client-side keepalive\n                self._disconnect_on_finish = False\n            else:\n                req_start_line = httputil.parse_request_start_line(start_line_str)\n                self._request_start_line = req_start_line\n                self._request_headers = headers\n                start_line = req_start_line\n                self._disconnect_on_finish = not self._can_keep_alive(\n                    req_start_line, headers\n                )\n            need_delegate_close = True\n            with _ExceptionLoggingContext(app_log):\n                header_recv_future = delegate.headers_received(start_line, headers)\n                if header_recv_future is not None:\n                    await header_recv_future\n            if self.stream is None:\n                # We've been detached.\n                need_delegate_close = False\n                return False\n            skip_body = False\n            if self.is_client:\n                assert isinstance(start_line, httputil.ResponseStartLine)\n                if (\n                    self._request_start_line is not None\n                    and self._request_start_line.method == \"HEAD\"\n                ):\n                    skip_body = True\n                code = start_line.code\n                if code == 304:\n                    # 304 responses may include the content-length header\n                    # but do not actually have a body.\n                    # http://tools.ietf.org/html/rfc7230#section-3.3\n                    skip_body = True\n                if 100 <= code < 200:\n                    # 1xx responses should never indicate the presence of\n                    # a body.\n                    if \"Content-Length\" in headers or \"Transfer-Encoding\" in headers:\n                        raise httputil.HTTPInputError(\n                            \"Response code %d cannot have body\" % code\n                        )\n                    # TODO: client delegates will get headers_received twice\n                    # in the case of a 100-continue.  Document or change?\n                    await self._read_message(delegate)\n            else:\n                if headers.get(\"Expect\") == \"100-continue\" and not self._write_finished:\n                    self.stream.write(b\"HTTP/1.1 100 (Continue)\\r\\n\\r\\n\")\n            if not skip_body:\n                body_future = self._read_body(\n                    resp_start_line.code if self.is_client else 0, headers, delegate\n                )\n                if body_future is not None:\n                    if self._body_timeout is None:\n                        await body_future\n                    else:\n                        try:\n                            await gen.with_timeout(\n                                self.stream.io_loop.time() + self._body_timeout,\n                                body_future,\n                                quiet_exceptions=iostream.StreamClosedError,\n                            )\n                        except gen.TimeoutError:\n                            gen_log.info(\"Timeout reading body from %s\", self.context)\n                            self.stream.close()\n                            return False\n            self._read_finished = True\n            if not self._write_finished or self.is_client:\n                need_delegate_close = False\n                with _ExceptionLoggingContext(app_log):\n                    delegate.finish()\n            # If we're waiting for the application to produce an asynchronous\n            # response, and we're not detached, register a close callback\n            # on the stream (we didn't need one while we were reading)\n            if (\n                not self._finish_future.done()\n                and self.stream is not None\n                and not self.stream.closed()\n            ):\n                self.stream.set_close_callback(self._on_connection_close)\n                await self._finish_future\n            if self.is_client and self._disconnect_on_finish:\n                self.close()\n            if self.stream is None:\n                return False\n        except httputil.HTTPInputError as e:\n            gen_log.info(\"Malformed HTTP message from %s: %s\", self.context, e)\n            if not self.is_client:\n                await self.stream.write(b\"HTTP/1.1 400 Bad Request\\r\\n\\r\\n\")\n            self.close()\n            return False\n        finally:\n            if need_delegate_close:\n                with _ExceptionLoggingContext(app_log):\n                    delegate.on_connection_close()\n            header_future = None  # type: ignore\n            self._clear_callbacks()\n        return True",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 120,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "_clear_callbacks",
      "sourceCode": "def _clear_callbacks(self) -> None:\n        \"\"\"Clears the callback attributes.\n\n        This allows the request handler to be garbage collected more\n        quickly in CPython by breaking up reference cycles.\n        \"\"\"\n        self._write_callback = None\n        self._write_future = None  # type: Optional[Future[None]]\n        self._close_callback = None  # type: Optional[Callable[[], None]]\n        if self.stream is not None:\n            self.stream.set_close_callback(None)",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "set_close_callback",
      "sourceCode": "def set_close_callback(self, callback: Optional[Callable[[], None]]) -> None:\n        \"\"\"Sets a callback that will be run when the connection is closed.\n\n        Note that this callback is slightly different from\n        `.HTTPMessageDelegate.on_connection_close`: The\n        `.HTTPMessageDelegate` method is called when the connection is\n        closed while receiving a message. This callback is used when\n        there is not an active delegate (for example, on the server\n        side this callback is used if the client closes the connection\n        after sending its request but before receiving all the\n        response.\n        \"\"\"\n        self._close_callback = callback",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "_on_connection_close",
      "sourceCode": "def _on_connection_close(self) -> None:\n        # Note that this callback is only registered on the IOStream\n        # when we have finished reading the request and are waiting for\n        # the application to produce its response.\n        if self._close_callback is not None:\n            callback = self._close_callback\n            self._close_callback = None\n            callback()\n        if not self._finish_future.done():\n            future_set_result_unless_cancelled(self._finish_future, None)\n        self._clear_callbacks()",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "detach",
      "sourceCode": "def detach(self) -> iostream.IOStream:\n        \"\"\"Take control of the underlying stream.\n\n        Returns the underlying `.IOStream` object and stops all further\n        HTTP processing.  May only be called during\n        `.HTTPMessageDelegate.headers_received`.  Intended for implementing\n        protocols like websockets that tunnel over an HTTP handshake.\n        \"\"\"\n        self._clear_callbacks()\n        stream = self.stream\n        self.stream = None  # type: ignore\n        if not self._finish_future.done():\n            future_set_result_unless_cancelled(self._finish_future, None)\n        return stream",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "write_headers",
      "sourceCode": "def write_headers(\n        self,\n        start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n        headers: httputil.HTTPHeaders,\n        chunk: Optional[bytes] = None,\n    ) -> \"Future[None]\":\n        \"\"\"Implements `.HTTPConnection.write_headers`.\"\"\"\n        lines = []\n        if self.is_client:\n            assert isinstance(start_line, httputil.RequestStartLine)\n            self._request_start_line = start_line\n            lines.append(utf8(f\"{start_line[0]} {start_line[1]} HTTP/1.1\"))\n            # Client requests with a non-empty body must have either a\n            # Content-Length or a Transfer-Encoding. If Content-Length is not\n            # present we'll add our Transfer-Encoding below.\n            self._chunking_output = (\n                start_line.method in (\"POST\", \"PUT\", \"PATCH\")\n                and \"Content-Length\" not in headers\n            )\n        else:\n            assert isinstance(start_line, httputil.ResponseStartLine)\n            assert self._request_start_line is not None\n            assert self._request_headers is not None\n            self._response_start_line = start_line\n            lines.append(utf8(\"HTTP/1.1 %d %s\" % (start_line[1], start_line[2])))\n            self._chunking_output = (\n                # TODO: should this use\n                # self._request_start_line.version or\n                # start_line.version?\n                self._request_start_line.version == \"HTTP/1.1\"\n                # Omit payload header field for HEAD request.\n                and self._request_start_line.method != \"HEAD\"\n                # 1xx, 204 and 304 responses have no body (not even a zero-length\n                # body), and so should not have either Content-Length or\n                # Transfer-Encoding headers.\n                and start_line.code not in (204, 304)\n                and (start_line.code < 100 or start_line.code >= 200)\n                # No need to chunk the output if a Content-Length is specified.\n                and \"Content-Length\" not in headers\n            )\n            # If connection to a 1.1 client will be closed, inform client\n            if (\n                self._request_start_line.version == \"HTTP/1.1\"\n                and self._disconnect_on_finish\n            ):\n                headers[\"Connection\"] = \"close\"\n            # If a 1.0 client asked for keep-alive, add the header.\n            if (\n                self._request_start_line.version == \"HTTP/1.0\"\n                and self._request_headers.get(\"Connection\", \"\").lower() == \"keep-alive\"\n            ):\n                headers[\"Connection\"] = \"Keep-Alive\"\n        if self._chunking_output:\n            headers[\"Transfer-Encoding\"] = \"chunked\"\n        if not self.is_client and (\n            self._request_start_line.method == \"HEAD\"\n            or cast(httputil.ResponseStartLine, start_line).code == 304\n        ):\n            self._expected_content_remaining = 0\n        elif \"Content-Length\" in headers:\n            self._expected_content_remaining = parse_int(headers[\"Content-Length\"])\n        else:\n            self._expected_content_remaining = None\n        # TODO: headers are supposed to be of type str, but we still have some\n        # cases that let bytes slip through. Remove these native_str calls when those\n        # are fixed.\n        header_lines = (\n            native_str(n) + \": \" + native_str(v) for n, v in headers.get_all()\n        )\n        lines.extend(line.encode(\"latin1\") for line in header_lines)\n        for line in lines:\n            if CR_OR_LF_RE.search(line):\n                raise ValueError(\"Illegal characters (CR or LF) in header: %r\" % line)\n        future = None\n        if self.stream.closed():\n            future = self._write_future = Future()\n            future.set_exception(iostream.StreamClosedError())\n            future.exception()\n        else:\n            future = self._write_future = Future()\n            data = b\"\\r\\n\".join(lines) + b\"\\r\\n\\r\\n\"\n            if chunk:\n                data += self._format_chunk(chunk)\n            self._pending_write = self.stream.write(data)\n            future_add_done_callback(self._pending_write, self._on_write_complete)\n        return future",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 85,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "_format_chunk",
      "sourceCode": "def _format_chunk(self, chunk: bytes) -> bytes:\n        if self._expected_content_remaining is not None:\n            self._expected_content_remaining -= len(chunk)\n            if self._expected_content_remaining < 0:\n                # Close the stream now to stop further framing errors.\n                self.stream.close()\n                raise httputil.HTTPOutputError(\n                    \"Tried to write more data than Content-Length\"\n                )\n        if self._chunking_output and chunk:\n            # Don't write out empty chunks because that means END-OF-STREAM\n            # with chunked encoding\n            return utf8(\"%x\" % len(chunk)) + b\"\\r\\n\" + chunk + b\"\\r\\n\"\n        else:\n            return chunk",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "write",
      "sourceCode": "def write(self, chunk: bytes) -> \"Future[None]\":\n        \"\"\"Implements `.HTTPConnection.write`.\n\n        For backwards compatibility it is allowed but deprecated to\n        skip `write_headers` and instead call `write()` with a\n        pre-encoded header block.\n        \"\"\"\n        future = None\n        if self.stream.closed():\n            future = self._write_future = Future()\n            self._write_future.set_exception(iostream.StreamClosedError())\n            self._write_future.exception()\n        else:\n            future = self._write_future = Future()\n            self._pending_write = self.stream.write(self._format_chunk(chunk))\n            future_add_done_callback(self._pending_write, self._on_write_complete)\n        return future",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "finish",
      "sourceCode": "def finish(self) -> None:\n        \"\"\"Implements `.HTTPConnection.finish`.\"\"\"\n        if (\n            self._expected_content_remaining is not None\n            and self._expected_content_remaining != 0\n            and not self.stream.closed()\n        ):\n            self.stream.close()\n            raise httputil.HTTPOutputError(\n                \"Tried to write %d bytes less than Content-Length\"\n                % self._expected_content_remaining\n            )\n        if self._chunking_output:\n            if not self.stream.closed():\n                self._pending_write = self.stream.write(b\"0\\r\\n\\r\\n\")\n                self._pending_write.add_done_callback(self._on_write_complete)\n        self._write_finished = True\n        # If the app finished the request while we're still reading,\n        # divert any remaining data away from the delegate and\n        # close the connection when we're done sending our response.\n        # Closing the connection is the only way to avoid reading the\n        # whole input body.\n        if not self._read_finished:\n            self._disconnect_on_finish = True\n        # No more data is coming, so instruct TCP to send any remaining\n        # data immediately instead of waiting for a full packet or ack.\n        self.stream.set_nodelay(True)\n        if self._pending_write is None:\n            self._finish_request(None)\n        else:\n            future_add_done_callback(self._pending_write, self._finish_request)",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 30,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "_on_write_complete",
      "sourceCode": "def _on_write_complete(self, future: \"Future[None]\") -> None:\n        exc = future.exception()\n        if exc is not None and not isinstance(exc, iostream.StreamClosedError):\n            future.result()\n        if self._write_callback is not None:\n            callback = self._write_callback\n            self._write_callback = None\n            self.stream.io_loop.add_callback(callback)\n        if self._write_future is not None:\n            future = self._write_future\n            self._write_future = None\n            future_set_result_unless_cancelled(future, None)",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "_can_keep_alive",
      "sourceCode": "def _can_keep_alive(\n        self, start_line: httputil.RequestStartLine, headers: httputil.HTTPHeaders\n    ) -> bool:\n        if self.params.no_keep_alive:\n            return False\n        connection_header = headers.get(\"Connection\")\n        if connection_header is not None:\n            connection_header = connection_header.lower()\n        if start_line.version == \"HTTP/1.1\":\n            return connection_header != \"close\"\n        elif (\n            \"Content-Length\" in headers\n            or is_transfer_encoding_chunked(headers)\n            or getattr(start_line, \"method\", None) in (\"HEAD\", \"GET\")\n        ):\n            # start_line may be a request or response start line; only\n            # the former has a method attribute.\n            return connection_header == \"keep-alive\"\n        return False",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 18,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "_parse_headers",
      "sourceCode": "def _parse_headers(self, data: bytes) -> Tuple[str, httputil.HTTPHeaders]:\n        # The lstrip removes newlines that some implementations sometimes\n        # insert between messages of a reused connection.  Per RFC 7230,\n        # we SHOULD ignore at least one empty line before the request.\n        # http://tools.ietf.org/html/rfc7230#section-3.5\n        data_str = native_str(data.decode(\"latin1\")).lstrip(\"\\r\\n\")\n        # RFC 7230 section allows for both CRLF and bare LF.\n        eol = data_str.find(\"\\n\")\n        start_line = data_str[:eol].rstrip(\"\\r\")\n        headers = httputil.HTTPHeaders.parse(data_str[eol:])\n        return start_line, headers",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "_read_body",
      "sourceCode": "def _read_body(\n        self,\n        code: int,\n        headers: httputil.HTTPHeaders,\n        delegate: httputil.HTTPMessageDelegate,\n    ) -> Optional[Awaitable[None]]:\n        if \"Content-Length\" in headers:\n            if \",\" in headers[\"Content-Length\"]:\n                # Proxies sometimes cause Content-Length headers to get\n                # duplicated.  If all the values are identical then we can\n                # use them but if they differ it's an error.\n                pieces = re.split(r\",\\s*\", headers[\"Content-Length\"])\n                if any(i != pieces[0] for i in pieces):\n                    raise httputil.HTTPInputError(\n                        \"Multiple unequal Content-Lengths: %r\"\n                        % headers[\"Content-Length\"]\n                    )\n                headers[\"Content-Length\"] = pieces[0]\n\n            try:\n                content_length: Optional[int] = parse_int(headers[\"Content-Length\"])\n            except ValueError:\n                # Handles non-integer Content-Length value.\n                raise httputil.HTTPInputError(\n                    \"Only integer Content-Length is allowed: %s\"\n                    % headers[\"Content-Length\"]\n                )\n\n            if cast(int, content_length) > self._max_body_size:\n                raise httputil.HTTPInputError(\"Content-Length too long\")\n        else:\n            content_length = None\n\n        is_chunked = is_transfer_encoding_chunked(headers)\n\n        if code == 204:\n            # This response code is not allowed to have a non-empty body,\n            # and has an implicit length of zero instead of read-until-close.\n            # http://www.w3.org/Protocols/rfc2616/rfc2616-sec4.html#sec4.3\n            if is_chunked or content_length not in (None, 0):\n                raise httputil.HTTPInputError(\n                    \"Response with code %d should not have body\" % code\n                )\n            content_length = 0\n\n        if is_chunked:\n            return self._read_chunked_body(delegate)\n        if content_length is not None:\n            return self._read_fixed_body(content_length, delegate)\n        if self.is_client:\n            return self._read_body_until_close(delegate)\n        return None",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 51,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "_read_fixed_body",
      "sourceCode": "async def _read_fixed_body(\n        self, content_length: int, delegate: httputil.HTTPMessageDelegate\n    ) -> None:\n        while content_length > 0:\n            body = await self.stream.read_bytes(\n                min(self.params.chunk_size, content_length), partial=True\n            )\n            content_length -= len(body)\n            if not self._write_finished or self.is_client:\n                with _ExceptionLoggingContext(app_log):\n                    ret = delegate.data_received(body)\n                    if ret is not None:\n                        await ret",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "_read_chunked_body",
      "sourceCode": "async def _read_chunked_body(self, delegate: httputil.HTTPMessageDelegate) -> None:\n        # TODO: \"chunk extensions\" http://tools.ietf.org/html/rfc2616#section-3.6.1\n        total_size = 0\n        while True:\n            chunk_len_str = await self.stream.read_until(b\"\\r\\n\", max_bytes=64)\n            try:\n                chunk_len = parse_hex_int(native_str(chunk_len_str[:-2]))\n            except ValueError:\n                raise httputil.HTTPInputError(\"invalid chunk size\")\n            if chunk_len == 0:\n                crlf = await self.stream.read_bytes(2)\n                if crlf != b\"\\r\\n\":\n                    raise httputil.HTTPInputError(\n                        \"improperly terminated chunked request\"\n                    )\n                return\n            total_size += chunk_len\n            if total_size > self._max_body_size:\n                raise httputil.HTTPInputError(\"chunked body too large\")\n            bytes_to_read = chunk_len\n            while bytes_to_read:\n                chunk = await self.stream.read_bytes(\n                    min(bytes_to_read, self.params.chunk_size), partial=True\n                )\n                bytes_to_read -= len(chunk)\n                if not self._write_finished or self.is_client:\n                    with _ExceptionLoggingContext(app_log):\n                        ret = delegate.data_received(chunk)\n                        if ret is not None:\n                            await ret\n            # chunk ends with \\r\\n\n            crlf = await self.stream.read_bytes(2)\n            assert crlf == b\"\\r\\n\"",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 32,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "headers_received",
      "sourceCode": "def headers_received(\n        self,\n        start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n        headers: httputil.HTTPHeaders,\n    ) -> Optional[Awaitable[None]]:\n        if headers.get(\"Content-Encoding\", \"\").lower() == \"gzip\":\n            self._decompressor = GzipDecompressor()\n            # Downstream delegates will only see uncompressed data,\n            # so rename the content-encoding header.\n            # (but note that curl_httpclient doesn't do this).\n            headers.add(\"X-Consumed-Content-Encoding\", headers[\"Content-Encoding\"])\n            del headers[\"Content-Encoding\"]\n        return self._delegate.headers_received(start_line, headers)",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "data_received",
      "sourceCode": "async def data_received(self, chunk: bytes) -> None:\n        if self._decompressor:\n            compressed_data = chunk\n            while compressed_data:\n                decompressed = self._decompressor.decompress(\n                    compressed_data, self._chunk_size\n                )\n                if decompressed:\n                    ret = self._delegate.data_received(decompressed)\n                    if ret is not None:\n                        await ret\n                compressed_data = self._decompressor.unconsumed_tail\n                if compressed_data and not decompressed:\n                    raise httputil.HTTPInputError(\n                        \"encountered unconsumed gzip data without making progress\"\n                    )\n        else:\n            ret = self._delegate.data_received(chunk)\n            if ret is not None:\n                await ret",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 19,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "finish",
      "sourceCode": "def finish(self) -> None:\n        if self._decompressor is not None:\n            tail = self._decompressor.flush()\n            if tail:\n                # The tail should always be empty: decompress returned\n                # all that it can in data_received and the only\n                # purpose of the flush call is to detect errors such\n                # as truncated input. If we did legitimately get a new\n                # chunk at this point we'd need to change the\n                # interface to make finish() a coroutine.\n                raise ValueError(\n                    \"decompressor.flush returned data; possible truncated input\"\n                )\n        return self._delegate.finish()",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        stream: iostream.IOStream,\n        params: Optional[HTTP1ConnectionParameters] = None,\n        context: Optional[object] = None,\n    ) -> None:\n        \"\"\"\n        :arg stream: an `.IOStream`\n        :arg params: a `.HTTP1ConnectionParameters` or None\n        :arg context: an opaque application-defined object that is accessible\n            as ``connection.context``\n        \"\"\"\n        self.stream = stream\n        if params is None:\n            params = HTTP1ConnectionParameters()\n        self.params = params\n        self.context = context\n        self._serving_future = None  # type: Optional[Future[None]]",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 17,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "close",
      "sourceCode": "async def close(self) -> None:\n        \"\"\"Closes the connection.\n\n        Returns a `.Future` that resolves after the serving loop has exited.\n        \"\"\"\n        self.stream.close()\n        # Block until the serving loop is done, but ignore any exceptions\n        # (start_serving is already responsible for logging them).\n        assert self._serving_future is not None\n        try:\n            await self._serving_future\n        except Exception:\n            pass",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "_server_request_loop",
      "sourceCode": "async def _server_request_loop(\n        self, delegate: httputil.HTTPServerConnectionDelegate\n    ) -> None:\n        try:\n            while True:\n                conn = HTTP1Connection(self.stream, False, self.params, self.context)\n                request_delegate = delegate.start_request(self, conn)\n                try:\n                    ret = await conn.read_response(request_delegate)\n                except (\n                    iostream.StreamClosedError,\n                    iostream.UnsatisfiableReadError,\n                    asyncio.CancelledError,\n                ):\n                    return\n                except _QuietException:\n                    # This exception was already logged.\n                    conn.close()\n                    return\n                except Exception:\n                    gen_log.error(\"Uncaught exception\", exc_info=True)\n                    conn.close()\n                    return\n                if not ret:\n                    return\n                await asyncio.sleep(0)\n        finally:\n            delegate.on_close(self)",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 27,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "is_transfer_encoding_chunked",
      "sourceCode": "def is_transfer_encoding_chunked(headers: httputil.HTTPHeaders) -> bool:\n    \"\"\"Returns true if the headers specify Transfer-Encoding: chunked.\n\n    Raise httputil.HTTPInputError if any other transfer encoding is used.\n    \"\"\"\n    # Note that transfer-encoding is an area in which postel's law can lead\n    # us astray. If a proxy and a backend server are liberal in what they accept,\n    # but accept slightly different things, this can lead to mismatched framing\n    # and request smuggling issues. Therefore we are as strict as possible here\n    # (even technically going beyond the requirements of the RFCs: a value of\n    # \",chunked\" is legal but doesn't appear in practice for legitimate traffic)\n    if \"Transfer-Encoding\" not in headers:\n        return False\n    if \"Content-Length\" in headers:\n        # Message cannot contain both Content-Length and\n        # Transfer-Encoding headers.\n        # http://tools.ietf.org/html/rfc7230#section-3.3.3\n        raise httputil.HTTPInputError(\n            \"Message with both Transfer-Encoding and Content-Length\"\n        )\n    if headers[\"Transfer-Encoding\"].lower() == \"chunked\":\n        return True\n    # We do not support any transfer-encodings other than chunked, and we do not\n    # expect to add any support because the concept of transfer-encoding has\n    # been removed in HTTP/2.\n    raise httputil.HTTPInputError(\n        \"Unsupported Transfer-Encoding %s\" % headers[\"Transfer-Encoding\"]\n    )",
      "importString": "import logging\nimport re\nimport types\nfrom tornado.concurrent import (\nFuture\nfuture_add_done_callback\nfuture_set_result_unless_cancelled\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple",
      "lineNum": 27,
      "relativeDocumentPath": "tornado/http1connection.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        async_client_class: \"Optional[Type[AsyncHTTPClient]]\" = None,\n        **kwargs: Any,\n    ) -> None:\n        # Initialize self._closed at the beginning of the constructor\n        # so that an exception raised here doesn't lead to confusing\n        # failures in __del__.\n        self._closed = True\n        self._io_loop = IOLoop(make_current=False)\n        if async_client_class is None:\n            async_client_class = AsyncHTTPClient\n\n        # Create the client while our IOLoop is \"current\", without\n        # clobbering the thread's real current IOLoop (if any).\n        async def make_client() -> \"AsyncHTTPClient\":\n            await gen.sleep(0)\n            assert async_client_class is not None\n            return async_client_class(**kwargs)\n\n        self._async_client = self._io_loop.run_sync(make_client)\n        self._closed = False",
      "importString": "import datetime\nimport functools\nfrom io import BytesIO\nimport ssl\nimport time\nimport weakref\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado.escape import utf8, native_str\nfrom tornado import gen, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable\n\nfrom typing import Type, Any, Union, Dict, Callable, Optional, cast",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/httpclient.py"
    },
    {
      "symbolName": "fetch",
      "sourceCode": "def fetch(\n        self, request: Union[\"HTTPRequest\", str], **kwargs: Any\n    ) -> \"HTTPResponse\":\n        \"\"\"Executes a request, returning an `HTTPResponse`.\n\n        The request may be either a string URL or an `HTTPRequest` object.\n        If it is a string, we construct an `HTTPRequest` using any additional\n        kwargs: ``HTTPRequest(request, **kwargs)``\n\n        If an error occurs during the fetch, we raise an `HTTPError` unless\n        the ``raise_error`` keyword argument is set to False.\n        \"\"\"\n        response = self._io_loop.run_sync(\n            functools.partial(self._async_client.fetch, request, **kwargs)\n        )\n        return response",
      "importString": "import datetime\nimport functools\nfrom io import BytesIO\nimport ssl\nimport time\nimport weakref\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado.escape import utf8, native_str\nfrom tornado import gen, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable\n\nfrom typing import Type, Any, Union, Dict, Callable, Optional, cast",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/httpclient.py"
    },
    {
      "symbolName": "__new__",
      "sourceCode": "def __new__(cls, force_instance: bool = False, **kwargs: Any) -> \"AsyncHTTPClient\":\n        io_loop = IOLoop.current()\n        if force_instance:\n            instance_cache = None\n        else:\n            instance_cache = cls._async_clients()\n        if instance_cache is not None and io_loop in instance_cache:\n            return instance_cache[io_loop]\n        instance = super().__new__(cls, **kwargs)  # type: ignore\n        # Make sure the instance knows which cache to remove itself from.\n        # It can't simply call _async_clients() because we may be in\n        # __new__(AsyncHTTPClient) but instance.__class__ may be\n        # SimpleAsyncHTTPClient.\n        instance._instance_cache = instance_cache\n        if instance_cache is not None:\n            instance_cache[instance.io_loop] = instance\n        return instance",
      "importString": "import datetime\nimport functools\nfrom io import BytesIO\nimport ssl\nimport time\nimport weakref\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado.escape import utf8, native_str\nfrom tornado import gen, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable\n\nfrom typing import Type, Any, Union, Dict, Callable, Optional, cast",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/httpclient.py"
    },
    {
      "symbolName": "close",
      "sourceCode": "def close(self) -> None:\n        \"\"\"Destroys this HTTP client, freeing any file descriptors used.\n\n        This method is **not needed in normal use** due to the way\n        that `AsyncHTTPClient` objects are transparently reused.\n        ``close()`` is generally only necessary when either the\n        `.IOLoop` is also being closed, or the ``force_instance=True``\n        argument was used when creating the `AsyncHTTPClient`.\n\n        No other methods may be called on the `AsyncHTTPClient` after\n        ``close()``.\n\n        \"\"\"\n        if self._closed:\n            return\n        self._closed = True\n        if self._instance_cache is not None:\n            cached_val = self._instance_cache.pop(self.io_loop, None)\n            # If there's an object other than self in the instance\n            # cache for our IOLoop, something has gotten mixed up. A\n            # value of None appears to be possible when this is called\n            # from a destructor (HTTPClient.__del__) as the weakref\n            # gets cleared before the destructor runs.\n            if cached_val is not None and cached_val is not self:\n                raise RuntimeError(\"inconsistent AsyncHTTPClient cache\")",
      "importString": "import datetime\nimport functools\nfrom io import BytesIO\nimport ssl\nimport time\nimport weakref\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado.escape import utf8, native_str\nfrom tornado import gen, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable\n\nfrom typing import Type, Any, Union, Dict, Callable, Optional, cast",
      "lineNum": 24,
      "relativeDocumentPath": "tornado/httpclient.py"
    },
    {
      "symbolName": "fetch",
      "sourceCode": "def fetch(\n        self,\n        request: Union[str, \"HTTPRequest\"],\n        raise_error: bool = True,\n        **kwargs: Any,\n    ) -> \"Future[HTTPResponse]\":\n        \"\"\"Executes a request, asynchronously returning an `HTTPResponse`.\n\n        The request may be either a string URL or an `HTTPRequest` object.\n        If it is a string, we construct an `HTTPRequest` using any additional\n        kwargs: ``HTTPRequest(request, **kwargs)``\n\n        This method returns a `.Future` whose result is an\n        `HTTPResponse`. By default, the ``Future`` will raise an\n        `HTTPError` if the request returned a non-200 response code\n        (other errors may also be raised if the server could not be\n        contacted). Instead, if ``raise_error`` is set to False, the\n        response will always be returned regardless of the response\n        code.\n\n        If a ``callback`` is given, it will be invoked with the `HTTPResponse`.\n        In the callback interface, `HTTPError` is not automatically raised.\n        Instead, you must check the response's ``error`` attribute or\n        call its `~HTTPResponse.rethrow` method.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           `.Future` instead.\n\n           The ``raise_error=False`` argument only affects the\n           `HTTPError` raised when a non-200 response code is used,\n           instead of suppressing all errors.\n        \"\"\"\n        if self._closed:\n            raise RuntimeError(\"fetch() called on closed AsyncHTTPClient\")\n        if not isinstance(request, HTTPRequest):\n            request = HTTPRequest(url=request, **kwargs)\n        else:\n            if kwargs:\n                raise ValueError(\n                    \"kwargs can't be used if request is an HTTPRequest object\"\n                )\n        # We may modify this (to add Host, Accept-Encoding, etc),\n        # so make sure we don't modify the caller's object.  This is also\n        # where normal dicts get converted to HTTPHeaders objects.\n        request.headers = httputil.HTTPHeaders(request.headers)\n        request_proxy = _RequestProxy(request, self.defaults)\n        future = Future()  # type: Future[HTTPResponse]\n\n        def handle_response(response: \"HTTPResponse\") -> None:\n            if response.error:\n                if raise_error or not response._error_is_response_code:\n                    future_set_exception_unless_cancelled(future, response.error)\n                    return\n            future_set_result_unless_cancelled(future, response)\n\n        self.fetch_impl(cast(HTTPRequest, request_proxy), handle_response)\n        return future",
      "importString": "import datetime\nimport functools\nfrom io import BytesIO\nimport ssl\nimport time\nimport weakref\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado.escape import utf8, native_str\nfrom tornado import gen, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable\n\nfrom typing import Type, Any, Union, Dict, Callable, Optional, cast",
      "lineNum": 58,
      "relativeDocumentPath": "tornado/httpclient.py"
    },
    {
      "symbolName": "configure",
      "sourceCode": "@classmethod\n    def configure(\n        cls, impl: \"Union[None, str, Type[Configurable]]\", **kwargs: Any\n    ) -> None:\n        \"\"\"Configures the `AsyncHTTPClient` subclass to use.\n\n        ``AsyncHTTPClient()`` actually creates an instance of a subclass.\n        This method may be called with either a class object or the\n        fully-qualified name of such a class (or ``None`` to use the default,\n        ``SimpleAsyncHTTPClient``)\n\n        If additional keyword arguments are given, they will be passed\n        to the constructor of each subclass instance created.  The\n        keyword argument ``max_clients`` determines the maximum number\n        of simultaneous `~AsyncHTTPClient.fetch()` operations that can\n        execute in parallel on each `.IOLoop`.  Additional arguments\n        may be supported depending on the implementation class in use.\n\n        Example::\n\n           AsyncHTTPClient.configure(\"tornado.curl_httpclient.CurlAsyncHTTPClient\")\n        \"\"\"\n        super().configure(impl, **kwargs)",
      "importString": "import datetime\nimport functools\nfrom io import BytesIO\nimport ssl\nimport time\nimport weakref\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado.escape import utf8, native_str\nfrom tornado import gen, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable\n\nfrom typing import Type, Any, Union, Dict, Callable, Optional, cast",
      "lineNum": 22,
      "relativeDocumentPath": "tornado/httpclient.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        url: str,\n        method: str = \"GET\",\n        headers: Optional[Union[Dict[str, str], httputil.HTTPHeaders]] = None,\n        body: Optional[Union[bytes, str]] = None,\n        auth_username: Optional[str] = None,\n        auth_password: Optional[str] = None,\n        auth_mode: Optional[str] = None,\n        connect_timeout: Optional[float] = None,\n        request_timeout: Optional[float] = None,\n        if_modified_since: Optional[Union[float, datetime.datetime]] = None,\n        follow_redirects: Optional[bool] = None,\n        max_redirects: Optional[int] = None,\n        user_agent: Optional[str] = None,\n        use_gzip: Optional[bool] = None,\n        network_interface: Optional[str] = None,\n        streaming_callback: Optional[Callable[[bytes], None]] = None,\n        header_callback: Optional[Callable[[str], None]] = None,\n        prepare_curl_callback: Optional[Callable[[Any], None]] = None,\n        proxy_host: Optional[str] = None,\n        proxy_port: Optional[int] = None,\n        proxy_username: Optional[str] = None,\n        proxy_password: Optional[str] = None,\n        proxy_auth_mode: Optional[str] = None,\n        allow_nonstandard_methods: Optional[bool] = None,\n        validate_cert: Optional[bool] = None,\n        ca_certs: Optional[str] = None,\n        allow_ipv6: Optional[bool] = None,\n        client_key: Optional[str] = None,\n        client_cert: Optional[str] = None,\n        body_producer: Optional[\n            Callable[[Callable[[bytes], None]], \"Future[None]\"]\n        ] = None,\n        expect_100_continue: bool = False,\n        decompress_response: Optional[bool] = None,\n        ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n    ) -> None:\n        r\"\"\"All parameters except ``url`` are optional.\n\n        :arg str url: URL to fetch\n        :arg str method: HTTP method, e.g. \"GET\" or \"POST\"\n        :arg headers: Additional HTTP headers to pass on the request\n        :type headers: `~tornado.httputil.HTTPHeaders` or `dict`\n        :arg body: HTTP request body as a string (byte or unicode; if unicode\n           the utf-8 encoding will be used)\n        :type body: `str` or `bytes`\n        :arg collections.abc.Callable body_producer: Callable used for\n           lazy/asynchronous request bodies.\n           It is called with one argument, a ``write`` function, and should\n           return a `.Future`.  It should call the write function with new\n           data as it becomes available.  The write function returns a\n           `.Future` which can be used for flow control.\n           Only one of ``body`` and ``body_producer`` may\n           be specified.  ``body_producer`` is not supported on\n           ``curl_httpclient``.  When using ``body_producer`` it is recommended\n           to pass a ``Content-Length`` in the headers as otherwise chunked\n           encoding will be used, and many servers do not support chunked\n           encoding on requests.  New in Tornado 4.0\n        :arg str auth_username: Username for HTTP authentication\n        :arg str auth_password: Password for HTTP authentication\n        :arg str auth_mode: Authentication mode; default is \"basic\".\n           Allowed values are implementation-defined; ``curl_httpclient``\n           supports \"basic\" and \"digest\"; ``simple_httpclient`` only supports\n           \"basic\"\n        :arg float connect_timeout: Timeout for initial connection in seconds,\n           default 20 seconds (0 means no timeout)\n        :arg float request_timeout: Timeout for entire request in seconds,\n           default 20 seconds (0 means no timeout)\n        :arg if_modified_since: Timestamp for ``If-Modified-Since`` header\n        :type if_modified_since: `datetime` or `float`\n        :arg bool follow_redirects: Should redirects be followed automatically\n           or return the 3xx response? Default True.\n        :arg int max_redirects: Limit for ``follow_redirects``, default 5.\n        :arg str user_agent: String to send as ``User-Agent`` header\n        :arg bool decompress_response: Request a compressed response from\n           the server and decompress it after downloading.  Default is True.\n           New in Tornado 4.0.\n        :arg bool use_gzip: Deprecated alias for ``decompress_response``\n           since Tornado 4.0.\n        :arg str network_interface: Network interface or source IP to use for request.\n           See ``curl_httpclient`` note below.\n        :arg collections.abc.Callable streaming_callback: If set, ``streaming_callback`` will\n           be run with each chunk of data as it is received, and\n           ``HTTPResponse.body`` and ``HTTPResponse.buffer`` will be empty in\n           the final response.\n        :arg collections.abc.Callable header_callback: If set, ``header_callback`` will\n           be run with each header line as it is received (including the\n           first line, e.g. ``HTTP/1.0 200 OK\\r\\n``, and a final line\n           containing only ``\\r\\n``.  All lines include the trailing newline\n           characters).  ``HTTPResponse.headers`` will be empty in the final\n           response.  This is most useful in conjunction with\n           ``streaming_callback``, because it's the only way to get access to\n           header data while the request is in progress.\n        :arg collections.abc.Callable prepare_curl_callback: If set, will be called with\n           a ``pycurl.Curl`` object to allow the application to make additional\n           ``setopt`` calls.\n        :arg str proxy_host: HTTP proxy hostname.  To use proxies,\n           ``proxy_host`` and ``proxy_port`` must be set; ``proxy_username``,\n           ``proxy_pass`` and ``proxy_auth_mode`` are optional.  Proxies are\n           currently only supported with ``curl_httpclient``.\n        :arg int proxy_port: HTTP proxy port\n        :arg str proxy_username: HTTP proxy username\n        :arg str proxy_password: HTTP proxy password\n        :arg str proxy_auth_mode: HTTP proxy Authentication mode;\n           default is \"basic\". supports \"basic\" and \"digest\"\n        :arg bool allow_nonstandard_methods: Allow unknown values for ``method``\n           argument? Default is False.\n        :arg bool validate_cert: For HTTPS requests, validate the server's\n           certificate? Default is True.\n        :arg str ca_certs: filename of CA certificates in PEM format,\n           or None to use defaults.  See note below when used with\n           ``curl_httpclient``.\n        :arg str client_key: Filename for client SSL key, if any.  See\n           note below when used with ``curl_httpclient``.\n        :arg str client_cert: Filename for client SSL certificate, if any.\n           See note below when used with ``curl_httpclient``.\n        :arg ssl.SSLContext ssl_options: `ssl.SSLContext` object for use in\n           ``simple_httpclient`` (unsupported by ``curl_httpclient``).\n           Overrides ``validate_cert``, ``ca_certs``, ``client_key``,\n           and ``client_cert``.\n        :arg bool allow_ipv6: Use IPv6 when available?  Default is True.\n        :arg bool expect_100_continue: If true, send the\n           ``Expect: 100-continue`` header and wait for a continue response\n           before sending the request body.  Only supported with\n           ``simple_httpclient``.\n\n        .. note::\n\n            When using ``curl_httpclient`` certain options may be\n            inherited by subsequent fetches because ``pycurl`` does\n            not allow them to be cleanly reset.  This applies to the\n            ``ca_certs``, ``client_key``, ``client_cert``, and\n            ``network_interface`` arguments.  If you use these\n            options, you should pass them on every request (you don't\n            have to always use the same values, but it's not possible\n            to mix requests that specify these options with ones that\n            use the defaults).\n\n        .. versionadded:: 3.1\n           The ``auth_mode`` argument.\n\n        .. versionadded:: 4.0\n           The ``body_producer`` and ``expect_100_continue`` arguments.\n\n        .. versionadded:: 4.2\n           The ``ssl_options`` argument.\n\n        .. versionadded:: 4.5\n           The ``proxy_auth_mode`` argument.\n        \"\"\"\n        # Note that some of these attributes go through property setters\n        # defined below.\n        self.headers = headers  # type: ignore\n        if if_modified_since:\n            self.headers[\"If-Modified-Since\"] = httputil.format_timestamp(\n                if_modified_since\n            )\n        self.proxy_host = proxy_host\n        self.proxy_port = proxy_port\n        self.proxy_username = proxy_username\n        self.proxy_password = proxy_password\n        self.proxy_auth_mode = proxy_auth_mode\n        self.url = url\n        self.method = method\n        self.body = body  # type: ignore\n        self.body_producer = body_producer\n        self.auth_username = auth_username\n        self.auth_password = auth_password\n        self.auth_mode = auth_mode\n        self.connect_timeout = connect_timeout\n        self.request_timeout = request_timeout\n        self.follow_redirects = follow_redirects\n        self.max_redirects = max_redirects\n        self.user_agent = user_agent\n        if decompress_response is not None:\n            self.decompress_response = decompress_response  # type: Optional[bool]\n        else:\n            self.decompress_response = use_gzip\n        self.network_interface = network_interface\n        self.streaming_callback = streaming_callback\n        self.header_callback = header_callback\n        self.prepare_curl_callback = prepare_curl_callback\n        self.allow_nonstandard_methods = allow_nonstandard_methods\n        self.validate_cert = validate_cert\n        self.ca_certs = ca_certs\n        self.allow_ipv6 = allow_ipv6\n        self.client_key = client_key\n        self.client_cert = client_cert\n        self.ssl_options = ssl_options\n        self.expect_100_continue = expect_100_continue\n        self.start_time = time.time()",
      "importString": "import datetime\nimport functools\nfrom io import BytesIO\nimport ssl\nimport time\nimport weakref\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado.escape import utf8, native_str\nfrom tornado import gen, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable\n\nfrom typing import Type, Any, Union, Dict, Callable, Optional, cast",
      "lineNum": 191,
      "relativeDocumentPath": "tornado/httpclient.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        request: HTTPRequest,\n        code: int,\n        headers: Optional[httputil.HTTPHeaders] = None,\n        buffer: Optional[BytesIO] = None,\n        effective_url: Optional[str] = None,\n        error: Optional[BaseException] = None,\n        request_time: Optional[float] = None,\n        time_info: Optional[Dict[str, float]] = None,\n        reason: Optional[str] = None,\n        start_time: Optional[float] = None,\n    ) -> None:\n        if isinstance(request, _RequestProxy):\n            self.request = request.request\n        else:\n            self.request = request\n        self.code = code\n        self.reason = reason or httputil.responses.get(code, \"Unknown\")\n        if headers is not None:\n            self.headers = headers\n        else:\n            self.headers = httputil.HTTPHeaders()\n        self.buffer = buffer\n        self._body = None  # type: Optional[bytes]\n        if effective_url is None:\n            self.effective_url = request.url\n        else:\n            self.effective_url = effective_url\n        self._error_is_response_code = False\n        if error is None:\n            if self.code < 200 or self.code >= 300:\n                self._error_is_response_code = True\n                self.error = HTTPError(self.code, message=self.reason, response=self)\n            else:\n                self.error = None\n        else:\n            self.error = error\n        self.start_time = start_time\n        self.request_time = request_time\n        self.time_info = time_info or {}",
      "importString": "import datetime\nimport functools\nfrom io import BytesIO\nimport ssl\nimport time\nimport weakref\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado.escape import utf8, native_str\nfrom tornado import gen, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable\n\nfrom typing import Type, Any, Union, Dict, Callable, Optional, cast",
      "lineNum": 40,
      "relativeDocumentPath": "tornado/httpclient.py"
    },
    {
      "symbolName": "main",
      "sourceCode": "def main() -> None:\n    from tornado.options import define, options, parse_command_line\n\n    define(\"print_headers\", type=bool, default=False)\n    define(\"print_body\", type=bool, default=True)\n    define(\"follow_redirects\", type=bool, default=True)\n    define(\"validate_cert\", type=bool, default=True)\n    define(\"proxy_host\", type=str)\n    define(\"proxy_port\", type=int)\n    args = parse_command_line()\n    client = HTTPClient()\n    for arg in args:\n        try:\n            response = client.fetch(\n                arg,\n                follow_redirects=options.follow_redirects,\n                validate_cert=options.validate_cert,\n                proxy_host=options.proxy_host,\n                proxy_port=options.proxy_port,\n            )\n        except HTTPError as e:\n            if e.response is not None:\n                response = e.response\n            else:\n                raise\n        if options.print_headers:\n            print(response.headers)\n        if options.print_body:\n            print(native_str(response.body))\n    client.close()",
      "importString": "import datetime\nimport functools\nfrom io import BytesIO\nimport ssl\nimport time\nimport weakref\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado.escape import utf8, native_str\nfrom tornado import gen, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable\n\nfrom typing import Type, Any, Union, Dict, Callable, Optional, cast",
      "lineNum": 29,
      "relativeDocumentPath": "tornado/httpclient.py"
    },
    {
      "symbolName": "initialize",
      "sourceCode": "def initialize(\n        self,\n        request_callback: Union[\n            httputil.HTTPServerConnectionDelegate,\n            Callable[[httputil.HTTPServerRequest], None],\n        ],\n        no_keep_alive: bool = False,\n        xheaders: bool = False,\n        ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n        protocol: Optional[str] = None,\n        decompress_request: bool = False,\n        chunk_size: Optional[int] = None,\n        max_header_size: Optional[int] = None,\n        idle_connection_timeout: Optional[float] = None,\n        body_timeout: Optional[float] = None,\n        max_body_size: Optional[int] = None,\n        max_buffer_size: Optional[int] = None,\n        trusted_downstream: Optional[List[str]] = None,\n    ) -> None:\n        # This method's signature is not extracted with autodoc\n        # because we want its arguments to appear on the class\n        # constructor. When changing this signature, also update the\n        # copy in httpserver.rst.\n        self.request_callback = request_callback\n        self.xheaders = xheaders\n        self.protocol = protocol\n        self.conn_params = HTTP1ConnectionParameters(\n            decompress=decompress_request,\n            chunk_size=chunk_size,\n            max_header_size=max_header_size,\n            header_timeout=idle_connection_timeout or 3600,\n            max_body_size=max_body_size,\n            body_timeout=body_timeout,\n            no_keep_alive=no_keep_alive,\n        )\n        TCPServer.__init__(\n            self,\n            ssl_options=ssl_options,\n            max_buffer_size=max_buffer_size,\n            read_chunk_size=chunk_size,\n        )\n        self._connections = set()  # type: Set[HTTP1ServerConnection]\n        self.trusted_downstream = trusted_downstream",
      "importString": "import socket\nimport ssl\nfrom tornado.escape import native_str\nfrom tornado.http1connection import HTTP1ServerConnection, HTTP1ConnectionParameters\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado import netutil\nfrom tornado.tcpserver import TCPServer\nfrom tornado.util import Configurable\n\nimport typing\nfrom typing import Union, Any, Dict, Callable, List, Type, Tuple, Optional, Awaitable",
      "lineNum": 42,
      "relativeDocumentPath": "tornado/httpserver.py"
    },
    {
      "symbolName": "close_all_connections",
      "sourceCode": "async def close_all_connections(self) -> None:\n        \"\"\"Close all open connections and asynchronously wait for them to finish.\n\n        This method is used in combination with `~.TCPServer.stop` to\n        support clean shutdowns (especially for unittests). Typical\n        usage would call ``stop()`` first to stop accepting new\n        connections, then ``await close_all_connections()`` to wait for\n        existing connections to finish.\n\n        This method does not currently close open websocket connections.\n\n        Note that this method is a coroutine and must be called with ``await``.\n\n        \"\"\"\n        while self._connections:\n            # Peek at an arbitrary element of the set\n            conn = next(iter(self._connections))\n            await conn.close()",
      "importString": "import socket\nimport ssl\nfrom tornado.escape import native_str\nfrom tornado.http1connection import HTTP1ServerConnection, HTTP1ConnectionParameters\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado import netutil\nfrom tornado.tcpserver import TCPServer\nfrom tornado.util import Configurable\n\nimport typing\nfrom typing import Union, Any, Dict, Callable, List, Type, Tuple, Optional, Awaitable",
      "lineNum": 17,
      "relativeDocumentPath": "tornado/httpserver.py"
    },
    {
      "symbolName": "start_request",
      "sourceCode": "def start_request(\n        self, server_conn: object, request_conn: httputil.HTTPConnection\n    ) -> httputil.HTTPMessageDelegate:\n        if isinstance(self.request_callback, httputil.HTTPServerConnectionDelegate):\n            delegate = self.request_callback.start_request(server_conn, request_conn)\n        else:\n            delegate = _CallableAdapter(self.request_callback, request_conn)\n\n        if self.xheaders:\n            delegate = _ProxyAdapter(delegate, request_conn)\n\n        return delegate",
      "importString": "import socket\nimport ssl\nfrom tornado.escape import native_str\nfrom tornado.http1connection import HTTP1ServerConnection, HTTP1ConnectionParameters\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado import netutil\nfrom tornado.tcpserver import TCPServer\nfrom tornado.util import Configurable\n\nimport typing\nfrom typing import Union, Any, Dict, Callable, List, Type, Tuple, Optional, Awaitable",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/httpserver.py"
    },
    {
      "symbolName": "headers_received",
      "sourceCode": "def headers_received(\n        self,\n        start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n        headers: httputil.HTTPHeaders,\n    ) -> Optional[Awaitable[None]]:\n        self.request = httputil.HTTPServerRequest(\n            connection=self.connection,\n            start_line=typing.cast(httputil.RequestStartLine, start_line),\n            headers=headers,\n        )\n        return None",
      "importString": "import socket\nimport ssl\nfrom tornado.escape import native_str\nfrom tornado.http1connection import HTTP1ServerConnection, HTTP1ConnectionParameters\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado import netutil\nfrom tornado.tcpserver import TCPServer\nfrom tornado.util import Configurable\n\nimport typing\nfrom typing import Union, Any, Dict, Callable, List, Type, Tuple, Optional, Awaitable",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/httpserver.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        stream: iostream.IOStream,\n        address: Tuple,\n        protocol: Optional[str],\n        trusted_downstream: Optional[List[str]] = None,\n    ) -> None:\n        self.address = address\n        # Save the socket's address family now so we know how to\n        # interpret self.address even after the stream is closed\n        # and its socket attribute replaced with None.\n        if stream.socket is not None:\n            self.address_family = stream.socket.family\n        else:\n            self.address_family = None\n        # In HTTPServerRequest we want an IP, not a full socket address.\n        if (\n            self.address_family in (socket.AF_INET, socket.AF_INET6)\n            and address is not None\n        ):\n            self.remote_ip = address[0]\n        else:\n            # Unix (or other) socket; fake the remote address.\n            self.remote_ip = \"0.0.0.0\"\n        if protocol:\n            self.protocol = protocol\n        elif isinstance(stream, iostream.SSLIOStream):\n            self.protocol = \"https\"\n        else:\n            self.protocol = \"http\"\n        self._orig_remote_ip = self.remote_ip\n        self._orig_protocol = self.protocol\n        self.trusted_downstream = set(trusted_downstream or [])",
      "importString": "import socket\nimport ssl\nfrom tornado.escape import native_str\nfrom tornado.http1connection import HTTP1ServerConnection, HTTP1ConnectionParameters\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado import netutil\nfrom tornado.tcpserver import TCPServer\nfrom tornado.util import Configurable\n\nimport typing\nfrom typing import Union, Any, Dict, Callable, List, Type, Tuple, Optional, Awaitable",
      "lineNum": 32,
      "relativeDocumentPath": "tornado/httpserver.py"
    },
    {
      "symbolName": "_apply_xheaders",
      "sourceCode": "def _apply_xheaders(self, headers: httputil.HTTPHeaders) -> None:\n        \"\"\"Rewrite the ``remote_ip`` and ``protocol`` fields.\"\"\"\n        # Squid uses X-Forwarded-For, others use X-Real-Ip\n        ip = headers.get(\"X-Forwarded-For\", self.remote_ip)\n        # Skip trusted downstream hosts in X-Forwarded-For list\n        for ip in (cand.strip() for cand in reversed(ip.split(\",\"))):\n            if ip not in self.trusted_downstream:\n                break\n        ip = headers.get(\"X-Real-Ip\", ip)\n        if netutil.is_valid_ip(ip):\n            self.remote_ip = ip\n        # AWS uses X-Forwarded-Proto\n        proto_header = headers.get(\n            \"X-Scheme\", headers.get(\"X-Forwarded-Proto\", self.protocol)\n        )\n        if proto_header:\n            # use only the last proto entry if there is more than one\n            # TODO: support trusting multiple layers of proxied protocol\n            proto_header = proto_header.split(\",\")[-1].strip()\n        if proto_header in (\"http\", \"https\"):\n            self.protocol = proto_header",
      "importString": "import socket\nimport ssl\nfrom tornado.escape import native_str\nfrom tornado.http1connection import HTTP1ServerConnection, HTTP1ConnectionParameters\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado import netutil\nfrom tornado.tcpserver import TCPServer\nfrom tornado.util import Configurable\n\nimport typing\nfrom typing import Union, Any, Dict, Callable, List, Type, Tuple, Optional, Awaitable",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/httpserver.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(self, *args: typing.Any, **kwargs: str) -> None:  # noqa: F811\n        self._dict = {}  # type: typing.Dict[str, str]\n        self._as_list = {}  # type: typing.Dict[str, typing.List[str]]\n        self._last_key = None  # type: Optional[str]\n        if len(args) == 1 and len(kwargs) == 0 and isinstance(args[0], HTTPHeaders):\n            # Copy constructor\n            for k, v in args[0].get_all():\n                self.add(k, v)\n        else:\n            # Dict-style initialization\n            self.update(*args, **kwargs)",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "add",
      "sourceCode": "def add(self, name: str, value: str, *, _chars_are_bytes: bool = True) -> None:\n        \"\"\"Adds a new value for the given key.\"\"\"\n        if not _ABNF.field_name.fullmatch(name):\n            raise HTTPInputError(\"Invalid header name %r\" % name)\n        if _chars_are_bytes:\n            if not _ABNF.field_value.fullmatch(to_unicode(value)):\n                # TODO: the fact we still support bytes here (contrary to type annotations)\n                # and still test for it should probably be changed.\n                raise HTTPInputError(\"Invalid header value %r\" % value)\n        else:\n            if _FORBIDDEN_HEADER_CHARS_RE.search(value):\n                raise HTTPInputError(\"Invalid header value %r\" % value)\n        norm_name = _normalize_header(name)\n        self._last_key = norm_name\n        if norm_name in self:\n            self._dict[norm_name] = (\n                native_str(self[norm_name]) + \",\" + native_str(value)\n            )\n            self._as_list[norm_name].append(value)\n        else:\n            self[norm_name] = value",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "parse_line",
      "sourceCode": "def parse_line(self, line: str, *, _chars_are_bytes: bool = True) -> None:\n        r\"\"\"Updates the dictionary with a single header line.\n\n        >>> h = HTTPHeaders()\n        >>> h.parse_line(\"Content-Type: text/html\")\n        >>> h.get('content-type')\n        'text/html'\n        >>> h.parse_line(\"Content-Length: 42\\r\\n\")\n        >>> h.get('content-type')\n        'text/html'\n\n        .. versionchanged:: 6.5\n            Now supports lines with or without the trailing CRLF, making it possible\n            to pass lines from AsyncHTTPClient's header_callback directly to this method.\n\n        .. deprecated:: 6.5\n           In Tornado 7.0, certain deprecated features of HTTP will become errors.\n           Specifically, line folding and the use of LF (with CR) as a line separator\n           will be removed.\n        \"\"\"\n        if m := re.search(r\"\\r?\\n$\", line):\n            # RFC 9112 section 2.2: a recipient MAY recognize a single LF as a line\n            # terminator and ignore any preceding CR.\n            # TODO(7.0): Remove this support for LF-only line endings.\n            line = line[: m.start()]\n        if not line:\n            # Empty line, or the final CRLF of a header block.\n            return\n        if line[0] in HTTP_WHITESPACE:\n            # continuation of a multi-line header\n            # TODO(7.0): Remove support for line folding.\n            if self._last_key is None:\n                raise HTTPInputError(\"first header line cannot start with whitespace\")\n            new_part = \" \" + line.strip(HTTP_WHITESPACE)\n            if _chars_are_bytes:\n                if not _ABNF.field_value.fullmatch(new_part[1:]):\n                    raise HTTPInputError(\"Invalid header continuation %r\" % new_part)\n            else:\n                if _FORBIDDEN_HEADER_CHARS_RE.search(new_part):\n                    raise HTTPInputError(\"Invalid header value %r\" % new_part)\n            self._as_list[self._last_key][-1] += new_part\n            self._dict[self._last_key] += new_part\n        else:\n            try:\n                name, value = line.split(\":\", 1)\n            except ValueError:\n                raise HTTPInputError(\"no colon in header line\")\n            self.add(\n                name, value.strip(HTTP_WHITESPACE), _chars_are_bytes=_chars_are_bytes\n            )",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 49,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "parse",
      "sourceCode": "@classmethod\n    def parse(cls, headers: str, *, _chars_are_bytes: bool = True) -> \"HTTPHeaders\":\n        \"\"\"Returns a dictionary from HTTP header text.\n\n        >>> h = HTTPHeaders.parse(\"Content-Type: text/html\\\\r\\\\nContent-Length: 42\\\\r\\\\n\")\n        >>> sorted(h.items())\n        [('Content-Length', '42'), ('Content-Type', 'text/html')]\n\n        .. versionchanged:: 5.1\n\n           Raises `HTTPInputError` on malformed headers instead of a\n           mix of `KeyError`, and `ValueError`.\n\n        \"\"\"\n        # _chars_are_bytes is a hack. This method is used in two places, HTTP headers (in which\n        # non-ascii characters are to be interpreted as latin-1) and multipart/form-data (in which\n        # they are to be interpreted as utf-8). For historical reasons, this method handled this by\n        # expecting both callers to decode the headers to strings before parsing them. This wasn't a\n        # problem until we started doing stricter validation of the characters allowed in HTTP\n        # headers (using ABNF rules defined in terms of byte values), which inadvertently started\n        # disallowing non-latin1 characters in multipart/form-data filenames.\n        #\n        # This method should have accepted bytes and a desired encoding, but this change is being\n        # introduced in a patch release that shouldn't change the API. Instead, the _chars_are_bytes\n        # flag decides whether to use HTTP-style ABNF validation (treating the string as bytes\n        # smuggled through the latin1 encoding) or to accept any non-control unicode characters\n        # as required by multipart/form-data. This method will change to accept bytes in a future\n        # release.\n        h = cls()\n\n        start = 0\n        while True:\n            lf = headers.find(\"\\n\", start)\n            if lf == -1:\n                h.parse_line(headers[start:], _chars_are_bytes=_chars_are_bytes)\n                break\n            line = headers[start : lf + 1]\n            start = lf + 1\n            h.parse_line(line, _chars_are_bytes=_chars_are_bytes)\n        return h",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 39,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        method: Optional[str] = None,\n        uri: Optional[str] = None,\n        version: str = \"HTTP/1.0\",\n        headers: Optional[HTTPHeaders] = None,\n        body: Optional[bytes] = None,\n        # host: Optional[str] = None,\n        files: Optional[Dict[str, List[\"HTTPFile\"]]] = None,\n        connection: Optional[\"HTTPConnection\"] = None,\n        start_line: Optional[\"RequestStartLine\"] = None,\n        server_connection: Optional[object] = None,\n    ) -> None:\n        if start_line is not None:\n            method, uri, version = start_line\n        self.method = method\n        self.uri = uri\n        self.version = version\n        self.headers = headers or HTTPHeaders()\n        self.body = body or b\"\"\n\n        # set remote IP and protocol\n        context = getattr(connection, \"context\", None)\n        self.remote_ip = getattr(context, \"remote_ip\", None)\n        self.protocol = getattr(context, \"protocol\", \"http\")\n\n        try:\n            self.host = self.headers[\"Host\"]\n        except KeyError:\n            if version == \"HTTP/1.0\":\n                # HTTP/1.0 does not require the Host header.\n                self.host = \"127.0.0.1\"\n            else:\n                raise HTTPInputError(\"Missing Host header\")\n        if not _ABNF.host.fullmatch(self.host):\n            print(_ABNF.host.pattern)\n            raise HTTPInputError(\"Invalid Host header: %r\" % self.host)\n        if \",\" in self.host:\n            # https://www.rfc-editor.org/rfc/rfc9112.html#name-request-target\n            # Server MUST respond with 400 Bad Request if multiple\n            # Host headers are present.\n            #\n            # We test for the presence of a comma instead of the number of\n            # headers received because a proxy may have converted\n            # multiple headers into a single comma-separated value\n            # (per RFC 9110 section 5.3).\n            #\n            # This is technically a departure from the RFC since the ABNF\n            # does not forbid commas in the host header. However, since\n            # commas are not allowed in DNS names, it is appropriate to\n            # disallow them. (The same argument could be made for other special\n            # characters, but commas are the most problematic since they could\n            # be used to exploit differences between proxies when multiple headers\n            # are supplied).\n            raise HTTPInputError(\"Multiple host headers not allowed: %r\" % self.host)\n        self.host_name = split_host_and_port(self.host.lower())[0]\n        self.files = files or {}\n        self.connection = connection\n        self.server_connection = server_connection\n        self._start_time = time.time()\n        self._finish_time = None\n\n        if uri is not None:\n            self.path, sep, self.query = uri.partition(\"?\")\n        self.arguments = parse_qs_bytes(self.query, keep_blank_values=True)\n        self.query_arguments = copy.deepcopy(self.arguments)\n        self.body_arguments = {}  # type: Dict[str, List[bytes]]",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 66,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "cookies",
      "sourceCode": "@property\n    def cookies(self) -> Dict[str, http.cookies.Morsel]:\n        \"\"\"A dictionary of ``http.cookies.Morsel`` objects.\"\"\"\n        if not hasattr(self, \"_cookies\"):\n            self._cookies = (\n                http.cookies.SimpleCookie()\n            )  # type: http.cookies.SimpleCookie\n            if \"Cookie\" in self.headers:\n                try:\n                    parsed = parse_cookie(self.headers[\"Cookie\"])\n                except Exception:\n                    pass\n                else:\n                    for k, v in parsed.items():\n                        try:\n                            self._cookies[k] = v\n                        except Exception:\n                            # SimpleCookie imposes some restrictions on keys;\n                            # parse_cookie does not. Discard any cookies\n                            # with disallowed keys.\n                            pass\n        return self._cookies",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "get_ssl_certificate",
      "sourceCode": "def get_ssl_certificate(\n        self, binary_form: bool = False\n    ) -> Union[None, Dict, bytes]:\n        \"\"\"Returns the client's SSL certificate, if any.\n\n        To use client certificates, the HTTPServer's\n        `ssl.SSLContext.verify_mode` field must be set, e.g.::\n\n            ssl_ctx = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n            ssl_ctx.load_cert_chain(\"foo.crt\", \"foo.key\")\n            ssl_ctx.load_verify_locations(\"cacerts.pem\")\n            ssl_ctx.verify_mode = ssl.CERT_REQUIRED\n            server = HTTPServer(app, ssl_options=ssl_ctx)\n\n        By default, the return value is a dictionary (or None, if no\n        client certificate is present).  If ``binary_form`` is true, a\n        DER-encoded form of the certificate is returned instead.  See\n        SSLSocket.getpeercert() in the standard library for more\n        details.\n        http://docs.python.org/library/ssl.html#sslsocket-objects\n        \"\"\"\n        try:\n            if self.connection is None:\n                return None\n            # TODO: add a method to HTTPConnection for this so it can work with HTTP/2\n            return self.connection.stream.socket.getpeercert(  # type: ignore\n                binary_form=binary_form\n            )\n        except SSLError:\n            return None",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 29,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "_parse_body",
      "sourceCode": "def _parse_body(self) -> None:\n        parse_body_arguments(\n            self.headers.get(\"Content-Type\", \"\"),\n            self.body,\n            self.body_arguments,\n            self.files,\n            self.headers,\n        )\n\n        for k, v in self.body_arguments.items():\n            self.arguments.setdefault(k, []).extend(v)",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "start_request",
      "sourceCode": "def start_request(\n        self, server_conn: object, request_conn: \"HTTPConnection\"\n    ) -> \"HTTPMessageDelegate\":\n        \"\"\"This method is called by the server when a new request has started.\n\n        :arg server_conn: is an opaque object representing the long-lived\n            (e.g. tcp-level) connection.\n        :arg request_conn: is a `.HTTPConnection` object for a single\n            request/response exchange.\n\n        This method should return a `.HTTPMessageDelegate`.\n        \"\"\"\n        raise NotImplementedError()",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "headers_received",
      "sourceCode": "def headers_received(\n        self,\n        start_line: Union[\"RequestStartLine\", \"ResponseStartLine\"],\n        headers: HTTPHeaders,\n    ) -> Optional[Awaitable[None]]:\n        \"\"\"Called when the HTTP headers have been received and parsed.\n\n        :arg start_line: a `.RequestStartLine` or `.ResponseStartLine`\n            depending on whether this is a client or server message.\n        :arg headers: a `.HTTPHeaders` instance.\n\n        Some `.HTTPConnection` methods can only be called during\n        ``headers_received``.\n\n        May return a `.Future`; if it does the body will not be read\n        until it is done.\n        \"\"\"\n        pass",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 17,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "write_headers",
      "sourceCode": "def write_headers(\n        self,\n        start_line: Union[\"RequestStartLine\", \"ResponseStartLine\"],\n        headers: HTTPHeaders,\n        chunk: Optional[bytes] = None,\n    ) -> \"Future[None]\":\n        \"\"\"Write an HTTP header block.\n\n        :arg start_line: a `.RequestStartLine` or `.ResponseStartLine`.\n        :arg headers: a `.HTTPHeaders` instance.\n        :arg chunk: the first (optional) chunk of data.  This is an optimization\n            so that small responses can be written in the same call as their\n            headers.\n\n        The ``version`` field of ``start_line`` is ignored.\n\n        Returns a future for flow control.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed.\n        \"\"\"\n        raise NotImplementedError()",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 22,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "url_concat",
      "sourceCode": "def url_concat(\n    url: str,\n    args: Union[\n        None, Dict[str, str], List[Tuple[str, str]], Tuple[Tuple[str, str], ...]\n    ],\n) -> str:\n    \"\"\"Concatenate url and arguments regardless of whether\n    url has existing query parameters.\n\n    ``args`` may be either a dictionary or a list of key-value pairs\n    (the latter allows for multiple values with the same key.\n\n    >>> url_concat(\"http://example.com/foo\", dict(c=\"d\"))\n    'http://example.com/foo?c=d'\n    >>> url_concat(\"http://example.com/foo?a=b\", dict(c=\"d\"))\n    'http://example.com/foo?a=b&c=d'\n    >>> url_concat(\"http://example.com/foo?a=b\", [(\"c\", \"d\"), (\"c\", \"d2\")])\n    'http://example.com/foo?a=b&c=d&c=d2'\n    \"\"\"\n    if args is None:\n        return url\n    parsed_url = urlparse(url)\n    if isinstance(args, dict):\n        parsed_query = parse_qsl(parsed_url.query, keep_blank_values=True)\n        parsed_query.extend(args.items())\n    elif isinstance(args, list) or isinstance(args, tuple):\n        parsed_query = parse_qsl(parsed_url.query, keep_blank_values=True)\n        parsed_query.extend(args)\n    else:\n        err = \"'args' parameter should be dict, list or tuple. Not {0}\".format(\n            type(args)\n        )\n        raise TypeError(err)\n    final_query = urlencode(parsed_query)\n    url = urlunparse(\n        (\n            parsed_url[0],\n            parsed_url[1],\n            parsed_url[2],\n            parsed_url[3],\n            final_query,\n            parsed_url[5],\n        )\n    )\n    return url",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 44,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "_parse_request_range",
      "sourceCode": "def _parse_request_range(\n    range_header: str,\n) -> Optional[Tuple[Optional[int], Optional[int]]]:\n    \"\"\"Parses a Range header.\n\n    Returns either ``None`` or tuple ``(start, end)``.\n    Note that while the HTTP headers use inclusive byte positions,\n    this method returns indexes suitable for use in slices.\n\n    >>> start, end = _parse_request_range(\"bytes=1-2\")\n    >>> start, end\n    (1, 3)\n    >>> [0, 1, 2, 3, 4][start:end]\n    [1, 2]\n    >>> _parse_request_range(\"bytes=6-\")\n    (6, None)\n    >>> _parse_request_range(\"bytes=-6\")\n    (-6, None)\n    >>> _parse_request_range(\"bytes=-0\")\n    (None, 0)\n    >>> _parse_request_range(\"bytes=\")\n    (None, None)\n    >>> _parse_request_range(\"foo=42\")\n    >>> _parse_request_range(\"bytes=1-2,6-10\")\n\n    Note: only supports one range (ex, ``bytes=1-2,6-10`` is not allowed).\n\n    See [0] for the details of the range header.\n\n    [0]: http://greenbytes.de/tech/webdav/draft-ietf-httpbis-p5-range-latest.html#byte.ranges\n    \"\"\"\n    unit, _, value = range_header.partition(\"=\")\n    unit, value = unit.strip(), value.strip()\n    if unit != \"bytes\":\n        return None\n    start_b, _, end_b = value.partition(\"-\")\n    try:\n        start = _int_or_none(start_b)\n        end = _int_or_none(end_b)\n    except ValueError:\n        return None\n    if end is not None:\n        if start is None:\n            if end != 0:\n                start = -end\n                end = None\n        else:\n            end += 1\n    return (start, end)",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 48,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "_get_content_range",
      "sourceCode": "def _get_content_range(start: Optional[int], end: Optional[int], total: int) -> str:\n    \"\"\"Returns a suitable Content-Range header:\n\n    >>> print(_get_content_range(None, 1, 4))\n    bytes 0-0/4\n    >>> print(_get_content_range(1, 3, 4))\n    bytes 1-2/4\n    >>> print(_get_content_range(None, None, 4))\n    bytes 0-3/4\n    \"\"\"\n    start = start or 0\n    end = (end or total) - 1\n    return f\"bytes {start}-{end}/{total}\"",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "parse_body_arguments",
      "sourceCode": "def parse_body_arguments(\n    content_type: str,\n    body: bytes,\n    arguments: Dict[str, List[bytes]],\n    files: Dict[str, List[HTTPFile]],\n    headers: Optional[HTTPHeaders] = None,\n) -> None:\n    \"\"\"Parses a form request body.\n\n    Supports ``application/x-www-form-urlencoded`` and\n    ``multipart/form-data``.  The ``content_type`` parameter should be\n    a string and ``body`` should be a byte string.  The ``arguments``\n    and ``files`` parameters are dictionaries that will be updated\n    with the parsed contents.\n    \"\"\"\n    if content_type.startswith(\"application/x-www-form-urlencoded\"):\n        if headers and \"Content-Encoding\" in headers:\n            raise HTTPInputError(\n                \"Unsupported Content-Encoding: %s\" % headers[\"Content-Encoding\"]\n            )\n        try:\n            # real charset decoding will happen in RequestHandler.decode_argument()\n            uri_arguments = parse_qs_bytes(body, keep_blank_values=True)\n        except Exception as e:\n            raise HTTPInputError(\"Invalid x-www-form-urlencoded body: %s\" % e) from e\n        for name, values in uri_arguments.items():\n            if values:\n                arguments.setdefault(name, []).extend(values)\n    elif content_type.startswith(\"multipart/form-data\"):\n        if headers and \"Content-Encoding\" in headers:\n            raise HTTPInputError(\n                \"Unsupported Content-Encoding: %s\" % headers[\"Content-Encoding\"]\n            )\n        try:\n            fields = content_type.split(\";\")\n            for field in fields:\n                k, sep, v = field.strip().partition(\"=\")\n                if k == \"boundary\" and v:\n                    parse_multipart_form_data(utf8(v), body, arguments, files)\n                    break\n            else:\n                raise HTTPInputError(\"multipart boundary not found\")\n        except Exception as e:\n            raise HTTPInputError(\"Invalid multipart/form-data: %s\" % e) from e",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 43,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "parse_multipart_form_data",
      "sourceCode": "def parse_multipart_form_data(\n    boundary: bytes,\n    data: bytes,\n    arguments: Dict[str, List[bytes]],\n    files: Dict[str, List[HTTPFile]],\n) -> None:\n    \"\"\"Parses a ``multipart/form-data`` body.\n\n    The ``boundary`` and ``data`` parameters are both byte strings.\n    The dictionaries given in the arguments and files parameters\n    will be updated with the contents of the body.\n\n    .. versionchanged:: 5.1\n\n       Now recognizes non-ASCII filenames in RFC 2231/5987\n       (``filename*=``) format.\n    \"\"\"\n    # The standard allows for the boundary to be quoted in the header,\n    # although it's rare (it happens at least for google app engine\n    # xmpp).  I think we're also supposed to handle backslash-escapes\n    # here but I'll save that until we see a client that uses them\n    # in the wild.\n    if boundary.startswith(b'\"') and boundary.endswith(b'\"'):\n        boundary = boundary[1:-1]\n    final_boundary_index = data.rfind(b\"--\" + boundary + b\"--\")\n    if final_boundary_index == -1:\n        raise HTTPInputError(\"Invalid multipart/form-data: no final boundary found\")\n    parts = data[:final_boundary_index].split(b\"--\" + boundary + b\"\\r\\n\")\n    for part in parts:\n        if not part:\n            continue\n        eoh = part.find(b\"\\r\\n\\r\\n\")\n        if eoh == -1:\n            raise HTTPInputError(\"multipart/form-data missing headers\")\n        headers = HTTPHeaders.parse(part[:eoh].decode(\"utf-8\"), _chars_are_bytes=False)\n        disp_header = headers.get(\"Content-Disposition\", \"\")\n        disposition, disp_params = _parse_header(disp_header)\n        if disposition != \"form-data\" or not part.endswith(b\"\\r\\n\"):\n            raise HTTPInputError(\"Invalid multipart/form-data\")\n        value = part[eoh + 4 : -2]\n        if not disp_params.get(\"name\"):\n            raise HTTPInputError(\"multipart/form-data missing name\")\n        name = disp_params[\"name\"]\n        if disp_params.get(\"filename\"):\n            ctype = headers.get(\"Content-Type\", \"application/unknown\")\n            files.setdefault(name, []).append(\n                HTTPFile(\n                    filename=disp_params[\"filename\"], body=value, content_type=ctype\n                )\n            )\n        else:\n            arguments.setdefault(name, []).append(value)",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 51,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "format_timestamp",
      "sourceCode": "def format_timestamp(\n    ts: Union[int, float, tuple, time.struct_time, datetime.datetime],\n) -> str:\n    \"\"\"Formats a timestamp in the format used by HTTP.\n\n    The argument may be a numeric timestamp as returned by `time.time`,\n    a time tuple as returned by `time.gmtime`, or a `datetime.datetime`\n    object. Naive `datetime.datetime` objects are assumed to represent\n    UTC; aware objects are converted to UTC before formatting.\n\n    >>> format_timestamp(1359312200)\n    'Sun, 27 Jan 2013 18:43:20 GMT'\n    \"\"\"\n    if isinstance(ts, (int, float)):\n        time_num = ts\n    elif isinstance(ts, (tuple, time.struct_time)):\n        time_num = calendar.timegm(ts)\n    elif isinstance(ts, datetime.datetime):\n        time_num = calendar.timegm(ts.utctimetuple())\n    else:\n        raise TypeError(\"unknown timestamp type: %r\" % ts)\n    return email.utils.formatdate(time_num, usegmt=True)",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "parse_request_start_line",
      "sourceCode": "def parse_request_start_line(line: str) -> RequestStartLine:\n    \"\"\"Returns a (method, path, version) tuple for an HTTP 1.x request line.\n\n    The response is a `typing.NamedTuple`.\n\n    >>> parse_request_start_line(\"GET /foo HTTP/1.1\")\n    RequestStartLine(method='GET', path='/foo', version='HTTP/1.1')\n    \"\"\"\n    match = _ABNF.request_line.fullmatch(line)\n    if not match:\n        # https://tools.ietf.org/html/rfc7230#section-3.1.1\n        # invalid request-line SHOULD respond with a 400 (Bad Request)\n        raise HTTPInputError(\"Malformed HTTP request line\")\n    r = RequestStartLine(match.group(1), match.group(2), match.group(3))\n    if not r.version.startswith(\"HTTP/1\"):\n        # HTTP/2 and above doesn't use parse_request_start_line.\n        # This could be folded into the regex but we don't want to deviate\n        # from the ABNF in the RFCs.\n        raise HTTPInputError(\"Unexpected HTTP version %r\" % r.version)\n    return r",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 19,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "parse_response_start_line",
      "sourceCode": "def parse_response_start_line(line: str) -> ResponseStartLine:\n    \"\"\"Returns a (version, code, reason) tuple for an HTTP 1.x response line.\n\n    The response is a `typing.NamedTuple`.\n\n    >>> parse_response_start_line(\"HTTP/1.1 200 OK\")\n    ResponseStartLine(version='HTTP/1.1', code=200, reason='OK')\n    \"\"\"\n    match = _ABNF.status_line.fullmatch(line)\n    if not match:\n        raise HTTPInputError(\"Error parsing response start line\")\n    r = ResponseStartLine(match.group(1), int(match.group(2)), match.group(3))\n    if not r.version.startswith(\"HTTP/1\"):\n        # HTTP/2 and above doesn't use parse_response_start_line.\n        raise HTTPInputError(\"Unexpected HTTP version %r\" % r.version)\n    return r",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "_parseparam",
      "sourceCode": "def _parseparam(s: str) -> Generator[str, None, None]:\n    while s[:1] == \";\":\n        s = s[1:]\n        end = s.find(\";\")\n        while end > 0 and (s.count('\"', 0, end) - s.count('\\\\\"', 0, end)) % 2:\n            end = s.find(\";\", end + 1)\n        if end < 0:\n            end = len(s)\n        f = s[:end]\n        yield f.strip()\n        s = s[end:]",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "_parse_header",
      "sourceCode": "def _parse_header(line: str) -> Tuple[str, Dict[str, str]]:\n    r\"\"\"Parse a Content-type like header.\n\n    Return the main content-type and a dictionary of options.\n\n    >>> d = \"form-data; foo=\\\"b\\\\\\\\a\\\\\\\"r\\\"; file*=utf-8''T%C3%A4st\"\n    >>> ct, d = _parse_header(d)\n    >>> ct\n    'form-data'\n    >>> d['file'] == r'T\\u00e4st'.encode('ascii').decode('unicode_escape')\n    True\n    >>> d['foo']\n    'b\\\\a\"r'\n    \"\"\"\n    parts = _parseparam(\";\" + line)\n    key = next(parts)\n    # decode_params treats first argument special, but we already stripped key\n    params = [(\"Dummy\", \"value\")]\n    for p in parts:\n        i = p.find(\"=\")\n        if i >= 0:\n            name = p[:i].strip().lower()\n            value = p[i + 1 :].strip()\n            params.append((name, native_str(value)))\n    decoded_params = email.utils.decode_params(params)\n    decoded_params.pop(0)  # get rid of the dummy again\n    pdict = {}\n    for name, decoded_value in decoded_params:\n        value = email.utils.collapse_rfc2231_value(decoded_value)\n        if len(value) >= 2 and value[0] == '\"' and value[-1] == '\"':\n            value = value[1:-1]\n        pdict[name] = value\n    return key, pdict",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 32,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "_encode_header",
      "sourceCode": "def _encode_header(key: str, pdict: Dict[str, str]) -> str:\n    \"\"\"Inverse of _parse_header.\n\n    >>> _encode_header('permessage-deflate',\n    ...     {'client_max_window_bits': 15, 'client_no_context_takeover': None})\n    'permessage-deflate; client_max_window_bits=15; client_no_context_takeover'\n    \"\"\"\n    if not pdict:\n        return key\n    out = [key]\n    # Sort the parameters just to make it easy to test.\n    for k, v in sorted(pdict.items()):\n        if v is None:\n            out.append(k)\n        else:\n            # TODO: quote if necessary.\n            out.append(f\"{k}={v}\")\n    return \"; \".join(out)",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 17,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "encode_username_password",
      "sourceCode": "def encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"\n    if isinstance(username, unicode_type):\n        username = unicodedata.normalize(\"NFC\", username)\n    if isinstance(password, unicode_type):\n        password = unicodedata.normalize(\"NFC\", password)\n    return utf8(username) + b\":\" + utf8(password)",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "split_host_and_port",
      "sourceCode": "def split_host_and_port(netloc: str) -> Tuple[str, Optional[int]]:\n    \"\"\"Returns ``(host, port)`` tuple from ``netloc``.\n\n    Returned ``port`` will be ``None`` if not present.\n\n    .. versionadded:: 4.1\n    \"\"\"\n    match = _netloc_re.match(netloc)\n    if match:\n        host = match.group(1)\n        port = int(match.group(2))  # type: Optional[int]\n    else:\n        host = netloc\n        port = None\n    return (host, port)",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "_unquote_cookie",
      "sourceCode": "def _unquote_cookie(s: str) -> str:\n    \"\"\"Handle double quotes and escaping in cookie values.\n\n    This method is copied verbatim from the Python 3.13 standard\n    library (http.cookies._unquote) so we don't have to depend on\n    non-public interfaces.\n    \"\"\"\n    # If there aren't any doublequotes,\n    # then there can't be any special characters.  See RFC 2109.\n    if s is None or len(s) < 2:\n        return s\n    if s[0] != '\"' or s[-1] != '\"':\n        return s\n\n    # We have to assume that we must decode this string.\n    # Down to work.\n\n    # Remove the \"s\n    s = s[1:-1]\n\n    # Check for special sequences.  Examples:\n    #    \\012 --> \\n\n    #    \\\"   --> \"\n    #\n    return _unquote_sub(_unquote_replace, s)",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 24,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "parse_cookie",
      "sourceCode": "def parse_cookie(cookie: str) -> Dict[str, str]:\n    \"\"\"Parse a ``Cookie`` HTTP header into a dict of name/value pairs.\n\n    This function attempts to mimic browser cookie parsing behavior;\n    it specifically does not follow any of the cookie-related RFCs\n    (because browsers don't either).\n\n    The algorithm used is identical to that used by Django version 1.9.10.\n\n    .. versionadded:: 4.4.2\n    \"\"\"\n    cookiedict = {}\n    for chunk in cookie.split(\";\"):\n        if \"=\" in chunk:\n            key, val = chunk.split(\"=\", 1)\n        else:\n            # Assume an empty name per\n            # https://bugzilla.mozilla.org/show_bug.cgi?id=169091\n            key, val = \"\", chunk\n        key, val = key.strip(), val.strip()\n        if key or val:\n            # unquote using Python's algorithm.\n            cookiedict[key] = _unquote_cookie(val)\n    return cookiedict",
      "importString": "import calendar\nimport collections.abc\nimport copy\nimport datetime\nimport email.utils\nfrom functools import lru_cache\nfrom http.client import responses\nimport http.cookies\nimport re\nfrom ssl import SSLError\nimport time\nimport unicodedata\nfrom urllib.parse import urlencode, urlparse, urlunparse, parse_qsl\n\nfrom tornado.escape import native_str, parse_qs_bytes, utf8, to_unicode\nfrom tornado.util import ObjectDict, unicode_type\nimport typing\nfrom typing import (\nTuple\nIterable\nList\nMapping\nIterator\nDict\nUnion\nOptional\nAwaitable\nGenerator\nAnyStr\n)",
      "lineNum": 23,
      "relativeDocumentPath": "tornado/httputil.py"
    },
    {
      "symbolName": "configure",
      "sourceCode": "@classmethod\n    def configure(\n        cls, impl: \"Union[None, str, Type[Configurable]]\", **kwargs: Any\n    ) -> None:\n        from tornado.platform.asyncio import BaseAsyncIOLoop\n\n        if isinstance(impl, str):\n            impl = import_object(impl)\n        if isinstance(impl, type) and not issubclass(impl, BaseAsyncIOLoop):\n            raise RuntimeError(\"only AsyncIOLoop is allowed when asyncio is available\")\n        super().configure(impl, **kwargs)",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "instance",
      "sourceCode": "@staticmethod\n    def instance() -> \"IOLoop\":\n        \"\"\"Deprecated alias for `IOLoop.current()`.\n\n        .. versionchanged:: 5.0\n\n           Previously, this method returned a global singleton\n           `IOLoop`, in contrast with the per-thread `IOLoop` returned\n           by `current()`. In nearly all cases the two were the same\n           (when they differed, it was generally used from non-Tornado\n           threads to communicate back to the main thread's `IOLoop`).\n           This distinction is not present in `asyncio`, so in order\n           to facilitate integration with that package `instance()`\n           was changed to be an alias to `current()`. Applications\n           using the cross-thread communications aspect of\n           `instance()` should instead set their own global variable\n           to point to the `IOLoop` they want to use.\n\n        .. deprecated:: 5.0\n        \"\"\"\n        return IOLoop.current()",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "install",
      "sourceCode": "def install(self) -> None:\n        \"\"\"Deprecated alias for `make_current()`.\n\n        .. versionchanged:: 5.0\n\n           Previously, this method would set this `IOLoop` as the\n           global singleton used by `IOLoop.instance()`. Now that\n           `instance()` is an alias for `current()`, `install()`\n           is an alias for `make_current()`.\n\n        .. deprecated:: 5.0\n        \"\"\"\n        self.make_current()",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "clear_instance",
      "sourceCode": "@staticmethod\n    def clear_instance() -> None:\n        \"\"\"Deprecated alias for `clear_current()`.\n\n        .. versionchanged:: 5.0\n\n           Previously, this method would clear the `IOLoop` used as\n           the global singleton by `IOLoop.instance()`. Now that\n           `instance()` is an alias for `current()`,\n           `clear_instance()` is an alias for `clear_current()`.\n\n        .. deprecated:: 5.0\n\n        \"\"\"\n        IOLoop.clear_current()",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "current",
      "sourceCode": "@staticmethod\n    def current(instance: bool = True) -> Optional[\"IOLoop\"]:  # noqa: F811\n        \"\"\"Returns the current thread's `IOLoop`.\n\n        If an `IOLoop` is currently running or has been marked as\n        current by `make_current`, returns that instance.  If there is\n        no current `IOLoop` and ``instance`` is true, creates one.\n\n        .. versionchanged:: 4.1\n           Added ``instance`` argument to control the fallback to\n           `IOLoop.instance()`.\n        .. versionchanged:: 5.0\n           On Python 3, control of the current `IOLoop` is delegated\n           to `asyncio`, with this and other methods as pass-through accessors.\n           The ``instance`` argument now controls whether an `IOLoop`\n           is created automatically when there is none, instead of\n           whether we fall back to `IOLoop.instance()` (which is now\n           an alias for this method). ``instance=False`` is deprecated,\n           since even if we do not create an `IOLoop`, this method\n           may initialize the asyncio loop.\n\n        .. deprecated:: 6.2\n           It is deprecated to call ``IOLoop.current()`` when no `asyncio`\n           event loop is running.\n        \"\"\"\n        try:\n            loop = asyncio.get_event_loop()\n        except RuntimeError:\n            if not instance:\n                return None\n            # Create a new asyncio event loop for this thread.\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n        try:\n            return IOLoop._ioloop_for_asyncio[loop]\n        except KeyError:\n            if instance:\n                from tornado.platform.asyncio import AsyncIOMainLoop\n\n                current = AsyncIOMainLoop()  # type: Optional[IOLoop]\n            else:\n                current = None\n        return current",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 43,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "make_current",
      "sourceCode": "def make_current(self) -> None:\n        \"\"\"Makes this the `IOLoop` for the current thread.\n\n        An `IOLoop` automatically becomes current for its thread\n        when it is started, but it is sometimes useful to call\n        `make_current` explicitly before starting the `IOLoop`,\n        so that code run at startup time can find the right\n        instance.\n\n        .. versionchanged:: 4.1\n           An `IOLoop` created while there is no current `IOLoop`\n           will automatically become current.\n\n        .. versionchanged:: 5.0\n           This method also sets the current `asyncio` event loop.\n\n        .. deprecated:: 6.2\n           Setting and clearing the current event loop through Tornado is\n           deprecated. Use ``asyncio.set_event_loop`` instead if you need this.\n        \"\"\"\n        warnings.warn(\n            \"make_current is deprecated; start the event loop first\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        self._make_current()",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 25,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "clear_current",
      "sourceCode": "@staticmethod\n    def clear_current() -> None:\n        \"\"\"Clears the `IOLoop` for the current thread.\n\n        Intended primarily for use by test frameworks in between tests.\n\n        .. versionchanged:: 5.0\n           This method also clears the current `asyncio` event loop.\n        .. deprecated:: 6.2\n        \"\"\"\n        warnings.warn(\n            \"clear_current is deprecated\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        IOLoop._clear_current()",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "close",
      "sourceCode": "def close(self, all_fds: bool = False) -> None:\n        \"\"\"Closes the `IOLoop`, freeing any resources used.\n\n        If ``all_fds`` is true, all file descriptors registered on the\n        IOLoop will be closed (not just the ones created by the\n        `IOLoop` itself).\n\n        Many applications will only use a single `IOLoop` that runs for the\n        entire lifetime of the process.  In that case closing the `IOLoop`\n        is not necessary since everything will be cleaned up when the\n        process exits.  `IOLoop.close` is provided mainly for scenarios\n        such as unit tests, which create and destroy a large number of\n        ``IOLoops``.\n\n        An `IOLoop` must be completely stopped before it can be closed.  This\n        means that `IOLoop.stop()` must be called *and* `IOLoop.start()` must\n        be allowed to return before attempting to call `IOLoop.close()`.\n        Therefore the call to `close` will usually appear just after\n        the call to `start` rather than near the call to `stop`.\n\n        .. versionchanged:: 3.1\n           If the `IOLoop` implementation supports non-integer objects\n           for \"file descriptors\", those objects will have their\n           ``close`` method when ``all_fds`` is true.\n        \"\"\"\n        raise NotImplementedError()",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 25,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "add_handler",
      "sourceCode": "def add_handler(  # noqa: F811\n        self, fd: Union[int, _Selectable], handler: Callable[..., None], events: int\n    ) -> None:\n        \"\"\"Registers the given handler to receive the given events for ``fd``.\n\n        The ``fd`` argument may either be an integer file descriptor or\n        a file-like object with a ``fileno()`` and ``close()`` method.\n\n        The ``events`` argument is a bitwise or of the constants\n        ``IOLoop.READ``, ``IOLoop.WRITE``, and ``IOLoop.ERROR``.\n\n        When an event occurs, ``handler(fd, events)`` will be run.\n\n        .. versionchanged:: 4.0\n           Added the ability to pass file-like objects in addition to\n           raw file descriptors.\n        \"\"\"\n        raise NotImplementedError()",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 17,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "stop",
      "sourceCode": "def stop(self) -> None:\n        \"\"\"Stop the I/O loop.\n\n        If the event loop is not currently running, the next call to `start()`\n        will return immediately.\n\n        Note that even after `stop` has been called, the `IOLoop` is not\n        completely stopped until `IOLoop.start` has also returned.\n        Some work that was scheduled before the call to `stop` may still\n        be run before the `IOLoop` shuts down.\n        \"\"\"\n        raise NotImplementedError()",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "run_sync",
      "sourceCode": "def run_sync(self, func: Callable, timeout: Optional[float] = None) -> Any:\n        \"\"\"Starts the `IOLoop`, runs the given function, and stops the loop.\n\n        The function must return either an awaitable object or\n        ``None``. If the function returns an awaitable object, the\n        `IOLoop` will run until the awaitable is resolved (and\n        `run_sync()` will return the awaitable's result). If it raises\n        an exception, the `IOLoop` will stop and the exception will be\n        re-raised to the caller.\n\n        The keyword-only argument ``timeout`` may be used to set\n        a maximum duration for the function.  If the timeout expires,\n        a `asyncio.TimeoutError` is raised.\n\n        This method is useful to allow asynchronous calls in a\n        ``main()`` function::\n\n            async def main():\n                # do stuff...\n\n            if __name__ == '__main__':\n                IOLoop.current().run_sync(main)\n\n        .. versionchanged:: 4.3\n           Returning a non-``None``, non-awaitable value is now an error.\n\n        .. versionchanged:: 5.0\n           If a timeout occurs, the ``func`` coroutine will be cancelled.\n\n        .. versionchanged:: 6.2\n           ``tornado.util.TimeoutError`` is now an alias to ``asyncio.TimeoutError``.\n        \"\"\"\n        if typing.TYPE_CHECKING:\n            FutureCell = TypedDict(  # noqa: F841\n                \"FutureCell\", {\"future\": Optional[Future], \"timeout_called\": bool}\n            )\n        future_cell = {\"future\": None, \"timeout_called\": False}  # type: FutureCell\n\n        def run() -> None:\n            try:\n                result = func()\n                if result is not None:\n                    from tornado.gen import convert_yielded\n\n                    result = convert_yielded(result)\n            except Exception:\n                fut = Future()  # type: Future[Any]\n                future_cell[\"future\"] = fut\n                future_set_exc_info(fut, sys.exc_info())\n            else:\n                if is_future(result):\n                    future_cell[\"future\"] = result\n                else:\n                    fut = Future()\n                    future_cell[\"future\"] = fut\n                    fut.set_result(result)\n            assert future_cell[\"future\"] is not None\n            self.add_future(future_cell[\"future\"], lambda future: self.stop())\n\n        self.add_callback(run)\n        if timeout is not None:\n\n            def timeout_callback() -> None:\n                # signal that timeout is triggered\n                future_cell[\"timeout_called\"] = True\n                # If we can cancel the future, do so and wait on it. If not,\n                # Just stop the loop and return with the task still pending.\n                # (If we neither cancel nor wait for the task, a warning\n                # will be logged).\n                assert future_cell[\"future\"] is not None\n                if not future_cell[\"future\"].cancel():\n                    self.stop()\n\n            timeout_handle = self.add_timeout(self.time() + timeout, timeout_callback)\n        self.start()\n        if timeout is not None:\n            self.remove_timeout(timeout_handle)\n        assert future_cell[\"future\"] is not None\n        if future_cell[\"future\"].cancelled() or not future_cell[\"future\"].done():\n            if future_cell[\"timeout_called\"]:\n                raise TimeoutError(\"Operation timed out after %s seconds\" % timeout)\n            else:\n                # timeout not called; maybe stop() was called explicitly\n                # or some other cancellation\n                raise RuntimeError(\"Event loop stopped before Future completed.\")\n        return future_cell[\"future\"].result()",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 85,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "run",
      "sourceCode": "def run() -> None:\n            try:\n                result = func()\n                if result is not None:\n                    from tornado.gen import convert_yielded\n\n                    result = convert_yielded(result)\n            except Exception:\n                fut = Future()  # type: Future[Any]\n                future_cell[\"future\"] = fut\n                future_set_exc_info(fut, sys.exc_info())\n            else:\n                if is_future(result):\n                    future_cell[\"future\"] = result\n                else:\n                    fut = Future()\n                    future_cell[\"future\"] = fut\n                    fut.set_result(result)\n            assert future_cell[\"future\"] is not None\n            self.add_future(future_cell[\"future\"], lambda future: self.stop())",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 19,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "time",
      "sourceCode": "def time(self) -> float:\n        \"\"\"Returns the current time according to the `IOLoop`'s clock.\n\n        The return value is a floating-point number relative to an\n        unspecified time in the past.\n\n        Historically, the IOLoop could be customized to use e.g.\n        `time.monotonic` instead of `time.time`, but this is not\n        currently supported and so this method is equivalent to\n        `time.time`.\n\n        \"\"\"\n        return time.time()",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "add_timeout",
      "sourceCode": "def add_timeout(\n        self,\n        deadline: Union[float, datetime.timedelta],\n        callback: Callable,\n        *args: Any,\n        **kwargs: Any,\n    ) -> object:\n        \"\"\"Runs the ``callback`` at the time ``deadline`` from the I/O loop.\n\n        Returns an opaque handle that may be passed to\n        `remove_timeout` to cancel.\n\n        ``deadline`` may be a number denoting a time (on the same\n        scale as `IOLoop.time`, normally `time.time`), or a\n        `datetime.timedelta` object for a deadline relative to the\n        current time.  Since Tornado 4.0, `call_later` is a more\n        convenient alternative for the relative case since it does not\n        require a timedelta object.\n\n        Note that it is not safe to call `add_timeout` from other threads.\n        Instead, you must use `add_callback` to transfer control to the\n        `IOLoop`'s thread, and then call `add_timeout` from there.\n\n        Subclasses of IOLoop must implement either `add_timeout` or\n        `call_at`; the default implementations of each will call\n        the other.  `call_at` is usually easier to implement, but\n        subclasses that wish to maintain compatibility with Tornado\n        versions prior to 4.0 must use `add_timeout` instead.\n\n        .. versionchanged:: 4.0\n           Now passes through ``*args`` and ``**kwargs`` to the callback.\n        \"\"\"\n        if isinstance(deadline, numbers.Real):\n            return self.call_at(deadline, callback, *args, **kwargs)\n        elif isinstance(deadline, datetime.timedelta):\n            return self.call_at(\n                self.time() + deadline.total_seconds(), callback, *args, **kwargs\n            )\n        else:\n            raise TypeError(\"Unsupported deadline %r\" % deadline)",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 39,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "call_later",
      "sourceCode": "def call_later(\n        self, delay: float, callback: Callable, *args: Any, **kwargs: Any\n    ) -> object:\n        \"\"\"Runs the ``callback`` after ``delay`` seconds have passed.\n\n        Returns an opaque handle that may be passed to `remove_timeout`\n        to cancel.  Note that unlike the `asyncio` method of the same\n        name, the returned object does not have a ``cancel()`` method.\n\n        See `add_timeout` for comments on thread-safety and subclassing.\n\n        .. versionadded:: 4.0\n        \"\"\"\n        return self.call_at(self.time() + delay, callback, *args, **kwargs)",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "call_at",
      "sourceCode": "def call_at(\n        self, when: float, callback: Callable, *args: Any, **kwargs: Any\n    ) -> object:\n        \"\"\"Runs the ``callback`` at the absolute time designated by ``when``.\n\n        ``when`` must be a number using the same reference point as\n        `IOLoop.time`.\n\n        Returns an opaque handle that may be passed to `remove_timeout`\n        to cancel.  Note that unlike the `asyncio` method of the same\n        name, the returned object does not have a ``cancel()`` method.\n\n        See `add_timeout` for comments on thread-safety and subclassing.\n\n        .. versionadded:: 4.0\n        \"\"\"\n        return self.add_timeout(when, callback, *args, **kwargs)",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "add_callback",
      "sourceCode": "def add_callback(self, callback: Callable, *args: Any, **kwargs: Any) -> None:\n        \"\"\"Calls the given callback on the next I/O loop iteration.\n\n        It is safe to call this method from any thread at any time,\n        except from a signal handler.  Note that this is the **only**\n        method in `IOLoop` that makes this thread-safety guarantee; all\n        other interaction with the `IOLoop` must be done from that\n        `IOLoop`'s thread.  `add_callback()` may be used to transfer\n        control from other threads to the `IOLoop`'s thread.\n        \"\"\"\n        raise NotImplementedError()",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "add_callback_from_signal",
      "sourceCode": "def add_callback_from_signal(\n        self, callback: Callable, *args: Any, **kwargs: Any\n    ) -> None:\n        \"\"\"Calls the given callback on the next I/O loop iteration.\n\n        Intended to be afe for use from a Python signal handler; should not be\n        used otherwise.\n\n        .. deprecated:: 6.4\n           Use ``asyncio.AbstractEventLoop.add_signal_handler`` instead.\n           This method is suspected to have been broken since Tornado 5.0 and\n           will be removed in version 7.0.\n        \"\"\"\n        raise NotImplementedError()",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "add_future",
      "sourceCode": "def add_future(\n        self,\n        future: \"Union[Future[_T], concurrent.futures.Future[_T]]\",\n        callback: Callable[[\"Future[_T]\"], None],\n    ) -> None:\n        \"\"\"Schedules a callback on the ``IOLoop`` when the given\n        `.Future` is finished.\n\n        The callback is invoked with one argument, the\n        `.Future`.\n\n        This method only accepts `.Future` objects and not other\n        awaitables (unlike most of Tornado where the two are\n        interchangeable).\n        \"\"\"\n        if isinstance(future, Future):\n            # Note that we specifically do not want the inline behavior of\n            # tornado.concurrent.future_add_done_callback. We always want\n            # this callback scheduled on the next IOLoop iteration (which\n            # asyncio.Future always does).\n            #\n            # Wrap the callback in self._run_callback so we control\n            # the error logging (i.e. it goes to tornado.log.app_log\n            # instead of asyncio's log).\n            future.add_done_callback(\n                lambda f: self._run_callback(functools.partial(callback, f))\n            )\n        else:\n            assert is_future(future)\n            # For concurrent futures, we use self.add_callback, so\n            # it's fine if future_add_done_callback inlines that call.\n            future_add_done_callback(future, lambda f: self.add_callback(callback, f))",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 31,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "run_in_executor",
      "sourceCode": "def run_in_executor(\n        self,\n        executor: Optional[concurrent.futures.Executor],\n        func: Callable[..., _T],\n        *args: Any,\n    ) -> \"Future[_T]\":\n        \"\"\"Runs a function in a ``concurrent.futures.Executor``. If\n        ``executor`` is ``None``, the IO loop's default executor will be used.\n\n        Use `functools.partial` to pass keyword arguments to ``func``.\n\n        .. versionadded:: 5.0\n        \"\"\"\n        if executor is None:\n            if not hasattr(self, \"_executor\"):\n                from tornado.process import cpu_count\n\n                self._executor = concurrent.futures.ThreadPoolExecutor(\n                    max_workers=(cpu_count() * 5)\n                )  # type: concurrent.futures.Executor\n            executor = self._executor\n        c_future = executor.submit(func, *args)\n        # Concurrent Futures are not usable with await. Wrap this in a\n        # Tornado Future instead, using self.add_future for thread-safety.\n        t_future = Future()  # type: Future[_T]\n        self.add_future(c_future, lambda f: chain_future(f, t_future))\n        return t_future",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 26,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "_run_callback",
      "sourceCode": "def _run_callback(self, callback: Callable[[], Any]) -> None:\n        \"\"\"Runs a callback with error handling.\n\n        .. versionchanged:: 6.0\n\n           CancelledErrors are no longer logged.\n        \"\"\"\n        try:\n            ret = callback()\n            if ret is not None:\n                from tornado import gen\n\n                # Functions that return Futures typically swallow all\n                # exceptions and store them in the Future.  If a Future\n                # makes it out to the IOLoop, ensure its exception (if any)\n                # gets logged too.\n                try:\n                    ret = gen.convert_yielded(ret)\n                except gen.BadYieldError:\n                    # It's not unusual for add_callback to be used with\n                    # methods returning a non-None and non-yieldable\n                    # result, which should just be ignored.\n                    pass\n                else:\n                    self.add_future(ret, self._discard_future_result)\n        except asyncio.CancelledError:\n            pass\n        except Exception:\n            app_log.error(\"Exception in callback %r\", callback, exc_info=True)",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 28,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "split_fd",
      "sourceCode": "def split_fd(\n        self, fd: Union[int, _Selectable]\n    ) -> Tuple[int, Union[int, _Selectable]]:\n        # \"\"\"Returns an (fd, obj) pair from an ``fd`` parameter.\n\n        # We accept both raw file descriptors and file-like objects as\n        # input to `add_handler` and related methods.  When a file-like\n        # object is passed, we must retain the object itself so we can\n        # close it correctly when the `IOLoop` shuts down, but the\n        # poller interfaces favor file descriptors (they will accept\n        # file-like objects and call ``fileno()`` for you, but they\n        # always return the descriptor itself).\n\n        # This method is provided for use by `IOLoop` subclasses and should\n        # not generally be used by application code.\n\n        # .. versionadded:: 4.0\n        # \"\"\"\n        if isinstance(fd, int):\n            return fd, fd\n        return fd.fileno(), fd",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "close_fd",
      "sourceCode": "def close_fd(self, fd: Union[int, _Selectable]) -> None:\n        # \"\"\"Utility method to close an ``fd``.\n\n        # If ``fd`` is a file-like object, we close it directly; otherwise\n        # we use `os.close`.\n\n        # This method is provided for use by `IOLoop` subclasses (in\n        # implementations of ``IOLoop.close(all_fds=True)`` and should\n        # not generally be used by application code.\n\n        # .. versionadded:: 4.0\n        # \"\"\"\n        try:\n            if isinstance(fd, int):\n                os.close(fd)\n            else:\n                fd.close()\n        except OSError:\n            pass",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 18,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self, deadline: float, callback: Callable[[], None], io_loop: IOLoop\n    ) -> None:\n        if not isinstance(deadline, numbers.Real):\n            raise TypeError(\"Unsupported deadline %r\" % deadline)\n        self.deadline = deadline\n        self.callback = callback\n        self.tdeadline = (\n            deadline,\n            next(io_loop._timeout_counter),\n        )  # type: Tuple[float, int]",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        callback: Callable[[], Optional[Awaitable]],\n        callback_time: Union[datetime.timedelta, float],\n        jitter: float = 0,\n    ) -> None:\n        self.callback = callback\n        if isinstance(callback_time, datetime.timedelta):\n            self.callback_time = callback_time / datetime.timedelta(milliseconds=1)\n        else:\n            if callback_time <= 0:\n                raise ValueError(\"Periodic callback must have a positive callback_time\")\n            self.callback_time = callback_time\n        self.jitter = jitter\n        self._running = False\n        self._timeout = None  # type: object",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "_run",
      "sourceCode": "async def _run(self) -> None:\n        if not self._running:\n            return\n        try:\n            val = self.callback()\n            if val is not None and isawaitable(val):\n                await val\n        except Exception:\n            app_log.error(\"Exception in callback %r\", self.callback, exc_info=True)\n        finally:\n            self._schedule_next()",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "_update_next",
      "sourceCode": "def _update_next(self, current_time: float) -> None:\n        callback_time_sec = self.callback_time / 1000.0\n        if self.jitter:\n            # apply jitter fraction\n            callback_time_sec *= 1 + (self.jitter * (random.random() - 0.5))\n        if self._next_timeout <= current_time:\n            # The period should be measured from the start of one call\n            # to the start of the next. If one call takes too long,\n            # skip cycles to get back to a multiple of the original\n            # schedule.\n            self._next_timeout += (\n                math.floor((current_time - self._next_timeout) / callback_time_sec) + 1\n            ) * callback_time_sec\n        else:\n            # If the clock moved backwards, ensure we advance the next\n            # timeout instead of recomputing the same value again.\n            # This may result in long gaps between callbacks if the\n            # clock jumps backwards by a lot, but the far more common\n            # scenario is a small NTP adjustment that should just be\n            # ignored.\n            #\n            # Note that on some systems if time.time() runs slower\n            # than time.monotonic() (most common on windows), we\n            # effectively experience a small backwards time jump on\n            # every iteration because PeriodicCallback uses\n            # time.time() while asyncio schedules callbacks using\n            # time.monotonic().\n            # https://github.com/tornadoweb/tornado/issues/2333\n            self._next_timeout += callback_time_sec",
      "importString": "import concurrent.futures\nimport datetime\nimport functools\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\nimport warnings\nfrom tornado.concurrent import (\nFuture\nis_future\nchain_future\nfuture_set_exc_info\nfuture_add_done_callback\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable",
      "lineNum": 28,
      "relativeDocumentPath": "tornado/ioloop.py"
    },
    {
      "symbolName": "append",
      "sourceCode": "def append(self, data: Union[bytes, bytearray, memoryview]) -> None:\n        \"\"\"\n        Append the given piece of data (should be a buffer-compatible object).\n        \"\"\"\n        size = len(data)\n        if size > self._large_buf_threshold:\n            if not isinstance(data, memoryview):\n                data = memoryview(data)\n            self._buffers.append((True, data))\n        elif size > 0:\n            if self._buffers:\n                is_memview, b = self._buffers[-1]\n                new_buf = is_memview or len(b) >= self._large_buf_threshold\n            else:\n                new_buf = True\n            if new_buf:\n                self._buffers.append((False, bytearray(data)))\n            else:\n                b += data  # type: ignore\n\n        self._size += size",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "peek",
      "sourceCode": "def peek(self, size: int) -> memoryview:\n        \"\"\"\n        Get a view over at most ``size`` bytes (possibly fewer) at the\n        current buffer position.\n        \"\"\"\n        assert size > 0\n        try:\n            is_memview, b = self._buffers[0]\n        except IndexError:\n            return memoryview(b\"\")\n\n        pos = self._first_pos\n        if is_memview:\n            return typing.cast(memoryview, b[pos : pos + size])\n        else:\n            return memoryview(b)[pos : pos + size]",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "advance",
      "sourceCode": "def advance(self, size: int) -> None:\n        \"\"\"\n        Advance the current buffer position by ``size`` bytes.\n        \"\"\"\n        assert 0 < size <= self._size\n        self._size -= size\n        pos = self._first_pos\n\n        buffers = self._buffers\n        while buffers and size > 0:\n            is_large, b = buffers[0]\n            b_remain = len(b) - size - pos\n            if b_remain <= 0:\n                buffers.popleft()\n                size -= len(b) - pos\n                pos = 0\n            elif is_large:\n                pos += size\n                size = 0\n            else:\n                pos += size\n                del typing.cast(bytearray, b)[:pos]\n                pos = 0\n                size = 0\n\n        assert size == 0\n        self._first_pos = pos",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 26,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        max_buffer_size: Optional[int] = None,\n        read_chunk_size: Optional[int] = None,\n        max_write_buffer_size: Optional[int] = None,\n    ) -> None:\n        \"\"\"`BaseIOStream` constructor.\n\n        :arg max_buffer_size: Maximum amount of incoming data to buffer;\n            defaults to 100MB.\n        :arg read_chunk_size: Amount of data to read at one time from the\n            underlying transport; defaults to 64KB.\n        :arg max_write_buffer_size: Amount of outgoing data to buffer;\n            defaults to unlimited.\n\n        .. versionchanged:: 4.0\n           Add the ``max_write_buffer_size`` parameter.  Changed default\n           ``read_chunk_size`` to 64KB.\n        .. versionchanged:: 5.0\n           The ``io_loop`` argument (deprecated since version 4.1) has been\n           removed.\n        \"\"\"\n        self.io_loop = ioloop.IOLoop.current()\n        self.max_buffer_size = max_buffer_size or 104857600\n        # A chunk size that is too close to max_buffer_size can cause\n        # spurious failures.\n        self.read_chunk_size = min(read_chunk_size or 65536, self.max_buffer_size // 2)\n        self.max_write_buffer_size = max_write_buffer_size\n        self.error = None  # type: Optional[BaseException]\n        self._read_buffer = bytearray()\n        self._read_buffer_size = 0\n        self._user_read_buffer = False\n        self._after_user_read_buffer = None  # type: Optional[bytearray]\n        self._write_buffer = _StreamBuffer()\n        self._total_write_index = 0\n        self._total_write_done_index = 0\n        self._read_delimiter = None  # type: Optional[bytes]\n        self._read_regex = None  # type: Optional[Pattern]\n        self._read_max_bytes = None  # type: Optional[int]\n        self._read_bytes = None  # type: Optional[int]\n        self._read_partial = False\n        self._read_until_close = False\n        self._read_future = None  # type: Optional[Future]\n        self._write_futures = (\n            collections.deque()\n        )  # type: Deque[Tuple[int, Future[None]]]\n        self._close_callback = None  # type: Optional[Callable[[], None]]\n        self._connect_future = None  # type: Optional[Future[IOStream]]\n        # _ssl_connect_future should be defined in SSLIOStream\n        # but it's here so we can clean it up in _signal_closed\n        # TODO: refactor that so subclasses can add additional futures\n        # to be cancelled.\n        self._ssl_connect_future = None  # type: Optional[Future[SSLIOStream]]\n        self._connecting = False\n        self._state = None  # type: Optional[int]\n        self._closed = False",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 55,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "read_from_fd",
      "sourceCode": "def read_from_fd(self, buf: Union[bytearray, memoryview]) -> Optional[int]:\n        \"\"\"Attempts to read from the underlying file.\n\n        Reads up to ``len(buf)`` bytes, storing them in the buffer.\n        Returns the number of bytes read. Returns None if there was\n        nothing to read (the socket returned `~errno.EWOULDBLOCK` or\n        equivalent), and zero on EOF.\n\n        .. versionchanged:: 5.0\n\n           Interface redesigned to take a buffer and return a number\n           of bytes instead of a freshly-allocated object.\n        \"\"\"\n        raise NotImplementedError()",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "read_until_regex",
      "sourceCode": "def read_until_regex(\n        self, regex: bytes, max_bytes: Optional[int] = None\n    ) -> Awaitable[bytes]:\n        \"\"\"Asynchronously read until we have matched the given regex.\n\n        The result includes the data that matches the regex and anything\n        that came before it.\n\n        If ``max_bytes`` is not None, the connection will be closed\n        if more than ``max_bytes`` bytes have been read and the regex is\n        not satisfied.\n\n        .. versionchanged:: 4.0\n            Added the ``max_bytes`` argument.  The ``callback`` argument is\n            now optional and a `.Future` will be returned if it is omitted.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           `.Future` instead.\n\n        \"\"\"\n        future = self._start_read()\n        self._read_regex = re.compile(regex)\n        self._read_max_bytes = max_bytes\n        try:\n            self._try_inline_read()\n        except UnsatisfiableReadError as e:\n            # Handle this the same way as in _handle_events.\n            gen_log.info(\"Unsatisfiable read, closing connection: %s\" % e)\n            self.close(exc_info=e)\n            return future\n        except:\n            # Ensure that the future doesn't log an error because its\n            # failure was never examined.\n            future.add_done_callback(lambda f: f.exception())\n            raise\n        return future",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 37,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "read_until",
      "sourceCode": "def read_until(\n        self, delimiter: bytes, max_bytes: Optional[int] = None\n    ) -> Awaitable[bytes]:\n        \"\"\"Asynchronously read until we have found the given delimiter.\n\n        The result includes all the data read including the delimiter.\n\n        If ``max_bytes`` is not None, the connection will be closed\n        if more than ``max_bytes`` bytes have been read and the delimiter\n        is not found.\n\n        .. versionchanged:: 4.0\n            Added the ``max_bytes`` argument.  The ``callback`` argument is\n            now optional and a `.Future` will be returned if it is omitted.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           `.Future` instead.\n        \"\"\"\n        future = self._start_read()\n        self._read_delimiter = delimiter\n        self._read_max_bytes = max_bytes\n        try:\n            self._try_inline_read()\n        except UnsatisfiableReadError as e:\n            # Handle this the same way as in _handle_events.\n            gen_log.info(\"Unsatisfiable read, closing connection: %s\" % e)\n            self.close(exc_info=e)\n            return future\n        except:\n            future.add_done_callback(lambda f: f.exception())\n            raise\n        return future",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 33,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "read_bytes",
      "sourceCode": "def read_bytes(self, num_bytes: int, partial: bool = False) -> Awaitable[bytes]:\n        \"\"\"Asynchronously read a number of bytes.\n\n        If ``partial`` is true, data is returned as soon as we have\n        any bytes to return (but never more than ``num_bytes``)\n\n        .. versionchanged:: 4.0\n            Added the ``partial`` argument.  The callback argument is now\n            optional and a `.Future` will be returned if it is omitted.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` and ``streaming_callback`` arguments have\n           been removed. Use the returned `.Future` (and\n           ``partial=True`` for ``streaming_callback``) instead.\n\n        \"\"\"\n        future = self._start_read()\n        assert isinstance(num_bytes, numbers.Integral)\n        self._read_bytes = num_bytes\n        self._read_partial = partial\n        try:\n            self._try_inline_read()\n        except:\n            future.add_done_callback(lambda f: f.exception())\n            raise\n        return future",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 26,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "read_into",
      "sourceCode": "def read_into(self, buf: bytearray, partial: bool = False) -> Awaitable[int]:\n        \"\"\"Asynchronously read a number of bytes.\n\n        ``buf`` must be a writable buffer into which data will be read.\n\n        If ``partial`` is true, the callback is run as soon as any bytes\n        have been read.  Otherwise, it is run when the ``buf`` has been\n        entirely filled with read data.\n\n        .. versionadded:: 5.0\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           `.Future` instead.\n\n        \"\"\"\n        future = self._start_read()\n\n        # First copy data already in read buffer\n        available_bytes = self._read_buffer_size\n        n = len(buf)\n        if available_bytes >= n:\n            buf[:] = memoryview(self._read_buffer)[:n]\n            del self._read_buffer[:n]\n            self._after_user_read_buffer = self._read_buffer\n        elif available_bytes > 0:\n            buf[:available_bytes] = memoryview(self._read_buffer)[:]\n\n        # Set up the supplied buffer as our temporary read buffer.\n        # The original (if it had any data remaining) has been\n        # saved for later.\n        self._user_read_buffer = True\n        self._read_buffer = buf\n        self._read_buffer_size = available_bytes\n        self._read_bytes = n\n        self._read_partial = partial\n\n        try:\n            self._try_inline_read()\n        except:\n            future.add_done_callback(lambda f: f.exception())\n            raise\n        return future",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 43,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "read_until_close",
      "sourceCode": "def read_until_close(self) -> Awaitable[bytes]:\n        \"\"\"Asynchronously reads all data from the socket until it is closed.\n\n        This will buffer all available data until ``max_buffer_size``\n        is reached. If flow control or cancellation are desired, use a\n        loop with `read_bytes(partial=True) <.read_bytes>` instead.\n\n        .. versionchanged:: 4.0\n            The callback argument is now optional and a `.Future` will\n            be returned if it is omitted.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` and ``streaming_callback`` arguments have\n           been removed. Use the returned `.Future` (and `read_bytes`\n           with ``partial=True`` for ``streaming_callback``) instead.\n\n        \"\"\"\n        future = self._start_read()\n        if self.closed():\n            self._finish_read(self._read_buffer_size)\n            return future\n        self._read_until_close = True\n        try:\n            self._try_inline_read()\n        except:\n            future.add_done_callback(lambda f: f.exception())\n            raise\n        return future",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 28,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "write",
      "sourceCode": "def write(self, data: Union[bytes, memoryview]) -> \"Future[None]\":\n        \"\"\"Asynchronously write the given data to this stream.\n\n        This method returns a `.Future` that resolves (with a result\n        of ``None``) when the write has been completed.\n\n        The ``data`` argument may be of type `bytes` or `memoryview`.\n\n        .. versionchanged:: 4.0\n            Now returns a `.Future` if no callback is given.\n\n        .. versionchanged:: 4.5\n            Added support for `memoryview` arguments.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           `.Future` instead.\n\n        \"\"\"\n        self._check_closed()\n        if data:\n            if isinstance(data, memoryview):\n                # Make sure that ``len(data) == data.nbytes``\n                data = memoryview(data).cast(\"B\")\n            if (\n                self.max_write_buffer_size is not None\n                and len(self._write_buffer) + len(data) > self.max_write_buffer_size\n            ):\n                raise StreamBufferFullError(\"Reached maximum write buffer size\")\n            self._write_buffer.append(data)\n            self._total_write_index += len(data)\n        future = Future()  # type: Future[None]\n        future.add_done_callback(lambda f: f.exception())\n        self._write_futures.append((self._total_write_index, future))\n        if not self._connecting:\n            self._handle_write()\n            if self._write_buffer:\n                self._add_io_state(self.io_loop.WRITE)\n            self._maybe_add_error_listener()\n        return future",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 40,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "set_close_callback",
      "sourceCode": "def set_close_callback(self, callback: Optional[Callable[[], None]]) -> None:\n        \"\"\"Call the given callback when the stream is closed.\n\n        This mostly is not necessary for applications that use the\n        `.Future` interface; all outstanding ``Futures`` will resolve\n        with a `StreamClosedError` when the stream is closed. However,\n        it is still useful as a way to signal that the stream has been\n        closed while no other read or write is in progress.\n\n        Unlike other callback-based interfaces, ``set_close_callback``\n        was not removed in Tornado 6.0.\n        \"\"\"\n        self._close_callback = callback\n        self._maybe_add_error_listener()",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "close",
      "sourceCode": "def close(\n        self,\n        exc_info: Union[\n            None,\n            bool,\n            BaseException,\n            Tuple[\n                \"Optional[Type[BaseException]]\",\n                Optional[BaseException],\n                Optional[TracebackType],\n            ],\n        ] = False,\n    ) -> None:\n        \"\"\"Close this stream.\n\n        If ``exc_info`` is true, set the ``error`` attribute to the current\n        exception from `sys.exc_info` (or if ``exc_info`` is a tuple,\n        use that instead of `sys.exc_info`).\n        \"\"\"\n        if not self.closed():\n            if exc_info:\n                if isinstance(exc_info, tuple):\n                    self.error = exc_info[1]\n                elif isinstance(exc_info, BaseException):\n                    self.error = exc_info\n                else:\n                    exc_info = sys.exc_info()\n                    if any(exc_info):\n                        self.error = exc_info[1]\n            if self._read_until_close:\n                self._read_until_close = False\n                self._finish_read(self._read_buffer_size)\n            elif self._read_future is not None:\n                # resolve reads that are pending and ready to complete\n                try:\n                    pos = self._find_read_pos()\n                except UnsatisfiableReadError:\n                    pass\n                else:\n                    if pos is not None:\n                        self._read_from_buffer(pos)\n            if self._state is not None:\n                self.io_loop.remove_handler(self.fileno())\n                self._state = None\n            self.close_fd()\n            self._closed = True\n        self._signal_closed()",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 46,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "_signal_closed",
      "sourceCode": "def _signal_closed(self) -> None:\n        futures = []  # type: List[Future]\n        if self._read_future is not None:\n            futures.append(self._read_future)\n            self._read_future = None\n        futures += [future for _, future in self._write_futures]\n        self._write_futures.clear()\n        if self._connect_future is not None:\n            futures.append(self._connect_future)\n            self._connect_future = None\n        for future in futures:\n            if not future.done():\n                future.set_exception(StreamClosedError(real_error=self.error))\n            # Reference the exception to silence warnings. Annoyingly,\n            # this raises if the future was cancelled, but just\n            # returns any other error.\n            try:\n                future.exception()\n            except asyncio.CancelledError:\n                pass\n        if self._ssl_connect_future is not None:\n            # _ssl_connect_future expects to see the real exception (typically\n            # an ssl.SSLError), not just StreamClosedError.\n            if not self._ssl_connect_future.done():\n                if self.error is not None:\n                    self._ssl_connect_future.set_exception(self.error)\n                else:\n                    self._ssl_connect_future.set_exception(StreamClosedError())\n            self._ssl_connect_future.exception()\n            self._ssl_connect_future = None\n        if self._close_callback is not None:\n            cb = self._close_callback\n            self._close_callback = None\n            self.io_loop.add_callback(cb)\n        # Clear the buffers so they can be cleared immediately even\n        # if the IOStream object is kept alive by a reference cycle.\n        # TODO: Clear the read buffer too; it currently breaks some tests.\n        self._write_buffer = None",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 37,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "set_nodelay",
      "sourceCode": "def set_nodelay(self, value: bool) -> None:\n        \"\"\"Sets the no-delay flag for this stream.\n\n        By default, data written to TCP streams may be held for a time\n        to make the most efficient use of bandwidth (according to\n        Nagle's algorithm).  The no-delay flag requests that data be\n        written as soon as possible, even if doing so would consume\n        additional bandwidth.\n\n        This flag is currently defined only for TCP-based ``IOStreams``.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        pass",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "_handle_events",
      "sourceCode": "def _handle_events(self, fd: Union[int, ioloop._Selectable], events: int) -> None:\n        if self.closed():\n            gen_log.warning(\"Got events for closed stream %s\", fd)\n            return\n        try:\n            if self._connecting:\n                # Most IOLoops will report a write failed connect\n                # with the WRITE event, but SelectIOLoop reports a\n                # READ as well so we must check for connecting before\n                # either.\n                self._handle_connect()\n            if self.closed():\n                return\n            if events & self.io_loop.READ:\n                self._handle_read()\n            if self.closed():\n                return\n            if events & self.io_loop.WRITE:\n                self._handle_write()\n            if self.closed():\n                return\n            if events & self.io_loop.ERROR:\n                self.error = self.get_fd_error()\n                # We may have queued up a user callback in _handle_read or\n                # _handle_write, so don't close the IOStream until those\n                # callbacks have had a chance to run.\n                self.io_loop.add_callback(self.close)\n                return\n            state = self.io_loop.ERROR\n            if self.reading():\n                state |= self.io_loop.READ\n            if self.writing():\n                state |= self.io_loop.WRITE\n            if state == self.io_loop.ERROR and self._read_buffer_size == 0:\n                # If the connection is idle, listen for reads too so\n                # we can tell if the connection is closed.  If there is\n                # data in the read buffer we won't run the close callback\n                # yet anyway, so we don't need to listen in this case.\n                state |= self.io_loop.READ\n            if state != self._state:\n                assert (\n                    self._state is not None\n                ), \"shouldn't happen: _handle_events without self._state\"\n                self._state = state\n                self.io_loop.update_handler(self.fileno(), self._state)\n        except UnsatisfiableReadError as e:\n            gen_log.info(\"Unsatisfiable read, closing connection: %s\" % e)\n            self.close(exc_info=e)\n        except Exception as e:\n            gen_log.error(\"Uncaught exception, closing connection.\", exc_info=True)\n            self.close(exc_info=e)\n            raise",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 51,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "_read_to_buffer_loop",
      "sourceCode": "def _read_to_buffer_loop(self) -> Optional[int]:\n        # This method is called from _handle_read and _try_inline_read.\n        if self._read_bytes is not None:\n            target_bytes = self._read_bytes  # type: Optional[int]\n        elif self._read_max_bytes is not None:\n            target_bytes = self._read_max_bytes\n        elif self.reading():\n            # For read_until without max_bytes, or\n            # read_until_close, read as much as we can before\n            # scanning for the delimiter.\n            target_bytes = None\n        else:\n            target_bytes = 0\n        next_find_pos = 0\n        while not self.closed():\n            # Read from the socket until we get EWOULDBLOCK or equivalent.\n            # SSL sockets do some internal buffering, and if the data is\n            # sitting in the SSL object's buffer select() and friends\n            # can't see it; the only way to find out if it's there is to\n            # try to read it.\n            if self._read_to_buffer() == 0:\n                break\n\n            # If we've read all the bytes we can use, break out of\n            # this loop.\n\n            # If we've reached target_bytes, we know we're done.\n            if target_bytes is not None and self._read_buffer_size >= target_bytes:\n                break\n\n            # Otherwise, we need to call the more expensive find_read_pos.\n            # It's inefficient to do this on every read, so instead\n            # do it on the first read and whenever the read buffer\n            # size has doubled.\n            if self._read_buffer_size >= next_find_pos:\n                pos = self._find_read_pos()\n                if pos is not None:\n                    return pos\n                next_find_pos = self._read_buffer_size * 2\n        return self._find_read_pos()",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 39,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "_handle_read",
      "sourceCode": "def _handle_read(self) -> None:\n        try:\n            pos = self._read_to_buffer_loop()\n        except UnsatisfiableReadError:\n            raise\n        except asyncio.CancelledError:\n            raise\n        except Exception as e:\n            gen_log.warning(\"error on read: %s\" % e)\n            self.close(exc_info=e)\n            return\n        if pos is not None:\n            self._read_from_buffer(pos)",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "_start_read",
      "sourceCode": "def _start_read(self) -> Future:\n        if self._read_future is not None:\n            # It is an error to start a read while a prior read is unresolved.\n            # However, if the prior read is unresolved because the stream was\n            # closed without satisfying it, it's better to raise\n            # StreamClosedError instead of AssertionError. In particular, this\n            # situation occurs in harmless situations in http1connection.py and\n            # an AssertionError would be logged noisily.\n            #\n            # On the other hand, it is legal to start a new read while the\n            # stream is closed, in case the read can be satisfied from the\n            # read buffer. So we only want to check the closed status of the\n            # stream if we need to decide what kind of error to raise for\n            # \"already reading\".\n            #\n            # These conditions have proven difficult to test; we have no\n            # unittests that reliably verify this behavior so be careful\n            # when making changes here. See #2651 and #2719.\n            self._check_closed()\n            assert self._read_future is None, \"Already reading\"\n        self._read_future = Future()\n        return self._read_future",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "_finish_read",
      "sourceCode": "def _finish_read(self, size: int) -> None:\n        if self._user_read_buffer:\n            self._read_buffer = self._after_user_read_buffer or bytearray()\n            self._after_user_read_buffer = None\n            self._read_buffer_size = len(self._read_buffer)\n            self._user_read_buffer = False\n            result = size  # type: Union[int, bytes]\n        else:\n            result = self._consume(size)\n        if self._read_future is not None:\n            future = self._read_future\n            self._read_future = None\n            future_set_result_unless_cancelled(future, result)\n        self._maybe_add_error_listener()",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "_try_inline_read",
      "sourceCode": "def _try_inline_read(self) -> None:\n        \"\"\"Attempt to complete the current read operation from buffered data.\n\n        If the read can be completed without blocking, schedules the\n        read callback on the next IOLoop iteration; otherwise starts\n        listening for reads on the socket.\n        \"\"\"\n        # See if we've already got the data from a previous read\n        pos = self._find_read_pos()\n        if pos is not None:\n            self._read_from_buffer(pos)\n            return\n        self._check_closed()\n        pos = self._read_to_buffer_loop()\n        if pos is not None:\n            self._read_from_buffer(pos)\n            return\n        # We couldn't satisfy the read inline, so make sure we're\n        # listening for new data unless the stream is closed.\n        if not self.closed():\n            self._add_io_state(ioloop.IOLoop.READ)",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "_read_to_buffer",
      "sourceCode": "def _read_to_buffer(self) -> Optional[int]:\n        \"\"\"Reads from the socket and appends the result to the read buffer.\n\n        Returns the number of bytes read.  Returns 0 if there is nothing\n        to read (i.e. the read returns EWOULDBLOCK or equivalent).  On\n        error closes the socket and raises an exception.\n        \"\"\"\n        try:\n            while True:\n                try:\n                    if self._user_read_buffer:\n                        buf = memoryview(self._read_buffer)[\n                            self._read_buffer_size :\n                        ]  # type: Union[memoryview, bytearray]\n                    else:\n                        buf = bytearray(self.read_chunk_size)\n                    bytes_read = self.read_from_fd(buf)\n                except OSError as e:\n                    # ssl.SSLError is a subclass of socket.error\n                    if self._is_connreset(e):\n                        # Treat ECONNRESET as a connection close rather than\n                        # an error to minimize log spam  (the exception will\n                        # be available on self.error for apps that care).\n                        self.close(exc_info=e)\n                        return None\n                    self.close(exc_info=e)\n                    raise\n                break\n            if bytes_read is None:\n                return 0\n            elif bytes_read == 0:\n                self.close()\n                return 0\n            if not self._user_read_buffer:\n                self._read_buffer += memoryview(buf)[:bytes_read]\n            self._read_buffer_size += bytes_read\n        finally:\n            # Break the reference to buf so we don't waste a chunk's worth of\n            # memory in case an exception hangs on to our stack frame.\n            del buf\n        if self._read_buffer_size > self.max_buffer_size:\n            gen_log.error(\"Reached maximum read buffer size\")\n            self.close()\n            raise StreamBufferFullError(\"Reached maximum read buffer size\")\n        return bytes_read",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 44,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "_find_read_pos",
      "sourceCode": "def _find_read_pos(self) -> Optional[int]:\n        \"\"\"Attempts to find a position in the read buffer that satisfies\n        the currently-pending read.\n\n        Returns a position in the buffer if the current read can be satisfied,\n        or None if it cannot.\n        \"\"\"\n        if self._read_bytes is not None and (\n            self._read_buffer_size >= self._read_bytes\n            or (self._read_partial and self._read_buffer_size > 0)\n        ):\n            num_bytes = min(self._read_bytes, self._read_buffer_size)\n            return num_bytes\n        elif self._read_delimiter is not None:\n            # Multi-byte delimiters (e.g. '\\r\\n') may straddle two\n            # chunks in the read buffer, so we can't easily find them\n            # without collapsing the buffer.  However, since protocols\n            # using delimited reads (as opposed to reads of a known\n            # length) tend to be \"line\" oriented, the delimiter is likely\n            # to be in the first few chunks.  Merge the buffer gradually\n            # since large merges are relatively expensive and get undone in\n            # _consume().\n            if self._read_buffer:\n                loc = self._read_buffer.find(self._read_delimiter)\n                if loc != -1:\n                    delimiter_len = len(self._read_delimiter)\n                    self._check_max_bytes(self._read_delimiter, loc + delimiter_len)\n                    return loc + delimiter_len\n                self._check_max_bytes(self._read_delimiter, self._read_buffer_size)\n        elif self._read_regex is not None:\n            if self._read_buffer:\n                m = self._read_regex.search(self._read_buffer)\n                if m is not None:\n                    loc = m.end()\n                    self._check_max_bytes(self._read_regex, loc)\n                    return loc\n                self._check_max_bytes(self._read_regex, self._read_buffer_size)\n        return None",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 37,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "_handle_write",
      "sourceCode": "def _handle_write(self) -> None:\n        while True:\n            size = len(self._write_buffer)\n            if not size:\n                break\n            assert size > 0\n            try:\n                if _WINDOWS:\n                    # On windows, socket.send blows up if given a\n                    # write buffer that's too large, instead of just\n                    # returning the number of bytes it was able to\n                    # process.  Therefore we must not call socket.send\n                    # with more than 128KB at a time.\n                    size = 128 * 1024\n\n                num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n                if num_bytes == 0:\n                    break\n                self._write_buffer.advance(num_bytes)\n                self._total_write_done_index += num_bytes\n            except BlockingIOError:\n                break\n            except OSError as e:\n                if not self._is_connreset(e):\n                    # Broken pipe errors are usually caused by connection\n                    # reset, and its better to not log EPIPE errors to\n                    # minimize log spam\n                    gen_log.warning(\"Write error on %s: %s\", self.fileno(), e)\n                self.close(exc_info=e)\n                return\n\n        while self._write_futures:\n            index, future = self._write_futures[0]\n            if index > self._total_write_done_index:\n                break\n            self._write_futures.popleft()\n            future_set_result_unless_cancelled(future, None)",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 36,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "_maybe_add_error_listener",
      "sourceCode": "def _maybe_add_error_listener(self) -> None:\n        # This method is part of an optimization: to detect a connection that\n        # is closed when we're not actively reading or writing, we must listen\n        # for read events.  However, it is inefficient to do this when the\n        # connection is first established because we are going to read or write\n        # immediately anyway.  Instead, we insert checks at various times to\n        # see if the connection is idle and add the read listener then.\n        if self._state is None or self._state == ioloop.IOLoop.ERROR:\n            if (\n                not self.closed()\n                and self._read_buffer_size == 0\n                and self._close_callback is not None\n            ):\n                self._add_io_state(ioloop.IOLoop.READ)",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "_add_io_state",
      "sourceCode": "def _add_io_state(self, state: int) -> None:\n        \"\"\"Adds `state` (IOLoop.{READ,WRITE} flags) to our event handler.\n\n        Implementation notes: Reads and writes have a fast path and a\n        slow path.  The fast path reads synchronously from socket\n        buffers, while the slow path uses `_add_io_state` to schedule\n        an IOLoop callback.\n\n        To detect closed connections, we must have called\n        `_add_io_state` at some point, but we want to delay this as\n        much as possible so we don't have to set an `IOLoop.ERROR`\n        listener that will be overwritten by the next slow-path\n        operation. If a sequence of fast-path ops do not end in a\n        slow-path op, (e.g. for an @asynchronous long-poll request),\n        we must add the error handler.\n\n        TODO: reevaluate this now that callbacks are gone.\n\n        \"\"\"\n        if self.closed():\n            # connection has been closed, so there can be no future events\n            return\n        if self._state is None:\n            self._state = ioloop.IOLoop.ERROR | state\n            self.io_loop.add_handler(self.fileno(), self._handle_events, self._state)\n        elif not self._state & state:\n            self._state = self._state | state\n            self.io_loop.update_handler(self.fileno(), self._state)",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 27,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "connect",
      "sourceCode": "def connect(\n        self: _IOStreamType, address: Any, server_hostname: Optional[str] = None\n    ) -> \"Future[_IOStreamType]\":\n        \"\"\"Connects the socket to a remote address without blocking.\n\n        May only be called if the socket passed to the constructor was\n        not previously connected.  The address parameter is in the\n        same format as for `socket.connect <socket.socket.connect>` for\n        the type of socket passed to the IOStream constructor,\n        e.g. an ``(ip, port)`` tuple.  Hostnames are accepted here,\n        but will be resolved synchronously and block the IOLoop.\n        If you have a hostname instead of an IP address, the `.TCPClient`\n        class is recommended instead of calling this method directly.\n        `.TCPClient` will do asynchronous DNS resolution and handle\n        both IPv4 and IPv6.\n\n        If ``callback`` is specified, it will be called with no\n        arguments when the connection is completed; if not this method\n        returns a `.Future` (whose result after a successful\n        connection will be the stream itself).\n\n        In SSL mode, the ``server_hostname`` parameter will be used\n        for certificate validation (unless disabled in the\n        ``ssl_options``) and SNI.\n\n        Note that it is safe to call `IOStream.write\n        <BaseIOStream.write>` while the connection is pending, in\n        which case the data will be written as soon as the connection\n        is ready.  Calling `IOStream` read methods before the socket is\n        connected works on some platforms but is non-portable.\n\n        .. versionchanged:: 4.0\n            If no callback is given, returns a `.Future`.\n\n        .. versionchanged:: 4.2\n           SSL certificates are validated by default; pass\n           ``ssl_options=dict(cert_reqs=ssl.CERT_NONE)`` or a\n           suitably-configured `ssl.SSLContext` to the\n           `SSLIOStream` constructor to disable.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           `.Future` instead.\n\n        \"\"\"\n        self._connecting = True\n        future = Future()  # type: Future[_IOStreamType]\n        self._connect_future = typing.cast(\"Future[IOStream]\", future)\n        try:\n            self.socket.connect(address)\n        except BlockingIOError:\n            # In non-blocking mode we expect connect() to raise an\n            # exception with EINPROGRESS or EWOULDBLOCK.\n            pass\n        except OSError as e:\n            # On freebsd, other errors such as ECONNREFUSED may be\n            # returned immediately when attempting to connect to\n            # localhost, so handle them the same way as an error\n            # reported later in _handle_connect.\n            if future is None:\n                gen_log.warning(\"Connect error on fd %s: %s\", self.socket.fileno(), e)\n            self.close(exc_info=e)\n            return future\n        self._add_io_state(self.io_loop.WRITE)\n        return future",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 65,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "start_tls",
      "sourceCode": "def start_tls(\n        self,\n        server_side: bool,\n        ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n        server_hostname: Optional[str] = None,\n    ) -> Awaitable[\"SSLIOStream\"]:\n        \"\"\"Convert this `IOStream` to an `SSLIOStream`.\n\n        This enables protocols that begin in clear-text mode and\n        switch to SSL after some initial negotiation (such as the\n        ``STARTTLS`` extension to SMTP and IMAP).\n\n        This method cannot be used if there are outstanding reads\n        or writes on the stream, or if there is any data in the\n        IOStream's buffer (data in the operating system's socket\n        buffer is allowed).  This means it must generally be used\n        immediately after reading or writing the last clear-text\n        data.  It can also be used immediately after connecting,\n        before any reads or writes.\n\n        The ``ssl_options`` argument may be either an `ssl.SSLContext`\n        object or a dictionary of keyword arguments for the\n        `ssl.SSLContext.wrap_socket` function.  The ``server_hostname`` argument\n        will be used for certificate validation unless disabled\n        in the ``ssl_options``.\n\n        This method returns a `.Future` whose result is the new\n        `SSLIOStream`.  After this method has been called,\n        any other operation on the original stream is undefined.\n\n        If a close callback is defined on this stream, it will be\n        transferred to the new stream.\n\n        .. versionadded:: 4.0\n\n        .. versionchanged:: 4.2\n           SSL certificates are validated by default; pass\n           ``ssl_options=dict(cert_reqs=ssl.CERT_NONE)`` or a\n           suitably-configured `ssl.SSLContext` to disable.\n        \"\"\"\n        if (\n            self._read_future\n            or self._write_futures\n            or self._connect_future\n            or self._closed\n            or self._read_buffer\n            or self._write_buffer\n        ):\n            raise ValueError(\"IOStream is not idle; cannot convert to SSL\")\n        if ssl_options is None:\n            if server_side:\n                ssl_options = _server_ssl_defaults\n            else:\n                ssl_options = _client_ssl_defaults\n\n        socket = self.socket\n        self.io_loop.remove_handler(socket)\n        self.socket = None  # type: ignore\n        socket = ssl_wrap_socket(\n            socket,\n            ssl_options,\n            server_hostname=server_hostname,\n            server_side=server_side,\n            do_handshake_on_connect=False,\n        )\n        orig_close_callback = self._close_callback\n        self._close_callback = None\n\n        future = Future()  # type: Future[SSLIOStream]\n        ssl_stream = SSLIOStream(socket, ssl_options=ssl_options)\n        ssl_stream.set_close_callback(orig_close_callback)\n        ssl_stream._ssl_connect_future = future\n        ssl_stream.max_buffer_size = self.max_buffer_size\n        ssl_stream.read_chunk_size = self.read_chunk_size\n        return future",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 74,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "_handle_connect",
      "sourceCode": "def _handle_connect(self) -> None:\n        try:\n            err = self.socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)\n        except OSError as e:\n            # Hurd doesn't allow SO_ERROR for loopback sockets because all\n            # errors for such sockets are reported synchronously.\n            if errno_from_exception(e) == errno.ENOPROTOOPT:\n                err = 0\n        if err != 0:\n            self.error = socket.error(err, os.strerror(err))\n            # IOLoop implementations may vary: some of them return\n            # an error state before the socket becomes writable, so\n            # in that case a connection failure would be handled by the\n            # error path in _handle_events instead of here.\n            if self._connect_future is None:\n                gen_log.warning(\n                    \"Connect error on fd %s: %s\",\n                    self.socket.fileno(),\n                    errno.errorcode[err],\n                )\n            self.close()\n            return\n        if self._connect_future is not None:\n            future = self._connect_future\n            self._connect_future = None\n            future_set_result_unless_cancelled(future, self)\n        self._connecting = False",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 26,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "set_nodelay",
      "sourceCode": "def set_nodelay(self, value: bool) -> None:\n        if self.socket is not None and self.socket.family in (\n            socket.AF_INET,\n            socket.AF_INET6,\n        ):\n            try:\n                self.socket.setsockopt(\n                    socket.IPPROTO_TCP, socket.TCP_NODELAY, 1 if value else 0\n                )\n            except OSError as e:\n                # Sometimes setsockopt will fail if the socket is closed\n                # at the wrong time.  This can happen with HTTPServer\n                # resetting the value to ``False`` between requests.\n                if e.errno != errno.EINVAL and not self._is_connreset(e):\n                    raise",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(self, *args: Any, **kwargs: Any) -> None:\n        \"\"\"The ``ssl_options`` keyword argument may either be an\n        `ssl.SSLContext` object or a dictionary of keywords arguments\n        for `ssl.SSLContext.wrap_socket`\n        \"\"\"\n        self._ssl_options = kwargs.pop(\"ssl_options\", _client_ssl_defaults)\n        super().__init__(*args, **kwargs)\n        self._ssl_accepting = True\n        self._handshake_reading = False\n        self._handshake_writing = False\n        self._server_hostname = None  # type: Optional[str]\n\n        # If the socket is already connected, attempt to start the handshake.\n        try:\n            self.socket.getpeername()\n        except OSError:\n            pass\n        else:\n            # Indirectly start the handshake, which will run on the next\n            # IOLoop iteration and then the real IO state will be set in\n            # _handle_events.\n            self._add_io_state(self.io_loop.WRITE)",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "_do_ssl_handshake",
      "sourceCode": "def _do_ssl_handshake(self) -> None:\n        # Based on code from test_ssl.py in the python stdlib\n        try:\n            self._handshake_reading = False\n            self._handshake_writing = False\n            self.socket.do_handshake()\n        except ssl.SSLError as err:\n            if err.args[0] == ssl.SSL_ERROR_WANT_READ:\n                self._handshake_reading = True\n                return\n            elif err.args[0] == ssl.SSL_ERROR_WANT_WRITE:\n                self._handshake_writing = True\n                return\n            elif err.args[0] in (ssl.SSL_ERROR_EOF, ssl.SSL_ERROR_ZERO_RETURN):\n                return self.close(exc_info=err)\n            elif err.args[0] in (ssl.SSL_ERROR_SSL, ssl.SSL_ERROR_SYSCALL):\n                try:\n                    peer = self.socket.getpeername()\n                except Exception:\n                    peer = \"(not connected)\"\n                gen_log.warning(\n                    \"SSL Error on %s %s: %s\", self.socket.fileno(), peer, err\n                )\n                return self.close(exc_info=err)\n            raise\n        except OSError as err:\n            # Some port scans (e.g. nmap in -sT mode) have been known\n            # to cause do_handshake to raise EBADF and ENOTCONN, so make\n            # those errors quiet as well.\n            # https://groups.google.com/forum/?fromgroups#!topic/python-tornado/ApucKJat1_0\n            # Errno 0 is also possible in some cases (nc -z).\n            # https://github.com/tornadoweb/tornado/issues/2504\n            if self._is_connreset(err) or err.args[0] in (\n                0,\n                errno.EBADF,\n                errno.ENOTCONN,\n            ):\n                return self.close(exc_info=err)\n            raise\n        except AttributeError as err:\n            # On Linux, if the connection was reset before the call to\n            # wrap_socket, do_handshake will fail with an\n            # AttributeError.\n            return self.close(exc_info=err)\n        else:\n            self._ssl_accepting = False\n            # Prior to the introduction of SNI, this is where we would check\n            # the server's claimed hostname.\n            assert ssl.HAS_SNI\n            self._finish_ssl_connect()",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 49,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "connect",
      "sourceCode": "def connect(\n        self, address: Tuple, server_hostname: Optional[str] = None\n    ) -> \"Future[SSLIOStream]\":\n        self._server_hostname = server_hostname\n        # Ignore the result of connect(). If it fails,\n        # wait_for_handshake will raise an error too. This is\n        # necessary for the old semantics of the connect callback\n        # (which takes no arguments). In 6.0 this can be refactored to\n        # be a regular coroutine.\n        # TODO: This is trickier than it looks, since if write()\n        # is called with a connect() pending, we want the connect\n        # to resolve before the write. Or do we care about this?\n        # (There's a test for it, but I think in practice users\n        # either wait for the connect before performing a write or\n        # they don't care about the connect Future at all)\n        fut = super().connect(address)\n        fut.add_done_callback(lambda f: f.exception())\n        return self.wait_for_handshake()",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 17,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "_handle_connect",
      "sourceCode": "def _handle_connect(self) -> None:\n        # Call the superclass method to check for errors.\n        super()._handle_connect()\n        if self.closed():\n            return\n        # When the connection is complete, wrap the socket for SSL\n        # traffic.  Note that we do this by overriding _handle_connect\n        # instead of by passing a callback to super().connect because\n        # user callbacks are enqueued asynchronously on the IOLoop,\n        # but since _handle_events calls _handle_connect immediately\n        # followed by _handle_write we need this to be synchronous.\n        #\n        # The IOLoop will get confused if we swap out self.socket while the\n        # fd is registered, so remove it now and re-register after\n        # wrap_socket().\n        self.io_loop.remove_handler(self.socket)\n        old_state = self._state\n        assert old_state is not None\n        self._state = None\n        self.socket = ssl_wrap_socket(\n            self.socket,\n            self._ssl_options,\n            server_hostname=self._server_hostname,\n            do_handshake_on_connect=False,\n            server_side=False,\n        )\n        self._add_io_state(old_state)",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 26,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "wait_for_handshake",
      "sourceCode": "def wait_for_handshake(self) -> \"Future[SSLIOStream]\":\n        \"\"\"Wait for the initial SSL handshake to complete.\n\n        If a ``callback`` is given, it will be called with no\n        arguments once the handshake is complete; otherwise this\n        method returns a `.Future` which will resolve to the\n        stream itself after the handshake is complete.\n\n        Once the handshake is complete, information such as\n        the peer's certificate and NPN/ALPN selections may be\n        accessed on ``self.socket``.\n\n        This method is intended for use on server-side streams\n        or after using `IOStream.start_tls`; it should not be used\n        with `IOStream.connect` (which already waits for the\n        handshake to complete). It may only be called once per stream.\n\n        .. versionadded:: 4.2\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           `.Future` instead.\n\n        \"\"\"\n        if self._ssl_connect_future is not None:\n            raise RuntimeError(\"Already waiting\")\n        future = self._ssl_connect_future = Future()\n        if not self._ssl_accepting:\n            self._finish_ssl_connect()\n        return future",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 30,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "write_to_fd",
      "sourceCode": "def write_to_fd(self, data: memoryview) -> int:\n        # clip buffer size at 1GB since SSL sockets only support upto 2GB\n        # this change in behaviour is transparent, since the function is\n        # already expected to (possibly) write less than the provided buffer\n        if len(data) >> 30:\n            data = memoryview(data)[: 1 << 30]\n        try:\n            return self.socket.send(data)  # type: ignore\n        except ssl.SSLError as e:\n            if e.args[0] == ssl.SSL_ERROR_WANT_WRITE:\n                # In Python 3.5+, SSLSocket.send raises a WANT_WRITE error if\n                # the socket is not writeable; we need to transform this into\n                # an EWOULDBLOCK socket.error or a zero return value,\n                # either of which will be recognized by the caller of this\n                # method. Prior to Python 3.5, an unwriteable socket would\n                # simply return 0 bytes written.\n                return 0\n            raise\n        finally:\n            # Avoid keeping to data, which can be a memoryview.\n            # See https://github.com/tornadoweb/tornado/pull/2008\n            del data",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "read_from_fd",
      "sourceCode": "def read_from_fd(self, buf: Union[bytearray, memoryview]) -> Optional[int]:\n        try:\n            if self._ssl_accepting:\n                # If the handshake hasn't finished yet, there can't be anything\n                # to read (attempting to read may or may not raise an exception\n                # depending on the SSL version)\n                return None\n            # clip buffer size at 1GB since SSL sockets only support upto 2GB\n            # this change in behaviour is transparent, since the function is\n            # already expected to (possibly) read less than the provided buffer\n            if len(buf) >> 30:\n                buf = memoryview(buf)[: 1 << 30]\n            try:\n                return self.socket.recv_into(buf, len(buf))\n            except ssl.SSLError as e:\n                # SSLError is a subclass of socket.error, so this except\n                # block must come first.\n                if e.args[0] == ssl.SSL_ERROR_WANT_READ:\n                    return None\n                else:\n                    raise\n            except BlockingIOError:\n                return None\n        finally:\n            del buf",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 24,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(self, fd: int, *args: Any, **kwargs: Any) -> None:\n        self.fd = fd\n        self._fio = io.FileIO(self.fd, \"r+\")\n        if sys.platform == \"win32\":\n            # The form and placement of this assertion is important to mypy.\n            # A plain assert statement isn't recognized here. If the assertion\n            # were earlier it would worry that the attributes of self aren't\n            # set on windows. If it were missing it would complain about\n            # the absence of the set_blocking function.\n            raise AssertionError(\"PipeIOStream is not supported on Windows\")\n        os.set_blocking(fd, False)\n        super().__init__(*args, **kwargs)",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "read_from_fd",
      "sourceCode": "def read_from_fd(self, buf: Union[bytearray, memoryview]) -> Optional[int]:\n        try:\n            return self._fio.readinto(buf)  # type: ignore\n        except OSError as e:\n            if errno_from_exception(e) == errno.EBADF:\n                # If the writing half of a pipe is closed, select will\n                # report it as readable but reads will fail with EBADF.\n                self.close(exc_info=e)\n                return None\n            else:\n                raise\n        finally:\n            del buf",
      "importString": "import collections\nimport errno\nimport io\nimport numbers\nimport os\nimport socket\nimport ssl\nimport sys\nimport re\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\nUnion\nOptional\nAwaitable\nCallable\nPattern\nAny\nDict\nTypeVar\nTuple\n)\nfrom types import TracebackType",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/iostream.py"
    },
    {
      "symbolName": "get",
      "sourceCode": "def get(*locale_codes: str) -> \"Locale\":\n    \"\"\"Returns the closest match for the given locale codes.\n\n    We iterate over all given locale codes in order. If we have a tight\n    or a loose match for the code (e.g., \"en\" for \"en_US\"), we return\n    the locale. Otherwise we move to the next code in the list.\n\n    By default we return ``en_US`` if no translations are found for any of\n    the specified locales. You can change the default locale with\n    `set_default_locale()`.\n    \"\"\"\n    return Locale.get_closest(*locale_codes)",
      "importString": "import codecs\nimport csv\nimport datetime\nimport gettext\nimport glob\nimport os\nimport re\nfrom tornado import escape\nfrom tornado.log import gen_log\n\nfrom tornado._locale_data import LOCALE_NAMES\n\nfrom typing import Iterable, Any, Union, Dict, Optional",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/locale.py"
    },
    {
      "symbolName": "set_default_locale",
      "sourceCode": "def set_default_locale(code: str) -> None:\n    \"\"\"Sets the default locale.\n\n    The default locale is assumed to be the language used for all strings\n    in the system. The translations loaded from disk are mappings from\n    the default locale to the destination locale. Consequently, you don't\n    need to create a translation file for the default locale.\n    \"\"\"\n    global _default_locale\n    global _supported_locales\n    _default_locale = code\n    _supported_locales = frozenset(list(_translations.keys()) + [_default_locale])",
      "importString": "import codecs\nimport csv\nimport datetime\nimport gettext\nimport glob\nimport os\nimport re\nfrom tornado import escape\nfrom tornado.log import gen_log\n\nfrom tornado._locale_data import LOCALE_NAMES\n\nfrom typing import Iterable, Any, Union, Dict, Optional",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/locale.py"
    },
    {
      "symbolName": "load_translations",
      "sourceCode": "def load_translations(directory: str, encoding: Optional[str] = None) -> None:\n    \"\"\"Loads translations from CSV files in a directory.\n\n    Translations are strings with optional Python-style named placeholders\n    (e.g., ``My name is %(name)s``) and their associated translations.\n\n    The directory should have translation files of the form ``LOCALE.csv``,\n    e.g. ``es_GT.csv``. The CSV files should have two or three columns: string,\n    translation, and an optional plural indicator. Plural indicators should\n    be one of \"plural\" or \"singular\". A given string can have both singular\n    and plural forms. For example ``%(name)s liked this`` may have a\n    different verb conjugation depending on whether %(name)s is one\n    name or a list of names. There should be two rows in the CSV file for\n    that string, one with plural indicator \"singular\", and one \"plural\".\n    For strings with no verbs that would change on translation, simply\n    use \"unknown\" or the empty string (or don't include the column at all).\n\n    The file is read using the `csv` module in the default \"excel\" dialect.\n    In this format there should not be spaces after the commas.\n\n    If no ``encoding`` parameter is given, the encoding will be\n    detected automatically (among UTF-8 and UTF-16) if the file\n    contains a byte-order marker (BOM), defaulting to UTF-8 if no BOM\n    is present.\n\n    Example translation ``es_LA.csv``::\n\n        \"I love you\",\"Te amo\"\n        \"%(name)s liked this\",\"A %(name)s les gustó esto\",\"plural\"\n        \"%(name)s liked this\",\"A %(name)s le gustó esto\",\"singular\"\n\n    .. versionchanged:: 4.3\n       Added ``encoding`` parameter. Added support for BOM-based encoding\n       detection, UTF-16, and UTF-8-with-BOM.\n    \"\"\"\n    global _translations\n    global _supported_locales\n    _translations = {}\n    for path in os.listdir(directory):\n        if not path.endswith(\".csv\"):\n            continue\n        locale, extension = path.split(\".\")\n        if not re.match(\"[a-z]+(_[A-Z]+)?$\", locale):\n            gen_log.error(\n                \"Unrecognized locale %r (path: %s)\",\n                locale,\n                os.path.join(directory, path),\n            )\n            continue\n        full_path = os.path.join(directory, path)\n        if encoding is None:\n            # Try to autodetect encoding based on the BOM.\n            with open(full_path, \"rb\") as bf:\n                data = bf.read(len(codecs.BOM_UTF16_LE))\n            if data in (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE):\n                encoding = \"utf-16\"\n            else:\n                # utf-8-sig is \"utf-8 with optional BOM\". It's discouraged\n                # in most cases but is common with CSV files because Excel\n                # cannot read utf-8 files without a BOM.\n                encoding = \"utf-8-sig\"\n        # python 3: csv.reader requires a file open in text mode.\n        # Specify an encoding to avoid dependence on $LANG environment variable.\n        with open(full_path, encoding=encoding) as f:\n            _translations[locale] = {}\n            for i, row in enumerate(csv.reader(f)):\n                if not row or len(row) < 2:\n                    continue\n                row = [escape.to_unicode(c).strip() for c in row]\n                english, translation = row[:2]\n                if len(row) > 2:\n                    plural = row[2] or \"unknown\"\n                else:\n                    plural = \"unknown\"\n                if plural not in (\"plural\", \"singular\", \"unknown\"):\n                    gen_log.error(\n                        \"Unrecognized plural indicator %r in %s line %d\",\n                        plural,\n                        path,\n                        i + 1,\n                    )\n                    continue\n                _translations[locale].setdefault(plural, {})[english] = translation\n    _supported_locales = frozenset(list(_translations.keys()) + [_default_locale])\n    gen_log.debug(\"Supported locales: %s\", sorted(_supported_locales))",
      "importString": "import codecs\nimport csv\nimport datetime\nimport gettext\nimport glob\nimport os\nimport re\nfrom tornado import escape\nfrom tornado.log import gen_log\n\nfrom tornado._locale_data import LOCALE_NAMES\n\nfrom typing import Iterable, Any, Union, Dict, Optional",
      "lineNum": 84,
      "relativeDocumentPath": "tornado/locale.py"
    },
    {
      "symbolName": "load_gettext_translations",
      "sourceCode": "def load_gettext_translations(directory: str, domain: str) -> None:\n    \"\"\"Loads translations from `gettext`'s locale tree\n\n    Locale tree is similar to system's ``/usr/share/locale``, like::\n\n        {directory}/{lang}/LC_MESSAGES/{domain}.mo\n\n    Three steps are required to have your app translated:\n\n    1. Generate POT translation file::\n\n        xgettext --language=Python --keyword=_:1,2 -d mydomain file1.py file2.html etc\n\n    2. Merge against existing POT file::\n\n        msgmerge old.po mydomain.po > new.po\n\n    3. Compile::\n\n        msgfmt mydomain.po -o {directory}/pt_BR/LC_MESSAGES/mydomain.mo\n    \"\"\"\n    global _translations\n    global _supported_locales\n    global _use_gettext\n    _translations = {}\n\n    for filename in glob.glob(\n        os.path.join(directory, \"*\", \"LC_MESSAGES\", domain + \".mo\")\n    ):\n        lang = os.path.basename(os.path.dirname(os.path.dirname(filename)))\n        try:\n            _translations[lang] = gettext.translation(\n                domain, directory, languages=[lang]\n            )\n        except Exception as e:\n            gen_log.error(\"Cannot load translation for '%s': %s\", lang, str(e))\n            continue\n    _supported_locales = frozenset(list(_translations.keys()) + [_default_locale])\n    _use_gettext = True\n    gen_log.debug(\"Supported locales: %s\", sorted(_supported_locales))",
      "importString": "import codecs\nimport csv\nimport datetime\nimport gettext\nimport glob\nimport os\nimport re\nfrom tornado import escape\nfrom tornado.log import gen_log\n\nfrom tornado._locale_data import LOCALE_NAMES\n\nfrom typing import Iterable, Any, Union, Dict, Optional",
      "lineNum": 39,
      "relativeDocumentPath": "tornado/locale.py"
    },
    {
      "symbolName": "get_closest",
      "sourceCode": "@classmethod\n    def get_closest(cls, *locale_codes: str) -> \"Locale\":\n        \"\"\"Returns the closest match for the given locale code.\"\"\"\n        for code in locale_codes:\n            if not code:\n                continue\n            code = code.replace(\"-\", \"_\")\n            parts = code.split(\"_\")\n            if len(parts) > 2:\n                continue\n            elif len(parts) == 2:\n                code = parts[0].lower() + \"_\" + parts[1].upper()\n            if code in _supported_locales:\n                return cls.get(code)\n            if parts[0].lower() in _supported_locales:\n                return cls.get(parts[0].lower())\n        return cls.get(_default_locale)",
      "importString": "import codecs\nimport csv\nimport datetime\nimport gettext\nimport glob\nimport os\nimport re\nfrom tornado import escape\nfrom tornado.log import gen_log\n\nfrom tornado._locale_data import LOCALE_NAMES\n\nfrom typing import Iterable, Any, Union, Dict, Optional",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/locale.py"
    },
    {
      "symbolName": "get",
      "sourceCode": "@classmethod\n    def get(cls, code: str) -> \"Locale\":\n        \"\"\"Returns the Locale for the given locale code.\n\n        If it is not supported, we raise an exception.\n        \"\"\"\n        if code not in cls._cache:\n            assert code in _supported_locales\n            translations = _translations.get(code, None)\n            if translations is None:\n                locale = CSVLocale(code, {})  # type: Locale\n            elif _use_gettext:\n                locale = GettextLocale(code, translations)\n            else:\n                locale = CSVLocale(code, translations)\n            cls._cache[code] = locale\n        return cls._cache[code]",
      "importString": "import codecs\nimport csv\nimport datetime\nimport gettext\nimport glob\nimport os\nimport re\nfrom tornado import escape\nfrom tornado.log import gen_log\n\nfrom tornado._locale_data import LOCALE_NAMES\n\nfrom typing import Iterable, Any, Union, Dict, Optional",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/locale.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(self, code: str) -> None:\n        self.code = code\n        self.name = LOCALE_NAMES.get(code, {}).get(\"name\", \"Unknown\")\n        self.rtl = False\n        for prefix in [\"fa\", \"ar\", \"he\"]:\n            if self.code.startswith(prefix):\n                self.rtl = True\n                break\n\n        # Initialize strings for date formatting\n        _ = self.translate\n        self._months = [\n            _(\"January\"),\n            _(\"February\"),\n            _(\"March\"),\n            _(\"April\"),\n            _(\"May\"),\n            _(\"June\"),\n            _(\"July\"),\n            _(\"August\"),\n            _(\"September\"),\n            _(\"October\"),\n            _(\"November\"),\n            _(\"December\"),\n        ]\n        self._weekdays = [\n            _(\"Monday\"),\n            _(\"Tuesday\"),\n            _(\"Wednesday\"),\n            _(\"Thursday\"),\n            _(\"Friday\"),\n            _(\"Saturday\"),\n            _(\"Sunday\"),\n        ]",
      "importString": "import codecs\nimport csv\nimport datetime\nimport gettext\nimport glob\nimport os\nimport re\nfrom tornado import escape\nfrom tornado.log import gen_log\n\nfrom tornado._locale_data import LOCALE_NAMES\n\nfrom typing import Iterable, Any, Union, Dict, Optional",
      "lineNum": 33,
      "relativeDocumentPath": "tornado/locale.py"
    },
    {
      "symbolName": "translate",
      "sourceCode": "def translate(\n        self,\n        message: str,\n        plural_message: Optional[str] = None,\n        count: Optional[int] = None,\n    ) -> str:\n        \"\"\"Returns the translation for the given message for this locale.\n\n        If ``plural_message`` is given, you must also provide\n        ``count``. We return ``plural_message`` when ``count != 1``,\n        and we return the singular form for the given message when\n        ``count == 1``.\n        \"\"\"\n        raise NotImplementedError()",
      "importString": "import codecs\nimport csv\nimport datetime\nimport gettext\nimport glob\nimport os\nimport re\nfrom tornado import escape\nfrom tornado.log import gen_log\n\nfrom tornado._locale_data import LOCALE_NAMES\n\nfrom typing import Iterable, Any, Union, Dict, Optional",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/locale.py"
    },
    {
      "symbolName": "format_date",
      "sourceCode": "def format_date(\n        self,\n        date: Union[int, float, datetime.datetime],\n        gmt_offset: int = 0,\n        relative: bool = True,\n        shorter: bool = False,\n        full_format: bool = False,\n    ) -> str:\n        \"\"\"Formats the given date.\n\n        By default, we return a relative time (e.g., \"2 minutes ago\"). You\n        can return an absolute date string with ``relative=False``.\n\n        You can force a full format date (\"July 10, 1980\") with\n        ``full_format=True``.\n\n        This method is primarily intended for dates in the past.\n        For dates in the future, we fall back to full format.\n\n        .. versionchanged:: 6.4\n           Aware `datetime.datetime` objects are now supported (naive\n           datetimes are still assumed to be UTC).\n        \"\"\"\n        if isinstance(date, (int, float)):\n            date = datetime.datetime.fromtimestamp(date, datetime.timezone.utc)\n        if date.tzinfo is None:\n            date = date.replace(tzinfo=datetime.timezone.utc)\n        now = datetime.datetime.now(datetime.timezone.utc)\n        if date > now:\n            if relative and (date - now).seconds < 60:\n                # Due to click skew, things are some things slightly\n                # in the future. Round timestamps in the immediate\n                # future down to now in relative mode.\n                date = now\n            else:\n                # Otherwise, future dates always use the full format.\n                full_format = True\n        local_date = date - datetime.timedelta(minutes=gmt_offset)\n        local_now = now - datetime.timedelta(minutes=gmt_offset)\n        local_yesterday = local_now - datetime.timedelta(hours=24)\n        difference = now - date\n        seconds = difference.seconds\n        days = difference.days\n\n        _ = self.translate\n        format = None\n        if not full_format:\n            if relative and days == 0:\n                if seconds < 50:\n                    return _(\"1 second ago\", \"%(seconds)d seconds ago\", seconds) % {\n                        \"seconds\": seconds\n                    }\n\n                if seconds < 50 * 60:\n                    minutes = round(seconds / 60.0)\n                    return _(\"1 minute ago\", \"%(minutes)d minutes ago\", minutes) % {\n                        \"minutes\": minutes\n                    }\n\n                hours = round(seconds / (60.0 * 60))\n                return _(\"1 hour ago\", \"%(hours)d hours ago\", hours) % {\"hours\": hours}\n\n            if days == 0:\n                format = _(\"%(time)s\")\n            elif days == 1 and local_date.day == local_yesterday.day and relative:\n                format = _(\"yesterday\") if shorter else _(\"yesterday at %(time)s\")\n            elif days < 5:\n                format = _(\"%(weekday)s\") if shorter else _(\"%(weekday)s at %(time)s\")\n            elif days < 334:  # 11mo, since confusing for same month last year\n                format = (\n                    _(\"%(month_name)s %(day)s\")\n                    if shorter\n                    else _(\"%(month_name)s %(day)s at %(time)s\")\n                )\n\n        if format is None:\n            format = (\n                _(\"%(month_name)s %(day)s, %(year)s\")\n                if shorter\n                else _(\"%(month_name)s %(day)s, %(year)s at %(time)s\")\n            )\n\n        tfhour_clock = self.code not in (\"en\", \"en_US\", \"zh_CN\")\n        if tfhour_clock:\n            str_time = \"%d:%02d\" % (local_date.hour, local_date.minute)\n        elif self.code == \"zh_CN\":\n            str_time = \"%s%d:%02d\" % (\n                (\"\\u4e0a\\u5348\", \"\\u4e0b\\u5348\")[local_date.hour >= 12],\n                local_date.hour % 12 or 12,\n                local_date.minute,\n            )\n        else:\n            str_time = \"%d:%02d %s\" % (\n                local_date.hour % 12 or 12,\n                local_date.minute,\n                (\"am\", \"pm\")[local_date.hour >= 12],\n            )\n\n        return format % {\n            \"month_name\": self._months[local_date.month - 1],\n            \"weekday\": self._weekdays[local_date.weekday()],\n            \"day\": str(local_date.day),\n            \"year\": str(local_date.year),\n            \"time\": str_time,\n        }",
      "importString": "import codecs\nimport csv\nimport datetime\nimport gettext\nimport glob\nimport os\nimport re\nfrom tornado import escape\nfrom tornado.log import gen_log\n\nfrom tornado._locale_data import LOCALE_NAMES\n\nfrom typing import Iterable, Any, Union, Dict, Optional",
      "lineNum": 104,
      "relativeDocumentPath": "tornado/locale.py"
    },
    {
      "symbolName": "format_day",
      "sourceCode": "def format_day(\n        self, date: datetime.datetime, gmt_offset: int = 0, dow: bool = True\n    ) -> bool:\n        \"\"\"Formats the given date as a day of week.\n\n        Example: \"Monday, January 22\". You can remove the day of week with\n        ``dow=False``.\n        \"\"\"\n        local_date = date - datetime.timedelta(minutes=gmt_offset)\n        _ = self.translate\n        if dow:\n            return _(\"%(weekday)s, %(month_name)s %(day)s\") % {\n                \"month_name\": self._months[local_date.month - 1],\n                \"weekday\": self._weekdays[local_date.weekday()],\n                \"day\": str(local_date.day),\n            }\n        else:\n            return _(\"%(month_name)s %(day)s\") % {\n                \"month_name\": self._months[local_date.month - 1],\n                \"day\": str(local_date.day),\n            }",
      "importString": "import codecs\nimport csv\nimport datetime\nimport gettext\nimport glob\nimport os\nimport re\nfrom tornado import escape\nfrom tornado.log import gen_log\n\nfrom tornado._locale_data import LOCALE_NAMES\n\nfrom typing import Iterable, Any, Union, Dict, Optional",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/locale.py"
    },
    {
      "symbolName": "list",
      "sourceCode": "def list(self, parts: Any) -> str:\n        \"\"\"Returns a comma-separated list for the given list of parts.\n\n        The format is, e.g., \"A, B and C\", \"A and B\" or just \"A\" for lists\n        of size 1.\n        \"\"\"\n        _ = self.translate\n        if len(parts) == 0:\n            return \"\"\n        if len(parts) == 1:\n            return parts[0]\n        comma = \" \\u0648 \" if self.code.startswith(\"fa\") else \", \"\n        return _(\"%(commas)s and %(last)s\") % {\n            \"commas\": comma.join(parts[:-1]),\n            \"last\": parts[len(parts) - 1],\n        }",
      "importString": "import codecs\nimport csv\nimport datetime\nimport gettext\nimport glob\nimport os\nimport re\nfrom tornado import escape\nfrom tornado.log import gen_log\n\nfrom tornado._locale_data import LOCALE_NAMES\n\nfrom typing import Iterable, Any, Union, Dict, Optional",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/locale.py"
    },
    {
      "symbolName": "translate",
      "sourceCode": "def translate(\n        self,\n        message: str,\n        plural_message: Optional[str] = None,\n        count: Optional[int] = None,\n    ) -> str:\n        if plural_message is not None:\n            assert count is not None\n            if count != 1:\n                message = plural_message\n                message_dict = self.translations.get(\"plural\", {})\n            else:\n                message_dict = self.translations.get(\"singular\", {})\n        else:\n            message_dict = self.translations.get(\"unknown\", {})\n        return message_dict.get(message, message)",
      "importString": "import codecs\nimport csv\nimport datetime\nimport gettext\nimport glob\nimport os\nimport re\nfrom tornado import escape\nfrom tornado.log import gen_log\n\nfrom tornado._locale_data import LOCALE_NAMES\n\nfrom typing import Iterable, Any, Union, Dict, Optional",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/locale.py"
    },
    {
      "symbolName": "translate",
      "sourceCode": "def translate(\n        self,\n        message: str,\n        plural_message: Optional[str] = None,\n        count: Optional[int] = None,\n    ) -> str:\n        if plural_message is not None:\n            assert count is not None\n            return self.ngettext(message, plural_message, count)\n        else:\n            return self.gettext(message)",
      "importString": "import codecs\nimport csv\nimport datetime\nimport gettext\nimport glob\nimport os\nimport re\nfrom tornado import escape\nfrom tornado.log import gen_log\n\nfrom tornado._locale_data import LOCALE_NAMES\n\nfrom typing import Iterable, Any, Union, Dict, Optional",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/locale.py"
    },
    {
      "symbolName": "pgettext",
      "sourceCode": "def pgettext(\n        self,\n        context: str,\n        message: str,\n        plural_message: Optional[str] = None,\n        count: Optional[int] = None,\n    ) -> str:\n        \"\"\"Allows to set context for translation, accepts plural forms.\n\n        Usage example::\n\n            pgettext(\"law\", \"right\")\n            pgettext(\"good\", \"right\")\n\n        Plural message example::\n\n            pgettext(\"organization\", \"club\", \"clubs\", len(clubs))\n            pgettext(\"stick\", \"club\", \"clubs\", len(clubs))\n\n        To generate POT file with context, add following options to step 1\n        of `load_gettext_translations` sequence::\n\n            xgettext [basic options] --keyword=pgettext:1c,2 --keyword=pgettext:1c,2,3\n\n        .. versionadded:: 4.2\n        \"\"\"\n        if plural_message is not None:\n            assert count is not None\n            msgs_with_ctxt = (\n                f\"{context}{CONTEXT_SEPARATOR}{message}\",\n                f\"{context}{CONTEXT_SEPARATOR}{plural_message}\",\n                count,\n            )\n            result = self.ngettext(*msgs_with_ctxt)\n            if CONTEXT_SEPARATOR in result:\n                # Translation not found\n                result = self.ngettext(message, plural_message, count)\n            return result\n        else:\n            msg_with_ctxt = f\"{context}{CONTEXT_SEPARATOR}{message}\"\n            result = self.gettext(msg_with_ctxt)\n            if CONTEXT_SEPARATOR in result:\n                # Translation not found\n                result = message\n            return result",
      "importString": "import codecs\nimport csv\nimport datetime\nimport gettext\nimport glob\nimport os\nimport re\nfrom tornado import escape\nfrom tornado.log import gen_log\n\nfrom tornado._locale_data import LOCALE_NAMES\n\nfrom typing import Iterable, Any, Union, Dict, Optional",
      "lineNum": 44,
      "relativeDocumentPath": "tornado/locale.py"
    },
    {
      "symbolName": "wait",
      "sourceCode": "def wait(\n        self, timeout: Optional[Union[float, datetime.timedelta]] = None\n    ) -> Awaitable[bool]:\n        \"\"\"Wait for `.notify`.\n\n        Returns a `.Future` that resolves ``True`` if the condition is notified,\n        or ``False`` after a timeout.\n        \"\"\"\n        waiter = Future()  # type: Future[bool]\n        self._waiters.append(waiter)\n        if timeout:\n\n            def on_timeout() -> None:\n                if not waiter.done():\n                    future_set_result_unless_cancelled(waiter, False)\n                self._garbage_collect()\n\n            io_loop = ioloop.IOLoop.current()\n            timeout_handle = io_loop.add_timeout(timeout, on_timeout)\n            waiter.add_done_callback(lambda _: io_loop.remove_timeout(timeout_handle))\n        return waiter",
      "importString": "import collections\nimport datetime\nimport types\nfrom tornado import gen, ioloop\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\n\nfrom typing import Union, Optional, Type, Any, Awaitable\nimport typing",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/locks.py"
    },
    {
      "symbolName": "notify",
      "sourceCode": "def notify(self, n: int = 1) -> None:\n        \"\"\"Wake ``n`` waiters.\"\"\"\n        waiters = []  # Waiters we plan to run right now.\n        while n and self._waiters:\n            waiter = self._waiters.popleft()\n            if not waiter.done():  # Might have timed out.\n                n -= 1\n                waiters.append(waiter)\n\n        for waiter in waiters:\n            future_set_result_unless_cancelled(waiter, True)",
      "importString": "import collections\nimport datetime\nimport types\nfrom tornado import gen, ioloop\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\n\nfrom typing import Union, Optional, Type, Any, Awaitable\nimport typing",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/locks.py"
    },
    {
      "symbolName": "set",
      "sourceCode": "def set(self) -> None:\n        \"\"\"Set the internal flag to ``True``. All waiters are awakened.\n\n        Calling `.wait` once the flag is set will not block.\n        \"\"\"\n        if not self._value:\n            self._value = True\n\n            for fut in self._waiters:\n                if not fut.done():\n                    fut.set_result(None)",
      "importString": "import collections\nimport datetime\nimport types\nfrom tornado import gen, ioloop\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\n\nfrom typing import Union, Optional, Type, Any, Awaitable\nimport typing",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/locks.py"
    },
    {
      "symbolName": "wait",
      "sourceCode": "def wait(\n        self, timeout: Optional[Union[float, datetime.timedelta]] = None\n    ) -> Awaitable[None]:\n        \"\"\"Block until the internal flag is true.\n\n        Returns an awaitable, which raises `tornado.util.TimeoutError` after a\n        timeout.\n        \"\"\"\n        fut = Future()  # type: Future[None]\n        if self._value:\n            fut.set_result(None)\n            return fut\n        self._waiters.add(fut)\n        fut.add_done_callback(lambda fut: self._waiters.remove(fut))\n        if timeout is None:\n            return fut\n        else:\n            timeout_fut = gen.with_timeout(timeout, fut)\n            # This is a slightly clumsy workaround for the fact that\n            # gen.with_timeout doesn't cancel its futures. Cancelling\n            # fut will remove it from the waiters list.\n            timeout_fut.add_done_callback(\n                lambda tf: fut.cancel() if not fut.done() else None\n            )\n            return timeout_fut",
      "importString": "import collections\nimport datetime\nimport types\nfrom tornado import gen, ioloop\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\n\nfrom typing import Union, Optional, Type, Any, Awaitable\nimport typing",
      "lineNum": 24,
      "relativeDocumentPath": "tornado/locks.py"
    },
    {
      "symbolName": "release",
      "sourceCode": "def release(self) -> None:\n        \"\"\"Increment the counter and wake one waiter.\"\"\"\n        self._value += 1\n        while self._waiters:\n            waiter = self._waiters.popleft()\n            if not waiter.done():\n                self._value -= 1\n\n                # If the waiter is a coroutine paused at\n                #\n                #     with (yield semaphore.acquire()):\n                #\n                # then the context manager's __exit__ calls release() at the end\n                # of the \"with\" block.\n                waiter.set_result(_ReleasingContextManager(self))\n                break",
      "importString": "import collections\nimport datetime\nimport types\nfrom tornado import gen, ioloop\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\n\nfrom typing import Union, Optional, Type, Any, Awaitable\nimport typing",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/locks.py"
    },
    {
      "symbolName": "acquire",
      "sourceCode": "def acquire(\n        self, timeout: Optional[Union[float, datetime.timedelta]] = None\n    ) -> Awaitable[_ReleasingContextManager]:\n        \"\"\"Decrement the counter. Returns an awaitable.\n\n        Block if the counter is zero and wait for a `.release`. The awaitable\n        raises `.TimeoutError` after the deadline.\n        \"\"\"\n        waiter = Future()  # type: Future[_ReleasingContextManager]\n        if self._value > 0:\n            self._value -= 1\n            waiter.set_result(_ReleasingContextManager(self))\n        else:\n            self._waiters.append(waiter)\n            if timeout:\n\n                def on_timeout() -> None:\n                    if not waiter.done():\n                        waiter.set_exception(gen.TimeoutError())\n                    self._garbage_collect()\n\n                io_loop = ioloop.IOLoop.current()\n                timeout_handle = io_loop.add_timeout(timeout, on_timeout)\n                waiter.add_done_callback(\n                    lambda _: io_loop.remove_timeout(timeout_handle)\n                )\n        return waiter",
      "importString": "import collections\nimport datetime\nimport types\nfrom tornado import gen, ioloop\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\n\nfrom typing import Union, Optional, Type, Any, Awaitable\nimport typing",
      "lineNum": 26,
      "relativeDocumentPath": "tornado/locks.py"
    },
    {
      "symbolName": "release",
      "sourceCode": "def release(self) -> None:\n        \"\"\"Unlock.\n\n        The first coroutine in line waiting for `acquire` gets the lock.\n\n        If not locked, raise a `RuntimeError`.\n        \"\"\"\n        try:\n            self._block.release()\n        except ValueError:\n            raise RuntimeError(\"release unlocked lock\")",
      "importString": "import collections\nimport datetime\nimport types\nfrom tornado import gen, ioloop\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\n\nfrom typing import Union, Optional, Type, Any, Awaitable\nimport typing",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/locks.py"
    },
    {
      "symbolName": "_stderr_supports_color",
      "sourceCode": "def _stderr_supports_color() -> bool:\n    try:\n        if hasattr(sys.stderr, \"isatty\") and sys.stderr.isatty():\n            if curses:\n                curses.setupterm()\n                if curses.tigetnum(\"colors\") > 0:\n                    return True\n            elif colorama:\n                if sys.stderr is getattr(\n                    colorama.initialise, \"wrapped_stderr\", object()\n                ):\n                    return True\n    except Exception:\n        # Very broad exception handling because it's always better to\n        # fall back to non-colored logs than to break at startup.\n        pass\n    return False",
      "importString": "import logging\nimport logging.handlers\nimport sys\nfrom tornado.escape import _unicode\nfrom tornado.util import unicode_type, basestring_type\nfrom typing import Dict, Any, cast, Optional",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/log.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        fmt: str = DEFAULT_FORMAT,\n        datefmt: str = DEFAULT_DATE_FORMAT,\n        style: str = \"%\",\n        color: bool = True,\n        colors: Dict[int, int] = DEFAULT_COLORS,\n    ) -> None:\n        r\"\"\"\n        :arg bool color: Enables color support.\n        :arg str fmt: Log message format.\n          It will be applied to the attributes dict of log records. The\n          text between ``%(color)s`` and ``%(end_color)s`` will be colored\n          depending on the level if color support is on.\n        :arg dict colors: color mappings from logging level to terminal color\n          code\n        :arg str datefmt: Datetime format.\n          Used for formatting ``(asctime)`` placeholder in ``prefix_fmt``.\n\n        .. versionchanged:: 3.2\n\n           Added ``fmt`` and ``datefmt`` arguments.\n        \"\"\"\n        logging.Formatter.__init__(self, datefmt=datefmt)\n        self._fmt = fmt\n\n        self._colors = {}  # type: Dict[int, str]\n        if color and _stderr_supports_color():\n            if curses is not None:\n                fg_color = curses.tigetstr(\"setaf\") or curses.tigetstr(\"setf\") or b\"\"\n\n                for levelno, code in colors.items():\n                    # Convert the terminal control characters from\n                    # bytes to unicode strings for easier use with the\n                    # logging module.\n                    self._colors[levelno] = unicode_type(\n                        curses.tparm(fg_color, code), \"ascii\"\n                    )\n                normal = curses.tigetstr(\"sgr0\")\n                if normal is not None:\n                    self._normal = unicode_type(normal, \"ascii\")\n                else:\n                    self._normal = \"\"\n            else:\n                # If curses is not present (currently we'll only get here for\n                # colorama on windows), assume hard-coded ANSI color codes.\n                for levelno, code in colors.items():\n                    self._colors[levelno] = \"\\033[2;3%dm\" % code\n                self._normal = \"\\033[0m\"\n        else:\n            self._normal = \"\"",
      "importString": "import logging\nimport logging.handlers\nimport sys\nfrom tornado.escape import _unicode\nfrom tornado.util import unicode_type, basestring_type\nfrom typing import Dict, Any, cast, Optional",
      "lineNum": 50,
      "relativeDocumentPath": "tornado/log.py"
    },
    {
      "symbolName": "format",
      "sourceCode": "def format(self, record: Any) -> str:\n        try:\n            message = record.getMessage()\n            assert isinstance(message, basestring_type)  # guaranteed by logging\n            # Encoding notes:  The logging module prefers to work with character\n            # strings, but only enforces that log messages are instances of\n            # basestring.  In python 2, non-ascii bytestrings will make\n            # their way through the logging framework until they blow up with\n            # an unhelpful decoding error (with this formatter it happens\n            # when we attach the prefix, but there are other opportunities for\n            # exceptions further along in the framework).\n            #\n            # If a byte string makes it this far, convert it to unicode to\n            # ensure it will make it out to the logs.  Use repr() as a fallback\n            # to ensure that all byte strings can be converted successfully,\n            # but don't do it by default so we don't add extra quotes to ascii\n            # bytestrings.  This is a bit of a hacky place to do this, but\n            # it's worth it since the encoding errors that would otherwise\n            # result are so useless (and tornado is fond of using utf8-encoded\n            # byte strings wherever possible).\n            record.message = _safe_unicode(message)\n        except Exception as e:\n            record.message = f\"Bad message ({e!r}): {record.__dict__!r}\"\n\n        record.asctime = self.formatTime(record, cast(str, self.datefmt))\n\n        if record.levelno in self._colors:\n            record.color = self._colors[record.levelno]\n            record.end_color = self._normal\n        else:\n            record.color = record.end_color = \"\"\n\n        formatted = self._fmt % record.__dict__\n\n        if record.exc_info:\n            if not record.exc_text:\n                record.exc_text = self.formatException(record.exc_info)\n        if record.exc_text:\n            # exc_text contains multiple lines.  We need to _safe_unicode\n            # each line separately so that non-utf8 bytes don't cause\n            # all the newlines to turn into '\\n'.\n            lines = [formatted.rstrip()]\n            lines.extend(_safe_unicode(ln) for ln in record.exc_text.split(\"\\n\"))\n            formatted = \"\\n\".join(lines)\n        return formatted.replace(\"\\n\", \"\\n    \")",
      "importString": "import logging\nimport logging.handlers\nimport sys\nfrom tornado.escape import _unicode\nfrom tornado.util import unicode_type, basestring_type\nfrom typing import Dict, Any, cast, Optional",
      "lineNum": 44,
      "relativeDocumentPath": "tornado/log.py"
    },
    {
      "symbolName": "enable_pretty_logging",
      "sourceCode": "def enable_pretty_logging(\n    options: Any = None, logger: Optional[logging.Logger] = None\n) -> None:\n    \"\"\"Turns on formatted logging output as configured.\n\n    This is called automatically by `tornado.options.parse_command_line`\n    and `tornado.options.parse_config_file`.\n    \"\"\"\n    if options is None:\n        import tornado.options\n\n        options = tornado.options.options\n    if options.logging is None or options.logging.lower() == \"none\":\n        return\n    if logger is None:\n        logger = logging.getLogger()\n    logger.setLevel(getattr(logging, options.logging.upper()))\n    if options.log_file_prefix:\n        rotate_mode = options.log_rotate_mode\n        if rotate_mode == \"size\":\n            channel = logging.handlers.RotatingFileHandler(\n                filename=options.log_file_prefix,\n                maxBytes=options.log_file_max_size,\n                backupCount=options.log_file_num_backups,\n                encoding=\"utf-8\",\n            )  # type: logging.Handler\n        elif rotate_mode == \"time\":\n            channel = logging.handlers.TimedRotatingFileHandler(\n                filename=options.log_file_prefix,\n                when=options.log_rotate_when,\n                interval=options.log_rotate_interval,\n                backupCount=options.log_file_num_backups,\n                encoding=\"utf-8\",\n            )\n        else:\n            error_message = (\n                \"The value of log_rotate_mode option should be \"\n                + '\"size\" or \"time\", not \"%s\".' % rotate_mode\n            )\n            raise ValueError(error_message)\n        channel.setFormatter(LogFormatter(color=False))\n        logger.addHandler(channel)\n\n    if options.log_to_stderr or (options.log_to_stderr is None and not logger.handlers):\n        # Set up color if we are in a tty and curses is installed\n        channel = logging.StreamHandler()\n        channel.setFormatter(LogFormatter())\n        logger.addHandler(channel)",
      "importString": "import logging\nimport logging.handlers\nimport sys\nfrom tornado.escape import _unicode\nfrom tornado.util import unicode_type, basestring_type\nfrom typing import Dict, Any, cast, Optional",
      "lineNum": 47,
      "relativeDocumentPath": "tornado/log.py"
    },
    {
      "symbolName": "define_logging_options",
      "sourceCode": "def define_logging_options(options: Any = None) -> None:\n    \"\"\"Add logging-related flags to ``options``.\n\n    These options are present automatically on the default options instance;\n    this method is only necessary if you have created your own `.OptionParser`.\n\n    .. versionadded:: 4.2\n        This function existed in prior versions but was broken and undocumented until 4.2.\n    \"\"\"\n    if options is None:\n        # late import to prevent cycle\n        import tornado.options\n\n        options = tornado.options.options\n    options.define(\n        \"logging\",\n        default=\"info\",\n        help=(\n            \"Set the Python log level. If 'none', tornado won't touch the \"\n            \"logging configuration.\"\n        ),\n        metavar=\"debug|info|warning|error|none\",\n    )\n    options.define(\n        \"log_to_stderr\",\n        type=bool,\n        default=None,\n        help=(\n            \"Send log output to stderr (colorized if possible). \"\n            \"By default use stderr if --log_file_prefix is not set and \"\n            \"no other logging is configured.\"\n        ),\n    )\n    options.define(\n        \"log_file_prefix\",\n        type=str,\n        default=None,\n        metavar=\"PATH\",\n        help=(\n            \"Path prefix for log files. \"\n            \"Note that if you are running multiple tornado processes, \"\n            \"log_file_prefix must be different for each of them (e.g. \"\n            \"include the port number)\"\n        ),\n    )\n    options.define(\n        \"log_file_max_size\",\n        type=int,\n        default=100 * 1000 * 1000,\n        help=\"max size of log files before rollover\",\n    )\n    options.define(\n        \"log_file_num_backups\", type=int, default=10, help=\"number of log files to keep\"\n    )\n\n    options.define(\n        \"log_rotate_when\",\n        type=str,\n        default=\"midnight\",\n        help=(\n            \"specify the type of TimedRotatingFileHandler interval \"\n            \"other options:('S', 'M', 'H', 'D', 'W0'-'W6')\"\n        ),\n    )\n    options.define(\n        \"log_rotate_interval\",\n        type=int,\n        default=1,\n        help=\"The interval value of timed rotating\",\n    )\n\n    options.define(\n        \"log_rotate_mode\",\n        type=str,\n        default=\"size\",\n        help=\"The mode of rotating files(time or size)\",\n    )\n\n    options.add_parse_callback(lambda: enable_pretty_logging(options))",
      "importString": "import logging\nimport logging.handlers\nimport sys\nfrom tornado.escape import _unicode\nfrom tornado.util import unicode_type, basestring_type\nfrom typing import Dict, Any, cast, Optional",
      "lineNum": 78,
      "relativeDocumentPath": "tornado/log.py"
    },
    {
      "symbolName": "bind_sockets",
      "sourceCode": "def bind_sockets(\n    port: int,\n    address: Optional[str] = None,\n    family: socket.AddressFamily = socket.AF_UNSPEC,\n    backlog: int = _DEFAULT_BACKLOG,\n    flags: Optional[int] = None,\n    reuse_port: bool = False,\n) -> List[socket.socket]:\n    \"\"\"Creates listening sockets bound to the given port and address.\n\n    Returns a list of socket objects (multiple sockets are returned if\n    the given address maps to multiple IP addresses, which is most common\n    for mixed IPv4 and IPv6 use).\n\n    Address may be either an IP address or hostname.  If it's a hostname,\n    the server will listen on all IP addresses associated with the\n    name.  Address may be an empty string or None to listen on all\n    available interfaces.  Family may be set to either `socket.AF_INET`\n    or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise\n    both will be used if available.\n\n    The ``backlog`` argument has the same meaning as for\n    `socket.listen() <socket.socket.listen>`.\n\n    ``flags`` is a bitmask of AI_* flags to `~socket.getaddrinfo`, like\n    ``socket.AI_PASSIVE | socket.AI_NUMERICHOST``.\n\n    ``reuse_port`` option sets ``SO_REUSEPORT`` option for every socket\n    in the list. If your platform doesn't support this option ValueError will\n    be raised.\n    \"\"\"\n    if reuse_port and not hasattr(socket, \"SO_REUSEPORT\"):\n        raise ValueError(\"the platform doesn't support SO_REUSEPORT\")\n\n    sockets = []\n    if address == \"\":\n        address = None\n    if not socket.has_ipv6 and family == socket.AF_UNSPEC:\n        # Python can be compiled with --disable-ipv6, which causes\n        # operations on AF_INET6 sockets to fail, but does not\n        # automatically exclude those results from getaddrinfo\n        # results.\n        # http://bugs.python.org/issue16208\n        family = socket.AF_INET\n    if flags is None:\n        flags = socket.AI_PASSIVE\n    bound_port = None\n    unique_addresses = set()  # type: set\n    for res in sorted(\n        socket.getaddrinfo(address, port, family, socket.SOCK_STREAM, 0, flags),\n        key=lambda x: x[0],\n    ):\n        if res in unique_addresses:\n            continue\n\n        unique_addresses.add(res)\n\n        af, socktype, proto, canonname, sockaddr = res\n        if (\n            sys.platform == \"darwin\"\n            and address == \"localhost\"\n            and af == socket.AF_INET6\n            and sockaddr[3] != 0  # type: ignore\n        ):\n            # Mac OS X includes a link-local address fe80::1%lo0 in the\n            # getaddrinfo results for 'localhost'.  However, the firewall\n            # doesn't understand that this is a local address and will\n            # prompt for access (often repeatedly, due to an apparent\n            # bug in its ability to remember granting access to an\n            # application). Skip these addresses.\n            continue\n        try:\n            sock = socket.socket(af, socktype, proto)\n        except OSError as e:\n            if errno_from_exception(e) == errno.EAFNOSUPPORT:\n                continue\n            raise\n        if os.name != \"nt\":\n            try:\n                sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            except OSError as e:\n                if errno_from_exception(e) != errno.ENOPROTOOPT:\n                    # Hurd doesn't support SO_REUSEADDR.\n                    raise\n        if reuse_port:\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n        if af == socket.AF_INET6:\n            # On linux, ipv6 sockets accept ipv4 too by default,\n            # but this makes it impossible to bind to both\n            # 0.0.0.0 in ipv4 and :: in ipv6.  On other systems,\n            # separate sockets *must* be used to listen for both ipv4\n            # and ipv6.  For consistency, always disable ipv4 on our\n            # ipv6 sockets and use a separate ipv4 socket when needed.\n            #\n            # Python 2.x on windows doesn't have IPPROTO_IPV6.\n            if hasattr(socket, \"IPPROTO_IPV6\"):\n                sock.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_V6ONLY, 1)\n\n        # automatic port allocation with port=None\n        # should bind on the same port on IPv4 and IPv6\n        host, requested_port = sockaddr[:2]\n        if requested_port == 0 and bound_port is not None:\n            sockaddr = tuple([host, bound_port] + list(sockaddr[2:]))\n\n        sock.setblocking(False)\n        try:\n            sock.bind(sockaddr)\n        except OSError as e:\n            if (\n                errno_from_exception(e) == errno.EADDRNOTAVAIL\n                and address == \"localhost\"\n                and sockaddr[0] == \"::1\"\n            ):\n                # On some systems (most notably docker with default\n                # configurations), ipv6 is partially disabled:\n                # socket.has_ipv6 is true, we can create AF_INET6\n                # sockets, and getaddrinfo(\"localhost\", ...,\n                # AF_PASSIVE) resolves to ::1, but we get an error\n                # when binding.\n                #\n                # Swallow the error, but only for this specific case.\n                # If EADDRNOTAVAIL occurs in other situations, it\n                # might be a real problem like a typo in a\n                # configuration.\n                sock.close()\n                continue\n            else:\n                raise\n        bound_port = sock.getsockname()[1]\n        sock.listen(backlog)\n        sockets.append(sock)\n    return sockets",
      "importString": "import concurrent.futures\nimport errno\nimport os\nimport sys\nimport socket\nimport ssl\nimport stat\nfrom tornado.concurrent import dummy_executor, run_on_executor\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable, errno_from_exception\n\nfrom typing import List, Callable, Any, Type, Dict, Union, Tuple, Awaitable, Optional",
      "lineNum": 131,
      "relativeDocumentPath": "tornado/netutil.py"
    },
    {
      "symbolName": "bind_unix_socket",
      "sourceCode": "def bind_unix_socket(\n        file: str, mode: int = 0o600, backlog: int = _DEFAULT_BACKLOG\n    ) -> socket.socket:\n        \"\"\"Creates a listening unix socket.\n\n        If a socket with the given name already exists, it will be deleted.\n        If any other file with that name exists, an exception will be\n        raised.\n\n        Returns a socket object (not a list of socket objects like\n        `bind_sockets`)\n        \"\"\"\n        sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        try:\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        except OSError as e:\n            if errno_from_exception(e) != errno.ENOPROTOOPT:\n                # Hurd doesn't support SO_REUSEADDR\n                raise\n        sock.setblocking(False)\n        # File names comprising of an initial null-byte denote an abstract\n        # namespace, on Linux, and therefore are not subject to file system\n        # orientated processing.\n        if not file.startswith(\"\\0\"):\n            try:\n                st = os.stat(file)\n            except FileNotFoundError:\n                pass\n            else:\n                if stat.S_ISSOCK(st.st_mode):\n                    os.remove(file)\n                else:\n                    raise ValueError(\"File %s exists and is not a socket\", file)\n            sock.bind(file)\n            os.chmod(file, mode)\n        else:\n            sock.bind(file)\n        sock.listen(backlog)\n        return sock",
      "importString": "import concurrent.futures\nimport errno\nimport os\nimport sys\nimport socket\nimport ssl\nimport stat\nfrom tornado.concurrent import dummy_executor, run_on_executor\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable, errno_from_exception\n\nfrom typing import List, Callable, Any, Type, Dict, Union, Tuple, Awaitable, Optional",
      "lineNum": 38,
      "relativeDocumentPath": "tornado/netutil.py"
    },
    {
      "symbolName": "add_accept_handler",
      "sourceCode": "def add_accept_handler(\n    sock: socket.socket, callback: Callable[[socket.socket, Any], None]\n) -> Callable[[], None]:\n    \"\"\"Adds an `.IOLoop` event handler to accept new connections on ``sock``.\n\n    When a connection is accepted, ``callback(connection, address)`` will\n    be run (``connection`` is a socket object, and ``address`` is the\n    address of the other end of the connection).  Note that this signature\n    is different from the ``callback(fd, events)`` signature used for\n    `.IOLoop` handlers.\n\n    A callable is returned which, when called, will remove the `.IOLoop`\n    event handler and stop processing further incoming connections.\n\n    .. versionchanged:: 5.0\n       The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n\n    .. versionchanged:: 5.0\n       A callable is returned (``None`` was returned before).\n    \"\"\"\n    io_loop = IOLoop.current()\n    removed = [False]\n\n    def accept_handler(fd: socket.socket, events: int) -> None:\n        # More connections may come in while we're handling callbacks;\n        # to prevent starvation of other tasks we must limit the number\n        # of connections we accept at a time.  Ideally we would accept\n        # up to the number of connections that were waiting when we\n        # entered this method, but this information is not available\n        # (and rearranging this method to call accept() as many times\n        # as possible before running any callbacks would have adverse\n        # effects on load balancing in multiprocess configurations).\n        # Instead, we use the (default) listen backlog as a rough\n        # heuristic for the number of connections we can reasonably\n        # accept at once.\n        for i in range(_DEFAULT_BACKLOG):\n            if removed[0]:\n                # The socket was probably closed\n                return\n            try:\n                connection, address = sock.accept()\n            except BlockingIOError:\n                # EWOULDBLOCK indicates we have accepted every\n                # connection that is available.\n                return\n            except ConnectionAbortedError:\n                # ECONNABORTED indicates that there was a connection\n                # but it was closed while still in the accept queue.\n                # (observed on FreeBSD).\n                continue\n            callback(connection, address)\n\n    def remove_handler() -> None:\n        io_loop.remove_handler(sock)\n        removed[0] = True\n\n    io_loop.add_handler(sock, accept_handler, IOLoop.READ)\n    return remove_handler",
      "importString": "import concurrent.futures\nimport errno\nimport os\nimport sys\nimport socket\nimport ssl\nimport stat\nfrom tornado.concurrent import dummy_executor, run_on_executor\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable, errno_from_exception\n\nfrom typing import List, Callable, Any, Type, Dict, Union, Tuple, Awaitable, Optional",
      "lineNum": 57,
      "relativeDocumentPath": "tornado/netutil.py"
    },
    {
      "symbolName": "accept_handler",
      "sourceCode": "def accept_handler(fd: socket.socket, events: int) -> None:\n        # More connections may come in while we're handling callbacks;\n        # to prevent starvation of other tasks we must limit the number\n        # of connections we accept at a time.  Ideally we would accept\n        # up to the number of connections that were waiting when we\n        # entered this method, but this information is not available\n        # (and rearranging this method to call accept() as many times\n        # as possible before running any callbacks would have adverse\n        # effects on load balancing in multiprocess configurations).\n        # Instead, we use the (default) listen backlog as a rough\n        # heuristic for the number of connections we can reasonably\n        # accept at once.\n        for i in range(_DEFAULT_BACKLOG):\n            if removed[0]:\n                # The socket was probably closed\n                return\n            try:\n                connection, address = sock.accept()\n            except BlockingIOError:\n                # EWOULDBLOCK indicates we have accepted every\n                # connection that is available.\n                return\n            except ConnectionAbortedError:\n                # ECONNABORTED indicates that there was a connection\n                # but it was closed while still in the accept queue.\n                # (observed on FreeBSD).\n                continue\n            callback(connection, address)",
      "importString": "import concurrent.futures\nimport errno\nimport os\nimport sys\nimport socket\nimport ssl\nimport stat\nfrom tornado.concurrent import dummy_executor, run_on_executor\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable, errno_from_exception\n\nfrom typing import List, Callable, Any, Type, Dict, Union, Tuple, Awaitable, Optional",
      "lineNum": 27,
      "relativeDocumentPath": "tornado/netutil.py"
    },
    {
      "symbolName": "is_valid_ip",
      "sourceCode": "def is_valid_ip(ip: str) -> bool:\n    \"\"\"Returns ``True`` if the given string is a well-formed IP address.\n\n    Supports IPv4 and IPv6.\n    \"\"\"\n    if not ip or \"\\x00\" in ip:\n        # getaddrinfo resolves empty strings to localhost, and truncates\n        # on zero bytes.\n        return False\n    try:\n        res = socket.getaddrinfo(\n            ip, 0, socket.AF_UNSPEC, socket.SOCK_STREAM, 0, socket.AI_NUMERICHOST\n        )\n        return bool(res)\n    except socket.gaierror as e:\n        if e.args[0] == socket.EAI_NONAME:\n            return False\n        raise\n    except UnicodeError:\n        # `socket.getaddrinfo` will raise a UnicodeError from the\n        # `idna` decoder if the input is longer than 63 characters,\n        # even for socket.AI_NUMERICHOST.  See\n        # https://bugs.python.org/issue32958 for discussion\n        return False\n    return True",
      "importString": "import concurrent.futures\nimport errno\nimport os\nimport sys\nimport socket\nimport ssl\nimport stat\nfrom tornado.concurrent import dummy_executor, run_on_executor\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable, errno_from_exception\n\nfrom typing import List, Callable, Any, Type, Dict, Union, Tuple, Awaitable, Optional",
      "lineNum": 24,
      "relativeDocumentPath": "tornado/netutil.py"
    },
    {
      "symbolName": "resolve",
      "sourceCode": "def resolve(\n        self, host: str, port: int, family: socket.AddressFamily = socket.AF_UNSPEC\n    ) -> Awaitable[List[Tuple[int, Any]]]:\n        \"\"\"Resolves an address.\n\n        The ``host`` argument is a string which may be a hostname or a\n        literal IP address.\n\n        Returns a `.Future` whose result is a list of (family,\n        address) pairs, where address is a tuple suitable to pass to\n        `socket.connect <socket.socket.connect>` (i.e. a ``(host,\n        port)`` pair for IPv4; additional fields may be present for\n        IPv6). If a ``callback`` is passed, it will be run with the\n        result as an argument when it is complete.\n\n        :raises IOError: if the address cannot be resolved.\n\n        .. versionchanged:: 4.4\n           Standardized all implementations to raise `IOError`.\n\n        .. versionchanged:: 6.0 The ``callback`` argument was removed.\n           Use the returned awaitable object instead.\n\n        \"\"\"\n        raise NotImplementedError()",
      "importString": "import concurrent.futures\nimport errno\nimport os\nimport sys\nimport socket\nimport ssl\nimport stat\nfrom tornado.concurrent import dummy_executor, run_on_executor\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable, errno_from_exception\n\nfrom typing import List, Callable, Any, Type, Dict, Union, Tuple, Awaitable, Optional",
      "lineNum": 24,
      "relativeDocumentPath": "tornado/netutil.py"
    },
    {
      "symbolName": "_resolve_addr",
      "sourceCode": "def _resolve_addr(\n    host: str, port: int, family: socket.AddressFamily = socket.AF_UNSPEC\n) -> List[Tuple[int, Any]]:\n    # On Solaris, getaddrinfo fails if the given port is not found\n    # in /etc/services and no socket type is given, so we must pass\n    # one here.  The socket type used here doesn't seem to actually\n    # matter (we discard the one we get back in the results),\n    # so the addresses we return should still be usable with SOCK_DGRAM.\n    addrinfo = socket.getaddrinfo(host, port, family, socket.SOCK_STREAM)\n    results = []\n    for fam, socktype, proto, canonname, address in addrinfo:\n        results.append((fam, address))\n    return results",
      "importString": "import concurrent.futures\nimport errno\nimport os\nimport sys\nimport socket\nimport ssl\nimport stat\nfrom tornado.concurrent import dummy_executor, run_on_executor\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable, errno_from_exception\n\nfrom typing import List, Callable, Any, Type, Dict, Union, Tuple, Awaitable, Optional",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/netutil.py"
    },
    {
      "symbolName": "resolve",
      "sourceCode": "async def resolve(\n        self, host: str, port: int, family: socket.AddressFamily = socket.AF_UNSPEC\n    ) -> List[Tuple[int, Any]]:\n        # On Solaris, getaddrinfo fails if the given port is not found\n        # in /etc/services and no socket type is given, so we must pass\n        # one here.  The socket type used here doesn't seem to actually\n        # matter (we discard the one we get back in the results),\n        # so the addresses we return should still be usable with SOCK_DGRAM.\n        return [\n            (fam, address)\n            for fam, _, _, _, address in await asyncio.get_running_loop().getaddrinfo(\n                host, port, family=family, type=socket.SOCK_STREAM\n            )\n        ]",
      "importString": "import concurrent.futures\nimport errno\nimport os\nimport sys\nimport socket\nimport ssl\nimport stat\nfrom tornado.concurrent import dummy_executor, run_on_executor\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable, errno_from_exception\n\nfrom typing import List, Callable, Any, Type, Dict, Union, Tuple, Awaitable, Optional",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/netutil.py"
    },
    {
      "symbolName": "initialize",
      "sourceCode": "def initialize(\n        self,\n        executor: Optional[concurrent.futures.Executor] = None,\n        close_executor: bool = True,\n    ) -> None:\n        if executor is not None:\n            self.executor = executor\n            self.close_executor = close_executor\n        else:\n            self.executor = dummy_executor\n            self.close_executor = False",
      "importString": "import concurrent.futures\nimport errno\nimport os\nimport sys\nimport socket\nimport ssl\nimport stat\nfrom tornado.concurrent import dummy_executor, run_on_executor\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable, errno_from_exception\n\nfrom typing import List, Callable, Any, Type, Dict, Union, Tuple, Awaitable, Optional",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/netutil.py"
    },
    {
      "symbolName": "_create_threadpool",
      "sourceCode": "@classmethod\n    def _create_threadpool(\n        cls, num_threads: int\n    ) -> concurrent.futures.ThreadPoolExecutor:\n        pid = os.getpid()\n        if cls._threadpool_pid != pid:\n            # Threads cannot survive after a fork, so if our pid isn't what it\n            # was when we created the pool then delete it.\n            cls._threadpool = None\n        if cls._threadpool is None:\n            cls._threadpool = concurrent.futures.ThreadPoolExecutor(num_threads)\n            cls._threadpool_pid = pid\n        return cls._threadpool",
      "importString": "import concurrent.futures\nimport errno\nimport os\nimport sys\nimport socket\nimport ssl\nimport stat\nfrom tornado.concurrent import dummy_executor, run_on_executor\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable, errno_from_exception\n\nfrom typing import List, Callable, Any, Type, Dict, Union, Tuple, Awaitable, Optional",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/netutil.py"
    },
    {
      "symbolName": "ssl_options_to_context",
      "sourceCode": "def ssl_options_to_context(\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext],\n    server_side: Optional[bool] = None,\n) -> ssl.SSLContext:\n    \"\"\"Try to convert an ``ssl_options`` dictionary to an\n    `~ssl.SSLContext` object.\n\n    The ``ssl_options`` argument may be either an `ssl.SSLContext` object or a dictionary containing\n    keywords to be passed to ``ssl.SSLContext.wrap_socket``.  This function converts the dict form\n    to its `~ssl.SSLContext` equivalent, and may be used when a component which accepts both forms\n    needs to upgrade to the `~ssl.SSLContext` version to use features like SNI or ALPN.\n\n    .. versionchanged:: 6.2\n\n       Added server_side argument. Omitting this argument will result in a DeprecationWarning on\n       Python 3.10.\n\n    \"\"\"\n    if isinstance(ssl_options, ssl.SSLContext):\n        return ssl_options\n    assert isinstance(ssl_options, dict)\n    assert all(k in _SSL_CONTEXT_KEYWORDS for k in ssl_options), ssl_options\n    # TODO: Now that we have the server_side argument, can we switch to\n    # create_default_context or would that change behavior?\n    default_version = ssl.PROTOCOL_TLS\n    if server_side:\n        default_version = ssl.PROTOCOL_TLS_SERVER\n    elif server_side is not None:\n        default_version = ssl.PROTOCOL_TLS_CLIENT\n    context = ssl.SSLContext(ssl_options.get(\"ssl_version\", default_version))\n    if \"certfile\" in ssl_options:\n        context.load_cert_chain(\n            ssl_options[\"certfile\"], ssl_options.get(\"keyfile\", None)\n        )\n    if \"cert_reqs\" in ssl_options:\n        if ssl_options[\"cert_reqs\"] == ssl.CERT_NONE:\n            # This may have been set automatically by PROTOCOL_TLS_CLIENT but is\n            # incompatible with CERT_NONE so we must manually clear it.\n            context.check_hostname = False\n        context.verify_mode = ssl_options[\"cert_reqs\"]\n    if \"ca_certs\" in ssl_options:\n        context.load_verify_locations(ssl_options[\"ca_certs\"])\n    if \"ciphers\" in ssl_options:\n        context.set_ciphers(ssl_options[\"ciphers\"])\n    if hasattr(ssl, \"OP_NO_COMPRESSION\"):\n        # Disable TLS compression to avoid CRIME and related attacks.\n        # This constant depends on openssl version 1.0.\n        # TODO: Do we need to do this ourselves or can we trust\n        # the defaults?\n        context.options |= ssl.OP_NO_COMPRESSION\n    return context",
      "importString": "import concurrent.futures\nimport errno\nimport os\nimport sys\nimport socket\nimport ssl\nimport stat\nfrom tornado.concurrent import dummy_executor, run_on_executor\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable, errno_from_exception\n\nfrom typing import List, Callable, Any, Type, Dict, Union, Tuple, Awaitable, Optional",
      "lineNum": 50,
      "relativeDocumentPath": "tornado/netutil.py"
    },
    {
      "symbolName": "ssl_wrap_socket",
      "sourceCode": "def ssl_wrap_socket(\n    socket: socket.socket,\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext],\n    server_hostname: Optional[str] = None,\n    server_side: Optional[bool] = None,\n    **kwargs: Any,\n) -> ssl.SSLSocket:\n    \"\"\"Returns an ``ssl.SSLSocket`` wrapping the given socket.\n\n    ``ssl_options`` may be either an `ssl.SSLContext` object or a\n    dictionary (as accepted by `ssl_options_to_context`).  Additional\n    keyword arguments are passed to `ssl.SSLContext.wrap_socket`.\n\n    .. versionchanged:: 6.2\n\n       Added server_side argument. Omitting this argument will\n       result in a DeprecationWarning on Python 3.10.\n    \"\"\"\n    context = ssl_options_to_context(ssl_options, server_side=server_side)\n    if server_side is None:\n        server_side = False\n    assert ssl.HAS_SNI\n    # TODO: add a unittest for hostname validation (python added server-side SNI support in 3.4)\n    # In the meantime it can be manually tested with\n    # python3 -m tornado.httpclient https://sni.velox.ch\n    return context.wrap_socket(\n        socket, server_hostname=server_hostname, server_side=server_side, **kwargs\n    )",
      "importString": "import concurrent.futures\nimport errno\nimport os\nimport sys\nimport socket\nimport ssl\nimport stat\nfrom tornado.concurrent import dummy_executor, run_on_executor\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable, errno_from_exception\n\nfrom typing import List, Callable, Any, Type, Dict, Union, Tuple, Awaitable, Optional",
      "lineNum": 27,
      "relativeDocumentPath": "tornado/netutil.py"
    },
    {
      "symbolName": "group_dict",
      "sourceCode": "def group_dict(self, group: str) -> Dict[str, Any]:\n        \"\"\"The names and values of options in a group.\n\n        Useful for copying options into Application settings::\n\n            from tornado.options import define, parse_command_line, options\n\n            define('template_path', group='application')\n            define('static_path', group='application')\n\n            parse_command_line()\n\n            application = Application(\n                handlers, **options.group_dict('application'))\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return {\n            opt.name: opt.value()\n            for name, opt in self._options.items()\n            if not group or group == opt.group_name\n        }",
      "importString": "import datetime\nimport numbers\nimport re\nimport sys\nimport os\nimport textwrap\nfrom tornado.escape import _unicode, native_str\nfrom tornado.log import define_logging_options\nfrom tornado.util import basestring_type, exec_in\nfrom typing import (\nAny\nIterator\nIterable\nTuple\nSet\nDict\nCallable\nList\nTextIO\nOptional\n)",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/options.py"
    },
    {
      "symbolName": "define",
      "sourceCode": "def define(\n        self,\n        name: str,\n        default: Any = None,\n        type: Optional[type] = None,\n        help: Optional[str] = None,\n        metavar: Optional[str] = None,\n        multiple: bool = False,\n        group: Optional[str] = None,\n        callback: Optional[Callable[[Any], None]] = None,\n    ) -> None:\n        \"\"\"Defines a new command line option.\n\n        ``type`` can be any of `str`, `int`, `float`, `bool`,\n        `~datetime.datetime`, or `~datetime.timedelta`. If no ``type``\n        is given but a ``default`` is, ``type`` is the type of\n        ``default``. Otherwise, ``type`` defaults to `str`.\n\n        If ``multiple`` is True, the option value is a list of ``type``\n        instead of an instance of ``type``.\n\n        ``help`` and ``metavar`` are used to construct the\n        automatically generated command line help string. The help\n        message is formatted like::\n\n           --name=METAVAR      help string\n\n        ``group`` is used to group the defined options in logical\n        groups. By default, command line options are grouped by the\n        file in which they are defined.\n\n        Command line option names must be unique globally.\n\n        If a ``callback`` is given, it will be run with the new value whenever\n        the option is changed.  This can be used to combine command-line\n        and file-based options::\n\n            define(\"config\", type=str, help=\"path to config file\",\n                   callback=lambda path: parse_config_file(path, final=False))\n\n        With this definition, options in the file specified by ``--config`` will\n        override options set earlier on the command line, but can be overridden\n        by later flags.\n\n        \"\"\"\n        normalized = self._normalize_name(name)\n        if normalized in self._options:\n            raise Error(\n                \"Option %r already defined in %s\"\n                % (normalized, self._options[normalized].file_name)\n            )\n        frame = sys._getframe(0)\n        if frame is not None:\n            options_file = frame.f_code.co_filename\n\n            # Can be called directly, or through top level define() fn, in which\n            # case, step up above that frame to look for real caller.\n            if (\n                frame.f_back is not None\n                and frame.f_back.f_code.co_filename == options_file\n                and frame.f_back.f_code.co_name == \"define\"\n            ):\n                frame = frame.f_back\n\n            assert frame.f_back is not None\n            file_name = frame.f_back.f_code.co_filename\n        else:\n            file_name = \"<unknown>\"\n        if file_name == options_file:\n            file_name = \"\"\n        if type is None:\n            if not multiple and default is not None:\n                type = default.__class__\n            else:\n                type = str\n        if group:\n            group_name = group  # type: Optional[str]\n        else:\n            group_name = file_name\n        option = _Option(\n            name,\n            file_name=file_name,\n            default=default,\n            type=type,\n            help=help,\n            metavar=metavar,\n            multiple=multiple,\n            group_name=group_name,\n            callback=callback,\n        )\n        self._options[normalized] = option",
      "importString": "import datetime\nimport numbers\nimport re\nimport sys\nimport os\nimport textwrap\nfrom tornado.escape import _unicode, native_str\nfrom tornado.log import define_logging_options\nfrom tornado.util import basestring_type, exec_in\nfrom typing import (\nAny\nIterator\nIterable\nTuple\nSet\nDict\nCallable\nList\nTextIO\nOptional\n)",
      "lineNum": 90,
      "relativeDocumentPath": "tornado/options.py"
    },
    {
      "symbolName": "parse_command_line",
      "sourceCode": "def parse_command_line(\n        self, args: Optional[List[str]] = None, final: bool = True\n    ) -> List[str]:\n        \"\"\"Parses all options given on the command line (defaults to\n        `sys.argv`).\n\n        Options look like ``--option=value`` and are parsed according\n        to their ``type``. For boolean options, ``--option`` is\n        equivalent to ``--option=true``\n\n        If the option has ``multiple=True``, comma-separated values\n        are accepted. For multi-value integer options, the syntax\n        ``x:y`` is also accepted and equivalent to ``range(x, y)``.\n\n        Note that ``args[0]`` is ignored since it is the program name\n        in `sys.argv`.\n\n        We return a list of all arguments that are not parsed as options.\n\n        If ``final`` is ``False``, parse callbacks will not be run.\n        This is useful for applications that wish to combine configurations\n        from multiple sources.\n\n        \"\"\"\n        if args is None:\n            args = sys.argv\n        remaining = []  # type: List[str]\n        for i in range(1, len(args)):\n            # All things after the last option are command line arguments\n            if not args[i].startswith(\"-\"):\n                remaining = args[i:]\n                break\n            if args[i] == \"--\":\n                remaining = args[i + 1 :]\n                break\n            arg = args[i].lstrip(\"-\")\n            name, equals, value = arg.partition(\"=\")\n            name = self._normalize_name(name)\n            if name not in self._options:\n                self.print_help()\n                raise Error(\"Unrecognized command line option: %r\" % name)\n            option = self._options[name]\n            if not equals:\n                if option.type == bool:\n                    value = \"true\"\n                else:\n                    raise Error(\"Option %r requires a value\" % name)\n            option.parse(value)\n\n        if final:\n            self.run_parse_callbacks()\n\n        return remaining",
      "importString": "import datetime\nimport numbers\nimport re\nimport sys\nimport os\nimport textwrap\nfrom tornado.escape import _unicode, native_str\nfrom tornado.log import define_logging_options\nfrom tornado.util import basestring_type, exec_in\nfrom typing import (\nAny\nIterator\nIterable\nTuple\nSet\nDict\nCallable\nList\nTextIO\nOptional\n)",
      "lineNum": 52,
      "relativeDocumentPath": "tornado/options.py"
    },
    {
      "symbolName": "parse_config_file",
      "sourceCode": "def parse_config_file(self, path: str, final: bool = True) -> None:\n        \"\"\"Parses and loads the config file at the given path.\n\n        The config file contains Python code that will be executed (so\n        it is **not safe** to use untrusted config files). Anything in\n        the global namespace that matches a defined option will be\n        used to set that option's value.\n\n        Options may either be the specified type for the option or\n        strings (in which case they will be parsed the same way as in\n        `.parse_command_line`)\n\n        Example (using the options defined in the top-level docs of\n        this module)::\n\n            port = 80\n            mysql_host = 'mydb.example.com:3306'\n            # Both lists and comma-separated strings are allowed for\n            # multiple=True.\n            memcache_hosts = ['cache1.example.com:11011',\n                              'cache2.example.com:11011']\n            memcache_hosts = 'cache1.example.com:11011,cache2.example.com:11011'\n\n        If ``final`` is ``False``, parse callbacks will not be run.\n        This is useful for applications that wish to combine configurations\n        from multiple sources.\n\n        .. note::\n\n            `tornado.options` is primarily a command-line library.\n            Config file support is provided for applications that wish\n            to use it, but applications that prefer config files may\n            wish to look at other libraries instead.\n\n        .. versionchanged:: 4.1\n           Config files are now always interpreted as utf-8 instead of\n           the system default encoding.\n\n        .. versionchanged:: 4.4\n           The special variable ``__file__`` is available inside config\n           files, specifying the absolute path to the config file itself.\n\n        .. versionchanged:: 5.1\n           Added the ability to set options via strings in config files.\n\n        \"\"\"\n        config = {\"__file__\": os.path.abspath(path)}\n        with open(path, \"rb\") as f:\n            exec_in(native_str(f.read()), config, config)\n        for name in config:\n            normalized = self._normalize_name(name)\n            if normalized in self._options:\n                option = self._options[normalized]\n                if option.multiple:\n                    if not isinstance(config[name], (list, str)):\n                        raise Error(\n                            \"Option %r is required to be a list of %s \"\n                            \"or a comma-separated string\"\n                            % (option.name, option.type.__name__)\n                        )\n\n                if type(config[name]) is str and (\n                    option.type is not str or option.multiple\n                ):\n                    option.parse(config[name])\n                else:\n                    option.set(config[name])\n\n        if final:\n            self.run_parse_callbacks()",
      "importString": "import datetime\nimport numbers\nimport re\nimport sys\nimport os\nimport textwrap\nfrom tornado.escape import _unicode, native_str\nfrom tornado.log import define_logging_options\nfrom tornado.util import basestring_type, exec_in\nfrom typing import (\nAny\nIterator\nIterable\nTuple\nSet\nDict\nCallable\nList\nTextIO\nOptional\n)",
      "lineNum": 69,
      "relativeDocumentPath": "tornado/options.py"
    },
    {
      "symbolName": "print_help",
      "sourceCode": "def print_help(self, file: Optional[TextIO] = None) -> None:\n        \"\"\"Prints all the command line options to stderr (or another file).\"\"\"\n        if file is None:\n            file = sys.stderr\n        print(\"Usage: %s [OPTIONS]\" % sys.argv[0], file=file)\n        print(\"\\nOptions:\\n\", file=file)\n        by_group = {}  # type: Dict[str, List[_Option]]\n        for option in self._options.values():\n            by_group.setdefault(option.group_name, []).append(option)\n\n        for filename, o in sorted(by_group.items()):\n            if filename:\n                print(\"\\n%s options:\\n\" % os.path.normpath(filename), file=file)\n            o.sort(key=lambda option: option.name)\n            for option in o:\n                # Always print names with dashes in a CLI context.\n                prefix = self._normalize_name(option.name)\n                if option.metavar:\n                    prefix += \"=\" + option.metavar\n                description = option.help or \"\"\n                if option.default is not None and option.default != \"\":\n                    description += \" (default %s)\" % option.default\n                lines = textwrap.wrap(description, 79 - 35)\n                if len(prefix) > 30 or len(lines) == 0:\n                    lines.insert(0, \"\")\n                print(\"  --%-30s %s\" % (prefix, lines[0]), file=file)\n                for line in lines[1:]:\n                    print(\"%-34s %s\" % (\" \", line), file=file)\n        print(file=file)",
      "importString": "import datetime\nimport numbers\nimport re\nimport sys\nimport os\nimport textwrap\nfrom tornado.escape import _unicode, native_str\nfrom tornado.log import define_logging_options\nfrom tornado.util import basestring_type, exec_in\nfrom typing import (\nAny\nIterator\nIterable\nTuple\nSet\nDict\nCallable\nList\nTextIO\nOptional\n)",
      "lineNum": 28,
      "relativeDocumentPath": "tornado/options.py"
    },
    {
      "symbolName": "mockable",
      "sourceCode": "def mockable(self) -> \"_Mockable\":\n        \"\"\"Returns a wrapper around self that is compatible with\n        `unittest.mock.patch`.\n\n        The `unittest.mock.patch` function is incompatible with objects like ``options`` that\n        override ``__getattr__`` and ``__setattr__``.  This function returns an object that can be\n        used with `mock.patch.object <unittest.mock.patch.object>` to modify option values::\n\n            with mock.patch.object(options.mockable(), 'name', value):\n                assert options.name == value\n        \"\"\"\n        return _Mockable(self)",
      "importString": "import datetime\nimport numbers\nimport re\nimport sys\nimport os\nimport textwrap\nfrom tornado.escape import _unicode, native_str\nfrom tornado.log import define_logging_options\nfrom tornado.util import basestring_type, exec_in\nfrom typing import (\nAny\nIterator\nIterable\nTuple\nSet\nDict\nCallable\nList\nTextIO\nOptional\n)",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/options.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        name: str,\n        default: Any = None,\n        type: Optional[type] = None,\n        help: Optional[str] = None,\n        metavar: Optional[str] = None,\n        multiple: bool = False,\n        file_name: Optional[str] = None,\n        group_name: Optional[str] = None,\n        callback: Optional[Callable[[Any], None]] = None,\n    ) -> None:\n        if default is None and multiple:\n            default = []\n        self.name = name\n        if type is None:\n            raise ValueError(\"type must not be None\")\n        self.type = type\n        self.help = help\n        self.metavar = metavar\n        self.multiple = multiple\n        self.file_name = file_name\n        self.group_name = group_name\n        self.callback = callback\n        self.default = default\n        self._value = _Option.UNSET  # type: Any",
      "importString": "import datetime\nimport numbers\nimport re\nimport sys\nimport os\nimport textwrap\nfrom tornado.escape import _unicode, native_str\nfrom tornado.log import define_logging_options\nfrom tornado.util import basestring_type, exec_in\nfrom typing import (\nAny\nIterator\nIterable\nTuple\nSet\nDict\nCallable\nList\nTextIO\nOptional\n)",
      "lineNum": 25,
      "relativeDocumentPath": "tornado/options.py"
    },
    {
      "symbolName": "parse",
      "sourceCode": "def parse(self, value: str) -> Any:\n        _parse = {\n            datetime.datetime: self._parse_datetime,\n            datetime.timedelta: self._parse_timedelta,\n            bool: self._parse_bool,\n            basestring_type: self._parse_string,\n        }.get(\n            self.type, self.type\n        )  # type: Callable[[str], Any]\n        if self.multiple:\n            self._value = []\n            for part in value.split(\",\"):\n                if issubclass(self.type, numbers.Integral):\n                    # allow ranges of the form X:Y (inclusive at both ends)\n                    lo_str, _, hi_str = part.partition(\":\")\n                    lo = _parse(lo_str)\n                    hi = _parse(hi_str) if hi_str else lo\n                    self._value.extend(range(lo, hi + 1))\n                else:\n                    self._value.append(_parse(part))\n        else:\n            self._value = _parse(value)\n        if self.callback is not None:\n            self.callback(self._value)\n        return self.value()",
      "importString": "import datetime\nimport numbers\nimport re\nimport sys\nimport os\nimport textwrap\nfrom tornado.escape import _unicode, native_str\nfrom tornado.log import define_logging_options\nfrom tornado.util import basestring_type, exec_in\nfrom typing import (\nAny\nIterator\nIterable\nTuple\nSet\nDict\nCallable\nList\nTextIO\nOptional\n)",
      "lineNum": 24,
      "relativeDocumentPath": "tornado/options.py"
    },
    {
      "symbolName": "set",
      "sourceCode": "def set(self, value: Any) -> None:\n        if self.multiple:\n            if not isinstance(value, list):\n                raise Error(\n                    \"Option %r is required to be a list of %s\"\n                    % (self.name, self.type.__name__)\n                )\n            for item in value:\n                if item is not None and not isinstance(item, self.type):\n                    raise Error(\n                        \"Option %r is required to be a list of %s\"\n                        % (self.name, self.type.__name__)\n                    )\n        else:\n            if value is not None and not isinstance(value, self.type):\n                raise Error(\n                    \"Option %r is required to be a %s (%s given)\"\n                    % (self.name, self.type.__name__, type(value))\n                )\n        self._value = value\n        if self.callback is not None:\n            self.callback(self._value)",
      "importString": "import datetime\nimport numbers\nimport re\nimport sys\nimport os\nimport textwrap\nfrom tornado.escape import _unicode, native_str\nfrom tornado.log import define_logging_options\nfrom tornado.util import basestring_type, exec_in\nfrom typing import (\nAny\nIterator\nIterable\nTuple\nSet\nDict\nCallable\nList\nTextIO\nOptional\n)",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/options.py"
    },
    {
      "symbolName": "_parse_timedelta",
      "sourceCode": "def _parse_timedelta(self, value: str) -> datetime.timedelta:\n        try:\n            sum = datetime.timedelta()\n            start = 0\n            while start < len(value):\n                m = self._TIMEDELTA_PATTERN.match(value, start)\n                if not m:\n                    raise Exception()\n                num = float(m.group(1))\n                units = m.group(2) or \"seconds\"\n                units = self._TIMEDELTA_ABBREV_DICT.get(units, units)\n\n                sum += datetime.timedelta(**{units: num})\n                start = m.end()\n            return sum\n        except Exception:\n            raise",
      "importString": "import datetime\nimport numbers\nimport re\nimport sys\nimport os\nimport textwrap\nfrom tornado.escape import _unicode, native_str\nfrom tornado.log import define_logging_options\nfrom tornado.util import basestring_type, exec_in\nfrom typing import (\nAny\nIterator\nIterable\nTuple\nSet\nDict\nCallable\nList\nTextIO\nOptional\n)",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/options.py"
    },
    {
      "symbolName": "define",
      "sourceCode": "def define(\n    name: str,\n    default: Any = None,\n    type: Optional[type] = None,\n    help: Optional[str] = None,\n    metavar: Optional[str] = None,\n    multiple: bool = False,\n    group: Optional[str] = None,\n    callback: Optional[Callable[[Any], None]] = None,\n) -> None:\n    \"\"\"Defines an option in the global namespace.\n\n    See `OptionParser.define`.\n    \"\"\"\n    return options.define(\n        name,\n        default=default,\n        type=type,\n        help=help,\n        metavar=metavar,\n        multiple=multiple,\n        group=group,\n        callback=callback,\n    )",
      "importString": "import datetime\nimport numbers\nimport re\nimport sys\nimport os\nimport textwrap\nfrom tornado.escape import _unicode, native_str\nfrom tornado.log import define_logging_options\nfrom tornado.util import basestring_type, exec_in\nfrom typing import (\nAny\nIterator\nIterable\nTuple\nSet\nDict\nCallable\nList\nTextIO\nOptional\n)",
      "lineNum": 23,
      "relativeDocumentPath": "tornado/options.py"
    },
    {
      "symbolName": "_atexit_callback",
      "sourceCode": "def _atexit_callback() -> None:\n    for loop in _selector_loops:\n        with loop._select_cond:\n            loop._closing_selector = True\n            loop._select_cond.notify()\n        try:\n            loop._waker_w.send(b\"a\")\n        except BlockingIOError:\n            pass\n        if loop._thread is not None:\n            # If we don't join our (daemon) thread here, we may get a deadlock\n            # during interpreter shutdown. I don't really understand why. This\n            # deadlock happens every time in CI (both travis and appveyor) but\n            # I've never been able to reproduce locally.\n            loop._thread.join()\n    _selector_loops.clear()",
      "importString": "import atexit\nimport concurrent.futures\nimport contextvars\nimport errno\nimport functools\nimport select\nimport socket\nimport sys\nimport threading\nimport typing\nimport warnings\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\nfrom typing import (\nAny\nCallable\nDict\nList\nOptional\nProtocol\nSet\nTuple\nTypeVar\nUnion\n)",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/platform/asyncio.py"
    },
    {
      "symbolName": "initialize",
      "sourceCode": "def initialize(  # type: ignore\n        self, asyncio_loop: asyncio.AbstractEventLoop, **kwargs: Any\n    ) -> None:\n        # asyncio_loop is always the real underlying IOLoop. This is used in\n        # ioloop.py to maintain the asyncio-to-ioloop mappings.\n        self.asyncio_loop = asyncio_loop\n        # selector_loop is an event loop that implements the add_reader family of\n        # methods. Usually the same as asyncio_loop but differs on platforms such\n        # as windows where the default event loop does not implement these methods.\n        self.selector_loop = asyncio_loop\n        if hasattr(asyncio, \"ProactorEventLoop\") and isinstance(\n            asyncio_loop, asyncio.ProactorEventLoop\n        ):\n            # Ignore this line for mypy because the abstract method checker\n            # doesn't understand dynamic proxies.\n            self.selector_loop = AddThreadSelectorEventLoop(asyncio_loop)  # type: ignore\n        # Maps fd to (fileobj, handler function) pair (as in IOLoop.add_handler)\n        self.handlers: Dict[int, Tuple[Union[int, _Selectable], Callable]] = {}\n        # Set of fds listening for reads/writes\n        self.readers: Set[int] = set()\n        self.writers: Set[int] = set()\n        self.closing = False\n        # If an asyncio loop was closed through an asyncio interface\n        # instead of IOLoop.close(), we'd never hear about it and may\n        # have left a dangling reference in our map. In case an\n        # application (or, more likely, a test suite) creates and\n        # destroys a lot of event loops in this way, check here to\n        # ensure that we don't have a lot of dead loops building up in\n        # the map.\n        #\n        # TODO(bdarnell): consider making self.asyncio_loop a weakref\n        # for AsyncIOMainLoop and make _ioloop_for_asyncio a\n        # WeakKeyDictionary.\n        for loop in IOLoop._ioloop_for_asyncio.copy():\n            if loop.is_closed():\n                try:\n                    del IOLoop._ioloop_for_asyncio[loop]\n                except KeyError:\n                    pass\n\n        # Make sure we don't already have an IOLoop for this asyncio loop\n        existing_loop = IOLoop._ioloop_for_asyncio.setdefault(asyncio_loop, self)\n        if existing_loop is not self:\n            raise RuntimeError(\n                f\"IOLoop {existing_loop} already associated with asyncio loop {asyncio_loop}\"\n            )\n\n        super().initialize(**kwargs)",
      "importString": "import atexit\nimport concurrent.futures\nimport contextvars\nimport errno\nimport functools\nimport select\nimport socket\nimport sys\nimport threading\nimport typing\nimport warnings\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\nfrom typing import (\nAny\nCallable\nDict\nList\nOptional\nProtocol\nSet\nTuple\nTypeVar\nUnion\n)",
      "lineNum": 47,
      "relativeDocumentPath": "tornado/platform/asyncio.py"
    },
    {
      "symbolName": "close",
      "sourceCode": "def close(self, all_fds: bool = False) -> None:\n        self.closing = True\n        for fd in list(self.handlers):\n            fileobj, handler_func = self.handlers[fd]\n            self.remove_handler(fd)\n            if all_fds:\n                self.close_fd(fileobj)\n        # Remove the mapping before closing the asyncio loop. If this\n        # happened in the other order, we could race against another\n        # initialize() call which would see the closed asyncio loop,\n        # assume it was closed from the asyncio side, and do this\n        # cleanup for us, leading to a KeyError.\n        del IOLoop._ioloop_for_asyncio[self.asyncio_loop]\n        if self.selector_loop is not self.asyncio_loop:\n            self.selector_loop.close()\n        self.asyncio_loop.close()",
      "importString": "import atexit\nimport concurrent.futures\nimport contextvars\nimport errno\nimport functools\nimport select\nimport socket\nimport sys\nimport threading\nimport typing\nimport warnings\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\nfrom typing import (\nAny\nCallable\nDict\nList\nOptional\nProtocol\nSet\nTuple\nTypeVar\nUnion\n)",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/platform/asyncio.py"
    },
    {
      "symbolName": "add_handler",
      "sourceCode": "def add_handler(\n        self, fd: Union[int, _Selectable], handler: Callable[..., None], events: int\n    ) -> None:\n        fd, fileobj = self.split_fd(fd)\n        if fd in self.handlers:\n            raise ValueError(\"fd %s added twice\" % fd)\n        self.handlers[fd] = (fileobj, handler)\n        if events & IOLoop.READ:\n            self.selector_loop.add_reader(fd, self._handle_events, fd, IOLoop.READ)\n            self.readers.add(fd)\n        if events & IOLoop.WRITE:\n            self.selector_loop.add_writer(fd, self._handle_events, fd, IOLoop.WRITE)\n            self.writers.add(fd)",
      "importString": "import atexit\nimport concurrent.futures\nimport contextvars\nimport errno\nimport functools\nimport select\nimport socket\nimport sys\nimport threading\nimport typing\nimport warnings\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\nfrom typing import (\nAny\nCallable\nDict\nList\nOptional\nProtocol\nSet\nTuple\nTypeVar\nUnion\n)",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/platform/asyncio.py"
    },
    {
      "symbolName": "update_handler",
      "sourceCode": "def update_handler(self, fd: Union[int, _Selectable], events: int) -> None:\n        fd, fileobj = self.split_fd(fd)\n        if events & IOLoop.READ:\n            if fd not in self.readers:\n                self.selector_loop.add_reader(fd, self._handle_events, fd, IOLoop.READ)\n                self.readers.add(fd)\n        else:\n            if fd in self.readers:\n                self.selector_loop.remove_reader(fd)\n                self.readers.remove(fd)\n        if events & IOLoop.WRITE:\n            if fd not in self.writers:\n                self.selector_loop.add_writer(fd, self._handle_events, fd, IOLoop.WRITE)\n                self.writers.add(fd)\n        else:\n            if fd in self.writers:\n                self.selector_loop.remove_writer(fd)\n                self.writers.remove(fd)",
      "importString": "import atexit\nimport concurrent.futures\nimport contextvars\nimport errno\nimport functools\nimport select\nimport socket\nimport sys\nimport threading\nimport typing\nimport warnings\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\nfrom typing import (\nAny\nCallable\nDict\nList\nOptional\nProtocol\nSet\nTuple\nTypeVar\nUnion\n)",
      "lineNum": 17,
      "relativeDocumentPath": "tornado/platform/asyncio.py"
    },
    {
      "symbolName": "remove_handler",
      "sourceCode": "def remove_handler(self, fd: Union[int, _Selectable]) -> None:\n        fd, fileobj = self.split_fd(fd)\n        if fd not in self.handlers:\n            return\n        if fd in self.readers:\n            self.selector_loop.remove_reader(fd)\n            self.readers.remove(fd)\n        if fd in self.writers:\n            self.selector_loop.remove_writer(fd)\n            self.writers.remove(fd)\n        del self.handlers[fd]",
      "importString": "import atexit\nimport concurrent.futures\nimport contextvars\nimport errno\nimport functools\nimport select\nimport socket\nimport sys\nimport threading\nimport typing\nimport warnings\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\nfrom typing import (\nAny\nCallable\nDict\nList\nOptional\nProtocol\nSet\nTuple\nTypeVar\nUnion\n)",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/platform/asyncio.py"
    },
    {
      "symbolName": "call_at",
      "sourceCode": "def call_at(\n        self, when: float, callback: Callable, *args: Any, **kwargs: Any\n    ) -> object:\n        # asyncio.call_at supports *args but not **kwargs, so bind them here.\n        # We do not synchronize self.time and asyncio_loop.time, so\n        # convert from absolute to relative.\n        return self.asyncio_loop.call_later(\n            max(0, when - self.time()),\n            self._run_callback,\n            functools.partial(callback, *args, **kwargs),\n        )",
      "importString": "import atexit\nimport concurrent.futures\nimport contextvars\nimport errno\nimport functools\nimport select\nimport socket\nimport sys\nimport threading\nimport typing\nimport warnings\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\nfrom typing import (\nAny\nCallable\nDict\nList\nOptional\nProtocol\nSet\nTuple\nTypeVar\nUnion\n)",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/platform/asyncio.py"
    },
    {
      "symbolName": "add_callback",
      "sourceCode": "def add_callback(self, callback: Callable, *args: Any, **kwargs: Any) -> None:\n        try:\n            if asyncio.get_running_loop() is self.asyncio_loop:\n                call_soon = self.asyncio_loop.call_soon\n            else:\n                call_soon = self.asyncio_loop.call_soon_threadsafe\n        except RuntimeError:\n            call_soon = self.asyncio_loop.call_soon_threadsafe\n\n        try:\n            call_soon(self._run_callback, functools.partial(callback, *args, **kwargs))\n        except RuntimeError:\n            # \"Event loop is closed\". Swallow the exception for\n            # consistency with PollIOLoop (and logical consistency\n            # with the fact that we can't guarantee that an\n            # add_callback that completes without error will\n            # eventually execute).\n            pass\n        except AttributeError:\n            # ProactorEventLoop may raise this instead of RuntimeError\n            # if call_soon_threadsafe races with a call to close().\n            # Swallow it too for consistency.\n            pass",
      "importString": "import atexit\nimport concurrent.futures\nimport contextvars\nimport errno\nimport functools\nimport select\nimport socket\nimport sys\nimport threading\nimport typing\nimport warnings\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\nfrom typing import (\nAny\nCallable\nDict\nList\nOptional\nProtocol\nSet\nTuple\nTypeVar\nUnion\n)",
      "lineNum": 22,
      "relativeDocumentPath": "tornado/platform/asyncio.py"
    },
    {
      "symbolName": "initialize",
      "sourceCode": "def initialize(self, **kwargs: Any) -> None:  # type: ignore\n        self.is_current = False\n        loop = None\n        if \"asyncio_loop\" not in kwargs:\n            kwargs[\"asyncio_loop\"] = loop = asyncio.new_event_loop()\n        try:\n            super().initialize(**kwargs)\n        except Exception:\n            # If initialize() does not succeed (taking ownership of the loop),\n            # we have to close it.\n            if loop is not None:\n                loop.close()\n            raise",
      "importString": "import atexit\nimport concurrent.futures\nimport contextvars\nimport errno\nimport functools\nimport select\nimport socket\nimport sys\nimport threading\nimport typing\nimport warnings\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\nfrom typing import (\nAny\nCallable\nDict\nList\nOptional\nProtocol\nSet\nTuple\nTypeVar\nUnion\n)",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/platform/asyncio.py"
    },
    {
      "symbolName": "to_asyncio_future",
      "sourceCode": "def to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:\n    \"\"\"Convert a Tornado yieldable object to an `asyncio.Future`.\n\n    .. versionadded:: 4.1\n\n    .. versionchanged:: 4.3\n       Now accepts any yieldable object, not just\n       `tornado.concurrent.Future`.\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,\n       so this method is now equivalent to `tornado.gen.convert_yielded`.\n    \"\"\"\n    return convert_yielded(tornado_future)",
      "importString": "import atexit\nimport concurrent.futures\nimport contextvars\nimport errno\nimport functools\nimport select\nimport socket\nimport sys\nimport threading\nimport typing\nimport warnings\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\nfrom typing import (\nAny\nCallable\nDict\nList\nOptional\nProtocol\nSet\nTuple\nTypeVar\nUnion\n)",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/platform/asyncio.py"
    },
    {
      "symbolName": "__getattr__",
      "sourceCode": "def __getattr__(name: str) -> typing.Any:\n    # The event loop policy system is deprecated in Python 3.14; simply accessing\n    # the name asyncio.DefaultEventLoopPolicy will raise a warning. Lazily create\n    # the AnyThreadEventLoopPolicy class so that the warning is only raised if\n    # the policy is used.\n    if name != \"AnyThreadEventLoopPolicy\":\n        raise AttributeError(f\"module {__name__!r} has no attribute {name!r}\")\n\n    global _AnyThreadEventLoopPolicy\n    if _AnyThreadEventLoopPolicy is None:\n        if sys.platform == \"win32\" and hasattr(\n            asyncio, \"WindowsSelectorEventLoopPolicy\"\n        ):\n            # \"Any thread\" and \"selector\" should be orthogonal, but there's not a clean\n            # interface for composing policies so pick the right base.\n            _BasePolicy = asyncio.WindowsSelectorEventLoopPolicy  # type: ignore\n        else:\n            _BasePolicy = asyncio.DefaultEventLoopPolicy\n\n        class AnyThreadEventLoopPolicy(_BasePolicy):  # type: ignore\n            \"\"\"Event loop policy that allows loop creation on any thread.\n\n            The default `asyncio` event loop policy only automatically creates\n            event loops in the main threads. Other threads must create event\n            loops explicitly or `asyncio.get_event_loop` (and therefore\n            `.IOLoop.current`) will fail. Installing this policy allows event\n            loops to be created automatically on any thread, matching the\n            behavior of Tornado versions prior to 5.0 (or 5.0 on Python 2).\n\n            Usage::\n\n                asyncio.set_event_loop_policy(AnyThreadEventLoopPolicy())\n\n            .. versionadded:: 5.0\n\n            .. deprecated:: 6.2\n\n                ``AnyThreadEventLoopPolicy`` affects the implicit creation\n                of an event loop, which is deprecated in Python 3.10 and\n                will be removed in a future version of Python. At that time\n                ``AnyThreadEventLoopPolicy`` will no longer be useful.\n                If you are relying on it, use `asyncio.new_event_loop`\n                or `asyncio.run` explicitly in any non-main threads that\n                need event loops.\n            \"\"\"\n\n            def __init__(self) -> None:\n                super().__init__()\n                warnings.warn(\n                    \"AnyThreadEventLoopPolicy is deprecated, use asyncio.run \"\n                    \"or asyncio.new_event_loop instead\",\n                    DeprecationWarning,\n                    stacklevel=2,\n                )\n\n            def get_event_loop(self) -> asyncio.AbstractEventLoop:\n                try:\n                    return super().get_event_loop()\n                except RuntimeError:\n                    # \"There is no current event loop in thread %r\"\n                    loop = self.new_event_loop()\n                    self.set_event_loop(loop)\n                    return loop\n\n        _AnyThreadEventLoopPolicy = AnyThreadEventLoopPolicy\n\n    return _AnyThreadEventLoopPolicy",
      "importString": "import atexit\nimport concurrent.futures\nimport contextvars\nimport errno\nimport functools\nimport select\nimport socket\nimport sys\nimport threading\nimport typing\nimport warnings\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\nfrom typing import (\nAny\nCallable\nDict\nList\nOptional\nProtocol\nSet\nTuple\nTypeVar\nUnion\n)",
      "lineNum": 66,
      "relativeDocumentPath": "tornado/platform/asyncio.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(self, real_loop: asyncio.AbstractEventLoop) -> None:\n        self._main_thread_ctx = contextvars.copy_context()\n\n        self._real_loop = real_loop\n\n        self._select_cond = threading.Condition()\n        self._select_args: Optional[\n            Tuple[List[_FileDescriptorLike], List[_FileDescriptorLike]]\n        ] = None\n        self._closing_selector = False\n        self._thread: Optional[threading.Thread] = None\n        self._thread_manager_handle = self._thread_manager()\n\n        async def thread_manager_anext() -> None:\n            # the anext builtin wasn't added until 3.10. We just need to iterate\n            # this generator one step.\n            await self._thread_manager_handle.__anext__()\n\n        # When the loop starts, start the thread. Not too soon because we can't\n        # clean up if we get to this point but the event loop is closed without\n        # starting.\n        self._real_loop.call_soon(\n            lambda: self._real_loop.create_task(thread_manager_anext()),\n            context=self._main_thread_ctx,\n        )\n\n        self._readers: Dict[_FileDescriptorLike, Callable] = {}\n        self._writers: Dict[_FileDescriptorLike, Callable] = {}\n\n        # Writing to _waker_w will wake up the selector thread, which\n        # watches for _waker_r to be readable.\n        self._waker_r, self._waker_w = socket.socketpair()\n        self._waker_r.setblocking(False)\n        self._waker_w.setblocking(False)\n        _selector_loops.add(self)\n        self.add_reader(self._waker_r, self._consume_waker)",
      "importString": "import atexit\nimport concurrent.futures\nimport contextvars\nimport errno\nimport functools\nimport select\nimport socket\nimport sys\nimport threading\nimport typing\nimport warnings\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\nfrom typing import (\nAny\nCallable\nDict\nList\nOptional\nProtocol\nSet\nTuple\nTypeVar\nUnion\n)",
      "lineNum": 35,
      "relativeDocumentPath": "tornado/platform/asyncio.py"
    },
    {
      "symbolName": "close",
      "sourceCode": "def close(self) -> None:\n        if self._closed:\n            return\n        with self._select_cond:\n            self._closing_selector = True\n            self._select_cond.notify()\n        self._wake_selector()\n        if self._thread is not None:\n            self._thread.join()\n        _selector_loops.discard(self)\n        self.remove_reader(self._waker_r)\n        self._waker_r.close()\n        self._waker_w.close()\n        self._closed = True",
      "importString": "import atexit\nimport concurrent.futures\nimport contextvars\nimport errno\nimport functools\nimport select\nimport socket\nimport sys\nimport threading\nimport typing\nimport warnings\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\nfrom typing import (\nAny\nCallable\nDict\nList\nOptional\nProtocol\nSet\nTuple\nTypeVar\nUnion\n)",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/platform/asyncio.py"
    },
    {
      "symbolName": "_thread_manager",
      "sourceCode": "async def _thread_manager(self) -> typing.AsyncGenerator[None, None]:\n        # Create a thread to run the select system call. We manage this thread\n        # manually so we can trigger a clean shutdown from an atexit hook. Note\n        # that due to the order of operations at shutdown, only daemon threads\n        # can be shut down in this way (non-daemon threads would require the\n        # introduction of a new hook: https://bugs.python.org/issue41962)\n        self._thread = threading.Thread(\n            name=\"Tornado selector\",\n            daemon=True,\n            target=self._run_select,\n        )\n        self._thread.start()\n        self._start_select()\n        try:\n            # The presense of this yield statement means that this coroutine\n            # is actually an asynchronous generator, which has a special\n            # shutdown protocol. We wait at this yield point until the\n            # event loop's shutdown_asyncgens method is called, at which point\n            # we will get a GeneratorExit exception and can shut down the\n            # selector thread.\n            yield\n        except GeneratorExit:\n            self.close()\n            raise",
      "importString": "import atexit\nimport concurrent.futures\nimport contextvars\nimport errno\nimport functools\nimport select\nimport socket\nimport sys\nimport threading\nimport typing\nimport warnings\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\nfrom typing import (\nAny\nCallable\nDict\nList\nOptional\nProtocol\nSet\nTuple\nTypeVar\nUnion\n)",
      "lineNum": 23,
      "relativeDocumentPath": "tornado/platform/asyncio.py"
    },
    {
      "symbolName": "_run_select",
      "sourceCode": "def _run_select(self) -> None:\n        while True:\n            with self._select_cond:\n                while self._select_args is None and not self._closing_selector:\n                    self._select_cond.wait()\n                if self._closing_selector:\n                    return\n                assert self._select_args is not None\n                to_read, to_write = self._select_args\n                self._select_args = None\n\n            # We use the simpler interface of the select module instead of\n            # the more stateful interface in the selectors module because\n            # this class is only intended for use on windows, where\n            # select.select is the only option. The selector interface\n            # does not have well-documented thread-safety semantics that\n            # we can rely on so ensuring proper synchronization would be\n            # tricky.\n            try:\n                # On windows, selecting on a socket for write will not\n                # return the socket when there is an error (but selecting\n                # for reads works). Also select for errors when selecting\n                # for writes, and merge the results.\n                #\n                # This pattern is also used in\n                # https://github.com/python/cpython/blob/v3.8.0/Lib/selectors.py#L312-L317\n                rs, ws, xs = select.select(to_read, to_write, to_write)\n                ws = ws + xs\n            except OSError as e:\n                # After remove_reader or remove_writer is called, the file\n                # descriptor may subsequently be closed on the event loop\n                # thread. It's possible that this select thread hasn't\n                # gotten into the select system call by the time that\n                # happens in which case (at least on macOS), select may\n                # raise a \"bad file descriptor\" error. If we get that\n                # error, check and see if we're also being woken up by\n                # polling the waker alone. If we are, just return to the\n                # event loop and we'll get the updated set of file\n                # descriptors on the next iteration. Otherwise, raise the\n                # original error.\n                if e.errno == getattr(errno, \"WSAENOTSOCK\", errno.EBADF):\n                    rs, _, _ = select.select([self._waker_r.fileno()], [], [], 0)\n                    if rs:\n                        ws = []\n                    else:\n                        raise\n                else:\n                    raise\n\n            try:\n                self._real_loop.call_soon_threadsafe(\n                    self._handle_select, rs, ws, context=self._main_thread_ctx\n                )\n            except RuntimeError:\n                # \"Event loop is closed\". Swallow the exception for\n                # consistency with PollIOLoop (and logical consistency\n                # with the fact that we can't guarantee that an\n                # add_callback that completes without error will\n                # eventually execute).\n                pass\n            except AttributeError:\n                # ProactorEventLoop may raise this instead of RuntimeError\n                # if call_soon_threadsafe races with a call to close().\n                # Swallow it too for consistency.\n                pass",
      "importString": "import atexit\nimport concurrent.futures\nimport contextvars\nimport errno\nimport functools\nimport select\nimport socket\nimport sys\nimport threading\nimport typing\nimport warnings\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\nfrom typing import (\nAny\nCallable\nDict\nList\nOptional\nProtocol\nSet\nTuple\nTypeVar\nUnion\n)",
      "lineNum": 64,
      "relativeDocumentPath": "tornado/platform/asyncio.py"
    },
    {
      "symbolName": "_sock_state_cb",
      "sourceCode": "def _sock_state_cb(self, fd: int, readable: bool, writable: bool) -> None:\n        state = (IOLoop.READ if readable else 0) | (IOLoop.WRITE if writable else 0)\n        if not state:\n            self.io_loop.remove_handler(fd)\n            del self.fds[fd]\n        elif fd in self.fds:\n            self.io_loop.update_handler(fd, state)\n            self.fds[fd] = state\n        else:\n            self.io_loop.add_handler(fd, self._handle_events, state)\n            self.fds[fd] = state",
      "importString": "import pycares\nimport socket\nfrom tornado.concurrent import Future\nfrom tornado import gen\nfrom tornado.ioloop import IOLoop\nfrom tornado.netutil import Resolver, is_valid_ip\n\nimport typing",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/platform/caresresolver.py"
    },
    {
      "symbolName": "resolve",
      "sourceCode": "@gen.coroutine\n    def resolve(\n        self, host: str, port: int, family: int = 0\n    ) -> \"Generator[Any, Any, List[Tuple[int, Any]]]\":\n        if is_valid_ip(host):\n            addresses = [host]\n        else:\n            # gethostbyname doesn't take callback as a kwarg\n            fut = Future()  # type: Future[Tuple[Any, Any]]\n            self.channel.gethostbyname(\n                host, family, lambda result, error: fut.set_result((result, error))\n            )\n            result, error = yield fut\n            if error:\n                raise OSError(\n                    \"C-Ares returned error %s: %s while resolving %s\"\n                    % (error, pycares.errno.strerror(error), host)\n                )\n            addresses = result.addresses\n        addrinfo = []\n        for address in addresses:\n            if \".\" in address:\n                address_family = socket.AF_INET\n            elif \":\" in address:\n                address_family = socket.AF_INET6\n            else:\n                address_family = socket.AF_UNSPEC\n            if family != socket.AF_UNSPEC and family != address_family:\n                raise OSError(\n                    \"Requested socket family %d but got %d\" % (family, address_family)\n                )\n            addrinfo.append((typing.cast(int, address_family), (address, port)))\n        return addrinfo",
      "importString": "import pycares\nimport socket\nfrom tornado.concurrent import Future\nfrom tornado import gen\nfrom tornado.ioloop import IOLoop\nfrom tornado.netutil import Resolver, is_valid_ip\n\nimport typing",
      "lineNum": 32,
      "relativeDocumentPath": "tornado/platform/caresresolver.py"
    },
    {
      "symbolName": "install",
      "sourceCode": "def install() -> None:\n    \"\"\"Install ``AsyncioSelectorReactor`` as the default Twisted reactor.\n\n    .. deprecated:: 5.1\n\n       This function is provided for backwards compatibility; code\n       that does not require compatibility with older versions of\n       Tornado should use\n       ``twisted.internet.asyncioreactor.install()`` directly.\n\n    .. versionchanged:: 6.0.3\n\n       In Tornado 5.x and before, this function installed a reactor\n       based on the Tornado ``IOLoop``. When that reactor\n       implementation was removed in Tornado 6.0.0, this function was\n       removed as well. It was restored in Tornado 6.0.3 using the\n       ``asyncio`` reactor instead.\n\n    \"\"\"\n    from twisted.internet.asyncioreactor import install  # type: ignore\n\n    install()",
      "importString": "import sys\nfrom twisted.internet.defer import Deferred\nfrom twisted.python import failure\nfrom tornado.concurrent import Future, future_set_exc_info\nfrom tornado import gen\n\nimport typing",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/platform/twisted.py"
    },
    {
      "symbolName": "_",
      "sourceCode": "@gen.convert_yielded.register(Deferred)\n    def _(d: Deferred) -> Future:\n        f = Future()  # type: Future[typing.Any]\n\n        def errback(failure: failure.Failure) -> None:\n            try:\n                failure.raiseException()\n                # Should never happen, but just in case\n                raise Exception(\"errback called without error\")\n            except:\n                future_set_exc_info(f, sys.exc_info())\n\n        d.addCallbacks(f.set_result, errback)\n        return f",
      "importString": "import sys\nfrom twisted.internet.defer import Deferred\nfrom twisted.python import failure\nfrom tornado.concurrent import Future, future_set_exc_info\nfrom tornado import gen\n\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/platform/twisted.py"
    },
    {
      "symbolName": "cpu_count",
      "sourceCode": "def cpu_count() -> int:\n    \"\"\"Returns the number of processors on this machine.\"\"\"\n    if multiprocessing is None:\n        return 1\n    try:\n        return multiprocessing.cpu_count()\n    except NotImplementedError:\n        pass\n    try:\n        return os.sysconf(\"SC_NPROCESSORS_CONF\")  # type: ignore\n    except (AttributeError, ValueError):\n        pass\n    gen_log.error(\"Could not detect number of processors; assuming 1\")\n    return 1",
      "importString": "import os\nimport multiprocessing\nimport signal\nimport subprocess\nimport sys\nimport time\nfrom binascii import hexlify\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado import ioloop\nfrom tornado.iostream import PipeIOStream\nfrom tornado.log import gen_log\n\nimport typing\nfrom typing import Optional, Any, Callable",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/process.py"
    },
    {
      "symbolName": "_reseed_random",
      "sourceCode": "def _reseed_random() -> None:\n    if \"random\" not in sys.modules:\n        return\n    import random\n\n    # If os.urandom is available, this method does the same thing as\n    # random.seed (at least as of python 2.6).  If os.urandom is not\n    # available, we mix in the pid in addition to a timestamp.\n    try:\n        seed = int(hexlify(os.urandom(16)), 16)\n    except NotImplementedError:\n        seed = int(time.time() * 1000) ^ os.getpid()\n    random.seed(seed)",
      "importString": "import os\nimport multiprocessing\nimport signal\nimport subprocess\nimport sys\nimport time\nfrom binascii import hexlify\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado import ioloop\nfrom tornado.iostream import PipeIOStream\nfrom tornado.log import gen_log\n\nimport typing\nfrom typing import Optional, Any, Callable",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/process.py"
    },
    {
      "symbolName": "fork_processes",
      "sourceCode": "def fork_processes(\n    num_processes: Optional[int], max_restarts: Optional[int] = None\n) -> int:\n    \"\"\"Starts multiple worker processes.\n\n    If ``num_processes`` is None or <= 0, we detect the number of cores\n    available on this machine and fork that number of child\n    processes. If ``num_processes`` is given and > 0, we fork that\n    specific number of sub-processes.\n\n    Since we use processes and not threads, there is no shared memory\n    between any server code.\n\n    Note that multiple processes are not compatible with the autoreload\n    module (or the ``autoreload=True`` option to `tornado.web.Application`\n    which defaults to True when ``debug=True``).\n    When using multiple processes, no IOLoops can be created or\n    referenced until after the call to ``fork_processes``.\n\n    In each child process, ``fork_processes`` returns its *task id*, a\n    number between 0 and ``num_processes``.  Processes that exit\n    abnormally (due to a signal or non-zero exit status) are restarted\n    with the same id (up to ``max_restarts`` times).  In the parent\n    process, ``fork_processes`` calls ``sys.exit(0)`` after all child\n    processes have exited normally.\n\n    max_restarts defaults to 100.\n\n    Availability: Unix\n    \"\"\"\n    if sys.platform == \"win32\":\n        # The exact form of this condition matters to mypy; it understands\n        # if but not assert in this context.\n        raise Exception(\"fork not available on windows\")\n    if max_restarts is None:\n        max_restarts = 100\n\n    assert _task_id is None\n    if num_processes is None or num_processes <= 0:\n        num_processes = cpu_count()\n    gen_log.info(\"Starting %d processes\", num_processes)\n    children = {}\n\n    def start_child(i: int) -> Optional[int]:\n        pid = os.fork()\n        if pid == 0:\n            # child process\n            _reseed_random()\n            global _task_id\n            _task_id = i\n            return i\n        else:\n            children[pid] = i\n            return None\n\n    for i in range(num_processes):\n        id = start_child(i)\n        if id is not None:\n            return id\n    num_restarts = 0\n    while children:\n        pid, status = os.wait()\n        if pid not in children:\n            continue\n        id = children.pop(pid)\n        if os.WIFSIGNALED(status):\n            gen_log.warning(\n                \"child %d (pid %d) killed by signal %d, restarting\",\n                id,\n                pid,\n                os.WTERMSIG(status),\n            )\n        elif os.WEXITSTATUS(status) != 0:\n            gen_log.warning(\n                \"child %d (pid %d) exited with status %d, restarting\",\n                id,\n                pid,\n                os.WEXITSTATUS(status),\n            )\n        else:\n            gen_log.info(\"child %d (pid %d) exited normally\", id, pid)\n            continue\n        num_restarts += 1\n        if num_restarts > max_restarts:\n            raise RuntimeError(\"Too many child restarts, giving up\")\n        new_id = start_child(id)\n        if new_id is not None:\n            return new_id\n    # All child processes exited cleanly, so exit the master process\n    # instead of just returning to right after the call to\n    # fork_processes (which will probably just start up another IOLoop\n    # unless the caller checks the return value).\n    sys.exit(0)",
      "importString": "import os\nimport multiprocessing\nimport signal\nimport subprocess\nimport sys\nimport time\nfrom binascii import hexlify\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado import ioloop\nfrom tornado.iostream import PipeIOStream\nfrom tornado.log import gen_log\n\nimport typing\nfrom typing import Optional, Any, Callable",
      "lineNum": 92,
      "relativeDocumentPath": "tornado/process.py"
    },
    {
      "symbolName": "start_child",
      "sourceCode": "def start_child(i: int) -> Optional[int]:\n        pid = os.fork()\n        if pid == 0:\n            # child process\n            _reseed_random()\n            global _task_id\n            _task_id = i\n            return i\n        else:\n            children[pid] = i\n            return None",
      "importString": "import os\nimport multiprocessing\nimport signal\nimport subprocess\nimport sys\nimport time\nfrom binascii import hexlify\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado import ioloop\nfrom tornado.iostream import PipeIOStream\nfrom tornado.log import gen_log\n\nimport typing\nfrom typing import Optional, Any, Callable",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/process.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(self, *args: Any, **kwargs: Any) -> None:\n        self.io_loop = ioloop.IOLoop.current()\n        # All FDs we create should be closed on error; those in to_close\n        # should be closed in the parent process on success.\n        pipe_fds = []  # type: List[int]\n        to_close = []  # type: List[int]\n        if kwargs.get(\"stdin\") is Subprocess.STREAM:\n            in_r, in_w = os.pipe()\n            kwargs[\"stdin\"] = in_r\n            pipe_fds.extend((in_r, in_w))\n            to_close.append(in_r)\n            self.stdin = PipeIOStream(in_w)\n        if kwargs.get(\"stdout\") is Subprocess.STREAM:\n            out_r, out_w = os.pipe()\n            kwargs[\"stdout\"] = out_w\n            pipe_fds.extend((out_r, out_w))\n            to_close.append(out_w)\n            self.stdout = PipeIOStream(out_r)\n        if kwargs.get(\"stderr\") is Subprocess.STREAM:\n            err_r, err_w = os.pipe()\n            kwargs[\"stderr\"] = err_w\n            pipe_fds.extend((err_r, err_w))\n            to_close.append(err_w)\n            self.stderr = PipeIOStream(err_r)\n        try:\n            self.proc = subprocess.Popen(*args, **kwargs)\n        except:\n            for fd in pipe_fds:\n                os.close(fd)\n            raise\n        for fd in to_close:\n            os.close(fd)\n        self.pid = self.proc.pid\n        for attr in [\"stdin\", \"stdout\", \"stderr\"]:\n            if not hasattr(self, attr):  # don't clobber streams set above\n                setattr(self, attr, getattr(self.proc, attr))\n        self._exit_callback = None  # type: Optional[Callable[[int], None]]\n        self.returncode = None  # type: Optional[int]",
      "importString": "import os\nimport multiprocessing\nimport signal\nimport subprocess\nimport sys\nimport time\nfrom binascii import hexlify\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado import ioloop\nfrom tornado.iostream import PipeIOStream\nfrom tornado.log import gen_log\n\nimport typing\nfrom typing import Optional, Any, Callable",
      "lineNum": 37,
      "relativeDocumentPath": "tornado/process.py"
    },
    {
      "symbolName": "set_exit_callback",
      "sourceCode": "def set_exit_callback(self, callback: Callable[[int], None]) -> None:\n        \"\"\"Runs ``callback`` when this process exits.\n\n        The callback takes one argument, the return code of the process.\n\n        This method uses a ``SIGCHLD`` handler, which is a global setting\n        and may conflict if you have other libraries trying to handle the\n        same signal.  If you are using more than one ``IOLoop`` it may\n        be necessary to call `Subprocess.initialize` first to designate\n        one ``IOLoop`` to run the signal handlers.\n\n        In many cases a close callback on the stdout or stderr streams\n        can be used as an alternative to an exit callback if the\n        signal handler is causing a problem.\n\n        Availability: Unix\n        \"\"\"\n        self._exit_callback = callback\n        Subprocess.initialize()\n        Subprocess._waiting[self.pid] = self\n        Subprocess._try_cleanup_process(self.pid)",
      "importString": "import os\nimport multiprocessing\nimport signal\nimport subprocess\nimport sys\nimport time\nfrom binascii import hexlify\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado import ioloop\nfrom tornado.iostream import PipeIOStream\nfrom tornado.log import gen_log\n\nimport typing\nfrom typing import Optional, Any, Callable",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/process.py"
    },
    {
      "symbolName": "wait_for_exit",
      "sourceCode": "def wait_for_exit(self, raise_error: bool = True) -> \"Future[int]\":\n        \"\"\"Returns a `.Future` which resolves when the process exits.\n\n        Usage::\n\n            ret = yield proc.wait_for_exit()\n\n        This is a coroutine-friendly alternative to `set_exit_callback`\n        (and a replacement for the blocking `subprocess.Popen.wait`).\n\n        By default, raises `subprocess.CalledProcessError` if the process\n        has a non-zero exit status. Use ``wait_for_exit(raise_error=False)``\n        to suppress this behavior and return the exit status without raising.\n\n        .. versionadded:: 4.2\n\n        Availability: Unix\n        \"\"\"\n        future = Future()  # type: Future[int]\n\n        def callback(ret: int) -> None:\n            if ret != 0 and raise_error:\n                # Unfortunately we don't have the original args any more.\n                future_set_exception_unless_cancelled(\n                    future, CalledProcessError(ret, \"unknown\")\n                )\n            else:\n                future_set_result_unless_cancelled(future, ret)\n\n        self.set_exit_callback(callback)\n        return future",
      "importString": "import os\nimport multiprocessing\nimport signal\nimport subprocess\nimport sys\nimport time\nfrom binascii import hexlify\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado import ioloop\nfrom tornado.iostream import PipeIOStream\nfrom tornado.log import gen_log\n\nimport typing\nfrom typing import Optional, Any, Callable",
      "lineNum": 30,
      "relativeDocumentPath": "tornado/process.py"
    },
    {
      "symbolName": "initialize",
      "sourceCode": "@classmethod\n    def initialize(cls) -> None:\n        \"\"\"Initializes the ``SIGCHLD`` handler.\n\n        The signal handler is run on an `.IOLoop` to avoid locking issues.\n        Note that the `.IOLoop` used for signal handling need not be the\n        same one used by individual Subprocess objects (as long as the\n        ``IOLoops`` are each running in separate threads).\n\n        .. versionchanged:: 5.0\n           The ``io_loop`` argument (deprecated since version 4.1) has been\n           removed.\n\n        Availability: Unix\n        \"\"\"\n        if cls._initialized:\n            return\n        loop = asyncio.get_event_loop()\n        loop.add_signal_handler(signal.SIGCHLD, cls._cleanup)\n        cls._initialized = True",
      "importString": "import os\nimport multiprocessing\nimport signal\nimport subprocess\nimport sys\nimport time\nfrom binascii import hexlify\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado import ioloop\nfrom tornado.iostream import PipeIOStream\nfrom tornado.log import gen_log\n\nimport typing\nfrom typing import Optional, Any, Callable",
      "lineNum": 19,
      "relativeDocumentPath": "tornado/process.py"
    },
    {
      "symbolName": "_try_cleanup_process",
      "sourceCode": "@classmethod\n    def _try_cleanup_process(cls, pid: int) -> None:\n        try:\n            ret_pid, status = os.waitpid(pid, os.WNOHANG)  # type: ignore\n        except ChildProcessError:\n            return\n        if ret_pid == 0:\n            return\n        assert ret_pid == pid\n        subproc = cls._waiting.pop(pid)\n        subproc.io_loop.add_callback(subproc._set_returncode, status)",
      "importString": "import os\nimport multiprocessing\nimport signal\nimport subprocess\nimport sys\nimport time\nfrom binascii import hexlify\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado import ioloop\nfrom tornado.iostream import PipeIOStream\nfrom tornado.log import gen_log\n\nimport typing\nfrom typing import Optional, Any, Callable",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/process.py"
    },
    {
      "symbolName": "_set_returncode",
      "sourceCode": "def _set_returncode(self, status: int) -> None:\n        if sys.platform == \"win32\":\n            self.returncode = -1\n        else:\n            if os.WIFSIGNALED(status):\n                self.returncode = -os.WTERMSIG(status)\n            else:\n                assert os.WIFEXITED(status)\n                self.returncode = os.WEXITSTATUS(status)\n        # We've taken over wait() duty from the subprocess.Popen\n        # object. If we don't inform it of the process's return code,\n        # it will log a warning at destruction in python 3.6+.\n        self.proc.returncode = self.returncode\n        if self._exit_callback:\n            callback = self._exit_callback\n            self._exit_callback = None\n            callback(self.returncode)",
      "importString": "import os\nimport multiprocessing\nimport signal\nimport subprocess\nimport sys\nimport time\nfrom binascii import hexlify\nfrom tornado.concurrent import (\nFuture\nfuture_set_result_unless_cancelled\nfuture_set_exception_unless_cancelled\n)\nfrom tornado import ioloop\nfrom tornado.iostream import PipeIOStream\nfrom tornado.log import gen_log\n\nimport typing\nfrom typing import Optional, Any, Callable",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/process.py"
    },
    {
      "symbolName": "_set_timeout",
      "sourceCode": "def _set_timeout(\n    future: Future, timeout: Union[None, float, datetime.timedelta]\n) -> None:\n    if timeout:\n\n        def on_timeout() -> None:\n            if not future.done():\n                future.set_exception(gen.TimeoutError())\n\n        io_loop = ioloop.IOLoop.current()\n        timeout_handle = io_loop.add_timeout(timeout, on_timeout)\n        future.add_done_callback(lambda _: io_loop.remove_timeout(timeout_handle))",
      "importString": "import collections\nimport datetime\nimport heapq\nfrom tornado import gen, ioloop\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.locks import Event\n\nfrom typing import Union, TypeVar, Generic, Awaitable, Optional\nimport typing",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/queues.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(self, maxsize: int = 0) -> None:\n        if maxsize is None:\n            raise TypeError(\"maxsize can't be None\")\n\n        if maxsize < 0:\n            raise ValueError(\"maxsize can't be negative\")\n\n        self._maxsize = maxsize\n        self._init()\n        self._getters = collections.deque([])  # type: Deque[Future[_T]]\n        self._putters = collections.deque([])  # type: Deque[Tuple[_T, Future[None]]]\n        self._unfinished_tasks = 0\n        self._finished = Event()\n        self._finished.set()",
      "importString": "import collections\nimport datetime\nimport heapq\nfrom tornado import gen, ioloop\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.locks import Event\n\nfrom typing import Union, TypeVar, Generic, Awaitable, Optional\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/queues.py"
    },
    {
      "symbolName": "put",
      "sourceCode": "def put(\n        self, item: _T, timeout: Optional[Union[float, datetime.timedelta]] = None\n    ) -> \"Future[None]\":\n        \"\"\"Put an item into the queue, perhaps waiting until there is room.\n\n        Returns a Future, which raises `tornado.util.TimeoutError` after a\n        timeout.\n\n        ``timeout`` may be a number denoting a time (on the same\n        scale as `tornado.ioloop.IOLoop.time`, normally `time.time`), or a\n        `datetime.timedelta` object for a deadline relative to the\n        current time.\n        \"\"\"\n        future = Future()  # type: Future[None]\n        try:\n            self.put_nowait(item)\n        except QueueFull:\n            self._putters.append((item, future))\n            _set_timeout(future, timeout)\n        else:\n            future.set_result(None)\n        return future",
      "importString": "import collections\nimport datetime\nimport heapq\nfrom tornado import gen, ioloop\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.locks import Event\n\nfrom typing import Union, TypeVar, Generic, Awaitable, Optional\nimport typing",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/queues.py"
    },
    {
      "symbolName": "put_nowait",
      "sourceCode": "def put_nowait(self, item: _T) -> None:\n        \"\"\"Put an item into the queue without blocking.\n\n        If no free slot is immediately available, raise `QueueFull`.\n        \"\"\"\n        self._consume_expired()\n        if self._getters:\n            assert self.empty(), \"queue non-empty, why are getters waiting?\"\n            getter = self._getters.popleft()\n            self.__put_internal(item)\n            future_set_result_unless_cancelled(getter, self._get())\n        elif self.full():\n            raise QueueFull\n        else:\n            self.__put_internal(item)",
      "importString": "import collections\nimport datetime\nimport heapq\nfrom tornado import gen, ioloop\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.locks import Event\n\nfrom typing import Union, TypeVar, Generic, Awaitable, Optional\nimport typing",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/queues.py"
    },
    {
      "symbolName": "get",
      "sourceCode": "def get(\n        self, timeout: Optional[Union[float, datetime.timedelta]] = None\n    ) -> Awaitable[_T]:\n        \"\"\"Remove and return an item from the queue.\n\n        Returns an awaitable which resolves once an item is available, or raises\n        `tornado.util.TimeoutError` after a timeout.\n\n        ``timeout`` may be a number denoting a time (on the same\n        scale as `tornado.ioloop.IOLoop.time`, normally `time.time`), or a\n        `datetime.timedelta` object for a deadline relative to the\n        current time.\n\n        .. note::\n\n           The ``timeout`` argument of this method differs from that\n           of the standard library's `queue.Queue.get`. That method\n           interprets numeric values as relative timeouts; this one\n           interprets them as absolute deadlines and requires\n           ``timedelta`` objects for relative timeouts (consistent\n           with other timeouts in Tornado).\n\n        \"\"\"\n        future = Future()  # type: Future[_T]\n        try:\n            future.set_result(self.get_nowait())\n        except QueueEmpty:\n            self._getters.append(future)\n            _set_timeout(future, timeout)\n        return future",
      "importString": "import collections\nimport datetime\nimport heapq\nfrom tornado import gen, ioloop\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.locks import Event\n\nfrom typing import Union, TypeVar, Generic, Awaitable, Optional\nimport typing",
      "lineNum": 29,
      "relativeDocumentPath": "tornado/queues.py"
    },
    {
      "symbolName": "get_nowait",
      "sourceCode": "def get_nowait(self) -> _T:\n        \"\"\"Remove and return an item from the queue without blocking.\n\n        Return an item if one is immediately available, else raise\n        `QueueEmpty`.\n        \"\"\"\n        self._consume_expired()\n        if self._putters:\n            assert self.full(), \"queue not full, why are putters waiting?\"\n            item, putter = self._putters.popleft()\n            self.__put_internal(item)\n            future_set_result_unless_cancelled(putter, None)\n            return self._get()\n        elif self.qsize():\n            return self._get()\n        else:\n            raise QueueEmpty",
      "importString": "import collections\nimport datetime\nimport heapq\nfrom tornado import gen, ioloop\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.locks import Event\n\nfrom typing import Union, TypeVar, Generic, Awaitable, Optional\nimport typing",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/queues.py"
    },
    {
      "symbolName": "task_done",
      "sourceCode": "def task_done(self) -> None:\n        \"\"\"Indicate that a formerly enqueued task is complete.\n\n        Used by queue consumers. For each `.get` used to fetch a task, a\n        subsequent call to `.task_done` tells the queue that the processing\n        on the task is complete.\n\n        If a `.join` is blocking, it resumes when all items have been\n        processed; that is, when every `.put` is matched by a `.task_done`.\n\n        Raises `ValueError` if called more times than `.put`.\n        \"\"\"\n        if self._unfinished_tasks <= 0:\n            raise ValueError(\"task_done() called too many times\")\n        self._unfinished_tasks -= 1\n        if self._unfinished_tasks == 0:\n            self._finished.set()",
      "importString": "import collections\nimport datetime\nimport heapq\nfrom tornado import gen, ioloop\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.locks import Event\n\nfrom typing import Union, TypeVar, Generic, Awaitable, Optional\nimport typing",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/queues.py"
    },
    {
      "symbolName": "_format",
      "sourceCode": "def _format(self) -> str:\n        result = f\"maxsize={self.maxsize!r}\"\n        if getattr(self, \"_queue\", None):\n            result += \" queue=%r\" % self._queue\n        if self._getters:\n            result += \" getters[%s]\" % len(self._getters)\n        if self._putters:\n            result += \" putters[%s]\" % len(self._putters)\n        if self._unfinished_tasks:\n            result += \" tasks=%s\" % self._unfinished_tasks\n        return result",
      "importString": "import collections\nimport datetime\nimport heapq\nfrom tornado import gen, ioloop\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.locks import Event\n\nfrom typing import Union, TypeVar, Generic, Awaitable, Optional\nimport typing",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/queues.py"
    },
    {
      "symbolName": "find_handler",
      "sourceCode": "def find_handler(\n        self, request: httputil.HTTPServerRequest, **kwargs: Any\n    ) -> Optional[httputil.HTTPMessageDelegate]:\n        \"\"\"Must be implemented to return an appropriate instance of `~.httputil.HTTPMessageDelegate`\n        that can serve the request.\n        Routing implementations may pass additional kwargs to extend the routing logic.\n\n        :arg httputil.HTTPServerRequest request: current HTTP request.\n        :arg kwargs: additional keyword arguments passed by routing implementation.\n        :returns: an instance of `~.httputil.HTTPMessageDelegate` that will be used to\n            process the request.\n        \"\"\"\n        raise NotImplementedError()",
      "importString": "import re\nfrom functools import partial\n\nfrom tornado import httputil\nfrom tornado.httpserver import _CallableAdapter\nfrom tornado.escape import url_escape, url_unescape, utf8\nfrom tornado.log import app_log\nfrom tornado.util import basestring_type, import_object, re_unescape, unicode_type\nfrom typing import (\nAny\nUnion\nOptional\nAwaitable\nList\nDict\nPattern\nTuple\noverload\nSequence\n)",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/routing.py"
    },
    {
      "symbolName": "headers_received",
      "sourceCode": "def headers_received(\n        self,\n        start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n        headers: httputil.HTTPHeaders,\n    ) -> Optional[Awaitable[None]]:\n        assert isinstance(start_line, httputil.RequestStartLine)\n        request = httputil.HTTPServerRequest(\n            connection=self.request_conn,\n            server_connection=self.server_conn,\n            start_line=start_line,\n            headers=headers,\n        )\n\n        self.delegate = self.router.find_handler(request)\n        if self.delegate is None:\n            app_log.debug(\n                \"Delegate for %s %s request not found\",\n                start_line.method,\n                start_line.path,\n            )\n            self.delegate = _DefaultMessageDelegate(self.request_conn)\n\n        return self.delegate.headers_received(start_line, headers)",
      "importString": "import re\nfrom functools import partial\n\nfrom tornado import httputil\nfrom tornado.httpserver import _CallableAdapter\nfrom tornado.escape import url_escape, url_unescape, utf8\nfrom tornado.log import app_log\nfrom tornado.util import basestring_type, import_object, re_unescape, unicode_type\nfrom typing import (\nAny\nUnion\nOptional\nAwaitable\nList\nDict\nPattern\nTuple\noverload\nSequence\n)",
      "lineNum": 22,
      "relativeDocumentPath": "tornado/routing.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(self, rules: Optional[_RuleList] = None) -> None:\n        \"\"\"Constructs a router from an ordered list of rules::\n\n            RuleRouter([\n                Rule(PathMatches(\"/handler\"), Target),\n                # ... more rules\n            ])\n\n        You can also omit explicit `Rule` constructor and use tuples of arguments::\n\n            RuleRouter([\n                (PathMatches(\"/handler\"), Target),\n            ])\n\n        `PathMatches` is a default matcher, so the example above can be simplified::\n\n            RuleRouter([\n                (\"/handler\", Target),\n            ])\n\n        In the examples above, ``Target`` can be a nested `Router` instance, an instance of\n        `~.httputil.HTTPServerConnectionDelegate` or an old-style callable,\n        accepting a request argument.\n\n        :arg rules: a list of `Rule` instances or tuples of `Rule`\n            constructor arguments.\n        \"\"\"\n        self.rules = []  # type: List[Rule]\n        if rules:\n            self.add_rules(rules)",
      "importString": "import re\nfrom functools import partial\n\nfrom tornado import httputil\nfrom tornado.httpserver import _CallableAdapter\nfrom tornado.escape import url_escape, url_unescape, utf8\nfrom tornado.log import app_log\nfrom tornado.util import basestring_type, import_object, re_unescape, unicode_type\nfrom typing import (\nAny\nUnion\nOptional\nAwaitable\nList\nDict\nPattern\nTuple\noverload\nSequence\n)",
      "lineNum": 29,
      "relativeDocumentPath": "tornado/routing.py"
    },
    {
      "symbolName": "add_rules",
      "sourceCode": "def add_rules(self, rules: _RuleList) -> None:\n        \"\"\"Appends new rules to the router.\n\n        :arg rules: a list of Rule instances (or tuples of arguments, which are\n            passed to Rule constructor).\n        \"\"\"\n        for rule in rules:\n            if isinstance(rule, (tuple, list)):\n                assert len(rule) in (2, 3, 4)\n                if isinstance(rule[0], basestring_type):\n                    rule = Rule(PathMatches(rule[0]), *rule[1:])\n                else:\n                    rule = Rule(*rule)\n\n            self.rules.append(self.process_rule(rule))",
      "importString": "import re\nfrom functools import partial\n\nfrom tornado import httputil\nfrom tornado.httpserver import _CallableAdapter\nfrom tornado.escape import url_escape, url_unescape, utf8\nfrom tornado.log import app_log\nfrom tornado.util import basestring_type, import_object, re_unescape, unicode_type\nfrom typing import (\nAny\nUnion\nOptional\nAwaitable\nList\nDict\nPattern\nTuple\noverload\nSequence\n)",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/routing.py"
    },
    {
      "symbolName": "find_handler",
      "sourceCode": "def find_handler(\n        self, request: httputil.HTTPServerRequest, **kwargs: Any\n    ) -> Optional[httputil.HTTPMessageDelegate]:\n        for rule in self.rules:\n            target_params = rule.matcher.match(request)\n            if target_params is not None:\n                if rule.target_kwargs:\n                    target_params[\"target_kwargs\"] = rule.target_kwargs\n\n                delegate = self.get_target_delegate(\n                    rule.target, request, **target_params\n                )\n\n                if delegate is not None:\n                    return delegate\n\n        return None",
      "importString": "import re\nfrom functools import partial\n\nfrom tornado import httputil\nfrom tornado.httpserver import _CallableAdapter\nfrom tornado.escape import url_escape, url_unescape, utf8\nfrom tornado.log import app_log\nfrom tornado.util import basestring_type, import_object, re_unescape, unicode_type\nfrom typing import (\nAny\nUnion\nOptional\nAwaitable\nList\nDict\nPattern\nTuple\noverload\nSequence\n)",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/routing.py"
    },
    {
      "symbolName": "get_target_delegate",
      "sourceCode": "def get_target_delegate(\n        self, target: Any, request: httputil.HTTPServerRequest, **target_params: Any\n    ) -> Optional[httputil.HTTPMessageDelegate]:\n        \"\"\"Returns an instance of `~.httputil.HTTPMessageDelegate` for a\n        Rule's target. This method is called by `~.find_handler` and can be\n        extended to provide additional target types.\n\n        :arg target: a Rule's target.\n        :arg httputil.HTTPServerRequest request: current request.\n        :arg target_params: additional parameters that can be useful\n            for `~.httputil.HTTPMessageDelegate` creation.\n        \"\"\"\n        if isinstance(target, Router):\n            return target.find_handler(request, **target_params)\n\n        elif isinstance(target, httputil.HTTPServerConnectionDelegate):\n            assert request.connection is not None\n            return target.start_request(request.server_connection, request.connection)\n\n        elif callable(target):\n            assert request.connection is not None\n            return _CallableAdapter(\n                partial(target, **target_params), request.connection\n            )\n\n        return None",
      "importString": "import re\nfrom functools import partial\n\nfrom tornado import httputil\nfrom tornado.httpserver import _CallableAdapter\nfrom tornado.escape import url_escape, url_unescape, utf8\nfrom tornado.log import app_log\nfrom tornado.util import basestring_type, import_object, re_unescape, unicode_type\nfrom typing import (\nAny\nUnion\nOptional\nAwaitable\nList\nDict\nPattern\nTuple\noverload\nSequence\n)",
      "lineNum": 25,
      "relativeDocumentPath": "tornado/routing.py"
    },
    {
      "symbolName": "process_rule",
      "sourceCode": "def process_rule(self, rule: \"Rule\") -> \"Rule\":\n        rule = super().process_rule(rule)\n\n        if rule.name:\n            if rule.name in self.named_rules:\n                app_log.warning(\n                    \"Multiple handlers named %s; replacing previous value\", rule.name\n                )\n            self.named_rules[rule.name] = rule\n\n        return rule",
      "importString": "import re\nfrom functools import partial\n\nfrom tornado import httputil\nfrom tornado.httpserver import _CallableAdapter\nfrom tornado.escape import url_escape, url_unescape, utf8\nfrom tornado.log import app_log\nfrom tornado.util import basestring_type, import_object, re_unescape, unicode_type\nfrom typing import (\nAny\nUnion\nOptional\nAwaitable\nList\nDict\nPattern\nTuple\noverload\nSequence\n)",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/routing.py"
    },
    {
      "symbolName": "reverse_url",
      "sourceCode": "def reverse_url(self, name: str, *args: Any) -> Optional[str]:\n        if name in self.named_rules:\n            return self.named_rules[name].matcher.reverse(*args)\n\n        for rule in self.rules:\n            if isinstance(rule.target, ReversibleRouter):\n                reversed_url = rule.target.reverse_url(name, *args)\n                if reversed_url is not None:\n                    return reversed_url\n\n        return None",
      "importString": "import re\nfrom functools import partial\n\nfrom tornado import httputil\nfrom tornado.httpserver import _CallableAdapter\nfrom tornado.escape import url_escape, url_unescape, utf8\nfrom tornado.log import app_log\nfrom tornado.util import basestring_type, import_object, re_unescape, unicode_type\nfrom typing import (\nAny\nUnion\nOptional\nAwaitable\nList\nDict\nPattern\nTuple\noverload\nSequence\n)",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/routing.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        matcher: \"Matcher\",\n        target: Any,\n        target_kwargs: Optional[Dict[str, Any]] = None,\n        name: Optional[str] = None,\n    ) -> None:\n        \"\"\"Constructs a Rule instance.\n\n        :arg Matcher matcher: a `Matcher` instance used for determining\n            whether the rule should be considered a match for a specific\n            request.\n        :arg target: a Rule's target (typically a ``RequestHandler`` or\n            `~.httputil.HTTPServerConnectionDelegate` subclass or even a nested `Router`,\n            depending on routing implementation).\n        :arg dict target_kwargs: a dict of parameters that can be useful\n            at the moment of target instantiation (for example, ``status_code``\n            for a ``RequestHandler`` subclass). They end up in\n            ``target_params['target_kwargs']`` of `RuleRouter.get_target_delegate`\n            method.\n        :arg str name: the name of the rule that can be used to find it\n            in `ReversibleRouter.reverse_url` implementation.\n        \"\"\"\n        if isinstance(target, str):\n            # import the Module and instantiate the class\n            # Must be a fully qualified name (module.ClassName)\n            target = import_object(target)\n\n        self.matcher = matcher  # type: Matcher\n        self.target = target\n        self.target_kwargs = target_kwargs if target_kwargs else {}\n        self.name = name",
      "importString": "import re\nfrom functools import partial\n\nfrom tornado import httputil\nfrom tornado.httpserver import _CallableAdapter\nfrom tornado.escape import url_escape, url_unescape, utf8\nfrom tornado.log import app_log\nfrom tornado.util import basestring_type, import_object, re_unescape, unicode_type\nfrom typing import (\nAny\nUnion\nOptional\nAwaitable\nList\nDict\nPattern\nTuple\noverload\nSequence\n)",
      "lineNum": 31,
      "relativeDocumentPath": "tornado/routing.py"
    },
    {
      "symbolName": "match",
      "sourceCode": "def match(self, request: httputil.HTTPServerRequest) -> Optional[Dict[str, Any]]:\n        \"\"\"Matches current instance against the request.\n\n        :arg httputil.HTTPServerRequest request: current HTTP request\n        :returns: a dict of parameters to be passed to the target handler\n            (for example, ``handler_kwargs``, ``path_args``, ``path_kwargs``\n            can be passed for proper `~.web.RequestHandler` instantiation).\n            An empty dict is a valid (and common) return value to indicate a match\n            when the argument-passing features are not used.\n            ``None`` must be returned to indicate that there is no match.\"\"\"\n        raise NotImplementedError()",
      "importString": "import re\nfrom functools import partial\n\nfrom tornado import httputil\nfrom tornado.httpserver import _CallableAdapter\nfrom tornado.escape import url_escape, url_unescape, utf8\nfrom tornado.log import app_log\nfrom tornado.util import basestring_type, import_object, re_unescape, unicode_type\nfrom typing import (\nAny\nUnion\nOptional\nAwaitable\nList\nDict\nPattern\nTuple\noverload\nSequence\n)",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/routing.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(self, path_pattern: Union[str, Pattern]) -> None:\n        if isinstance(path_pattern, basestring_type):\n            if not path_pattern.endswith(\"$\"):\n                path_pattern += \"$\"\n            self.regex = re.compile(path_pattern)\n        else:\n            self.regex = path_pattern\n\n        assert len(self.regex.groupindex) in (0, self.regex.groups), (\n            \"groups in url regexes must either be all named or all \"\n            \"positional: %r\" % self.regex.pattern\n        )\n\n        self._path, self._group_count = self._find_groups()",
      "importString": "import re\nfrom functools import partial\n\nfrom tornado import httputil\nfrom tornado.httpserver import _CallableAdapter\nfrom tornado.escape import url_escape, url_unescape, utf8\nfrom tornado.log import app_log\nfrom tornado.util import basestring_type, import_object, re_unescape, unicode_type\nfrom typing import (\nAny\nUnion\nOptional\nAwaitable\nList\nDict\nPattern\nTuple\noverload\nSequence\n)",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/routing.py"
    },
    {
      "symbolName": "match",
      "sourceCode": "def match(self, request: httputil.HTTPServerRequest) -> Optional[Dict[str, Any]]:\n        match = self.regex.match(request.path)\n        if match is None:\n            return None\n        if not self.regex.groups:\n            return {}\n\n        path_args = []  # type: List[bytes]\n        path_kwargs = {}  # type: Dict[str, bytes]\n\n        # Pass matched groups to the handler.  Since\n        # match.groups() includes both named and\n        # unnamed groups, we want to use either groups\n        # or groupdict but not both.\n        if self.regex.groupindex:\n            path_kwargs = {\n                str(k): _unquote_or_none(v) for (k, v) in match.groupdict().items()\n            }\n        else:\n            path_args = [_unquote_or_none(s) for s in match.groups()]\n\n        return dict(path_args=path_args, path_kwargs=path_kwargs)",
      "importString": "import re\nfrom functools import partial\n\nfrom tornado import httputil\nfrom tornado.httpserver import _CallableAdapter\nfrom tornado.escape import url_escape, url_unescape, utf8\nfrom tornado.log import app_log\nfrom tornado.util import basestring_type, import_object, re_unescape, unicode_type\nfrom typing import (\nAny\nUnion\nOptional\nAwaitable\nList\nDict\nPattern\nTuple\noverload\nSequence\n)",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/routing.py"
    },
    {
      "symbolName": "reverse",
      "sourceCode": "def reverse(self, *args: Any) -> Optional[str]:\n        if self._path is None:\n            raise ValueError(\"Cannot reverse url regex \" + self.regex.pattern)\n        assert len(args) == self._group_count, (\n            \"required number of arguments \" \"not found\"\n        )\n        if not len(args):\n            return self._path\n        converted_args = []\n        for a in args:\n            if not isinstance(a, (unicode_type, bytes)):\n                a = str(a)\n            converted_args.append(url_escape(utf8(a), plus=False))\n        return self._path % tuple(converted_args)",
      "importString": "import re\nfrom functools import partial\n\nfrom tornado import httputil\nfrom tornado.httpserver import _CallableAdapter\nfrom tornado.escape import url_escape, url_unescape, utf8\nfrom tornado.log import app_log\nfrom tornado.util import basestring_type, import_object, re_unescape, unicode_type\nfrom typing import (\nAny\nUnion\nOptional\nAwaitable\nList\nDict\nPattern\nTuple\noverload\nSequence\n)",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/routing.py"
    },
    {
      "symbolName": "_find_groups",
      "sourceCode": "def _find_groups(self) -> Tuple[Optional[str], Optional[int]]:\n        \"\"\"Returns a tuple (reverse string, group count) for a url.\n\n        For example: Given the url pattern /([0-9]{4})/([a-z-]+)/, this method\n        would return ('/%s/%s/', 2).\n        \"\"\"\n        pattern = self.regex.pattern\n        if pattern.startswith(\"^\"):\n            pattern = pattern[1:]\n        if pattern.endswith(\"$\"):\n            pattern = pattern[:-1]\n\n        if self.regex.groups != pattern.count(\"(\"):\n            # The pattern is too complicated for our simplistic matching,\n            # so we can't support reversing it.\n            return None, None\n\n        pieces = []\n        for fragment in pattern.split(\"(\"):\n            if \")\" in fragment:\n                paren_loc = fragment.index(\")\")\n                if paren_loc >= 0:\n                    try:\n                        unescaped_fragment = re_unescape(fragment[paren_loc + 1 :])\n                    except ValueError:\n                        # If we can't unescape part of it, we can't\n                        # reverse this url.\n                        return (None, None)\n                    pieces.append(\"%s\" + unescaped_fragment)\n            else:\n                try:\n                    unescaped_fragment = re_unescape(fragment)\n                except ValueError:\n                    # If we can't unescape part of it, we can't\n                    # reverse this url.\n                    return (None, None)\n                pieces.append(unescaped_fragment)\n\n        return \"\".join(pieces), self.regex.groups",
      "importString": "import re\nfrom functools import partial\n\nfrom tornado import httputil\nfrom tornado.httpserver import _CallableAdapter\nfrom tornado.escape import url_escape, url_unescape, utf8\nfrom tornado.log import app_log\nfrom tornado.util import basestring_type, import_object, re_unescape, unicode_type\nfrom typing import (\nAny\nUnion\nOptional\nAwaitable\nList\nDict\nPattern\nTuple\noverload\nSequence\n)",
      "lineNum": 38,
      "relativeDocumentPath": "tornado/routing.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        pattern: Union[str, Pattern],\n        handler: Any,\n        kwargs: Optional[Dict[str, Any]] = None,\n        name: Optional[str] = None,\n    ) -> None:\n        \"\"\"Parameters:\n\n        * ``pattern``: Regular expression to be matched. Any capturing\n          groups in the regex will be passed in to the handler's\n          get/post/etc methods as arguments (by keyword if named, by\n          position if unnamed. Named and unnamed capturing groups\n          may not be mixed in the same rule).\n\n        * ``handler``: `~.web.RequestHandler` subclass to be invoked.\n\n        * ``kwargs`` (optional): A dictionary of additional arguments\n          to be passed to the handler's constructor.\n\n        * ``name`` (optional): A name for this handler.  Used by\n          `~.web.Application.reverse_url`.\n\n        \"\"\"\n        matcher = PathMatches(pattern)\n        super().__init__(matcher, handler, kwargs, name)\n\n        self.regex = matcher.regex\n        self.handler_class = self.target\n        self.kwargs = kwargs",
      "importString": "import re\nfrom functools import partial\n\nfrom tornado import httputil\nfrom tornado.httpserver import _CallableAdapter\nfrom tornado.escape import url_escape, url_unescape, utf8\nfrom tornado.log import app_log\nfrom tornado.util import basestring_type, import_object, re_unescape, unicode_type\nfrom typing import (\nAny\nUnion\nOptional\nAwaitable\nList\nDict\nPattern\nTuple\noverload\nSequence\n)",
      "lineNum": 29,
      "relativeDocumentPath": "tornado/routing.py"
    },
    {
      "symbolName": "initialize",
      "sourceCode": "def initialize(  # type: ignore\n        self,\n        max_clients: int = 10,\n        hostname_mapping: Optional[Dict[str, str]] = None,\n        max_buffer_size: int = 104857600,\n        resolver: Optional[Resolver] = None,\n        defaults: Optional[Dict[str, Any]] = None,\n        max_header_size: Optional[int] = None,\n        max_body_size: Optional[int] = None,\n    ) -> None:\n        super().initialize(defaults=defaults)\n        self.max_clients = max_clients\n        self.queue = (\n            collections.deque()\n        )  # type: Deque[Tuple[object, HTTPRequest, Callable[[HTTPResponse], None]]]\n        self.active = (\n            {}\n        )  # type: Dict[object, Tuple[HTTPRequest, Callable[[HTTPResponse], None]]]\n        self.waiting = (\n            {}\n        )  # type: Dict[object, Tuple[HTTPRequest, Callable[[HTTPResponse], None], object]]\n        self.max_buffer_size = max_buffer_size\n        self.max_header_size = max_header_size\n        self.max_body_size = max_body_size\n        # TCPClient could create a Resolver for us, but we have to do it\n        # ourselves to support hostname_mapping.\n        if resolver:\n            self.resolver = resolver\n            self.own_resolver = False\n        else:\n            self.resolver = Resolver()\n            self.own_resolver = True\n        if hostname_mapping is not None:\n            self.resolver = OverrideResolver(\n                resolver=self.resolver, mapping=hostname_mapping\n            )\n        self.tcp_client = TCPClient(resolver=self.resolver)",
      "importString": "from tornado.escape import _unicode\nfrom tornado import gen, version\nfrom tornado.httpclient import (\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n_RequestProxy\nHTTPRequest\n)\nfrom tornado import httputil\nfrom tornado.http1connection import HTTP1Connection, HTTP1ConnectionParameters\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.netutil import (\nResolver\nOverrideResolver\n_client_ssl_defaults\nis_valid_ip\n)\nfrom tornado.log import gen_log\nfrom tornado.tcpclient import TCPClient\n\nimport base64\nimport collections\nimport copy\nimport functools\nimport re\nimport socket\nimport ssl\nimport sys\nimport time\nfrom io import BytesIO\nimport urllib.parse\n\nfrom typing import Dict, Any, Callable, Optional, Type, Union\nfrom types import TracebackType\nimport typing",
      "lineNum": 36,
      "relativeDocumentPath": "tornado/simple_httpclient.py"
    },
    {
      "symbolName": "fetch_impl",
      "sourceCode": "def fetch_impl(\n        self, request: HTTPRequest, callback: Callable[[HTTPResponse], None]\n    ) -> None:\n        key = object()\n        self.queue.append((key, request, callback))\n        assert request.connect_timeout is not None\n        assert request.request_timeout is not None\n        timeout_handle = None\n        if len(self.active) >= self.max_clients:\n            timeout = (\n                min(request.connect_timeout, request.request_timeout)\n                or request.connect_timeout\n                or request.request_timeout\n            )  # min but skip zero\n            if timeout:\n                timeout_handle = self.io_loop.add_timeout(\n                    self.io_loop.time() + timeout,\n                    functools.partial(self._on_timeout, key, \"in request queue\"),\n                )\n        self.waiting[key] = (request, callback, timeout_handle)\n        self._process_queue()\n        if self.queue:\n            gen_log.debug(\n                \"max_clients limit reached, request queued. \"\n                \"%d active, %d queued requests.\" % (len(self.active), len(self.queue))\n            )",
      "importString": "from tornado.escape import _unicode\nfrom tornado import gen, version\nfrom tornado.httpclient import (\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n_RequestProxy\nHTTPRequest\n)\nfrom tornado import httputil\nfrom tornado.http1connection import HTTP1Connection, HTTP1ConnectionParameters\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.netutil import (\nResolver\nOverrideResolver\n_client_ssl_defaults\nis_valid_ip\n)\nfrom tornado.log import gen_log\nfrom tornado.tcpclient import TCPClient\n\nimport base64\nimport collections\nimport copy\nimport functools\nimport re\nimport socket\nimport ssl\nimport sys\nimport time\nfrom io import BytesIO\nimport urllib.parse\n\nfrom typing import Dict, Any, Callable, Optional, Type, Union\nfrom types import TracebackType\nimport typing",
      "lineNum": 25,
      "relativeDocumentPath": "tornado/simple_httpclient.py"
    },
    {
      "symbolName": "_handle_request",
      "sourceCode": "def _handle_request(\n        self,\n        request: HTTPRequest,\n        release_callback: Callable[[], None],\n        final_callback: Callable[[HTTPResponse], None],\n    ) -> None:\n        self._connection_class()(\n            self,\n            request,\n            release_callback,\n            final_callback,\n            self.max_buffer_size,\n            self.tcp_client,\n            self.max_header_size,\n            self.max_body_size,\n        )",
      "importString": "from tornado.escape import _unicode\nfrom tornado import gen, version\nfrom tornado.httpclient import (\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n_RequestProxy\nHTTPRequest\n)\nfrom tornado import httputil\nfrom tornado.http1connection import HTTP1Connection, HTTP1ConnectionParameters\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.netutil import (\nResolver\nOverrideResolver\n_client_ssl_defaults\nis_valid_ip\n)\nfrom tornado.log import gen_log\nfrom tornado.tcpclient import TCPClient\n\nimport base64\nimport collections\nimport copy\nimport functools\nimport re\nimport socket\nimport ssl\nimport sys\nimport time\nfrom io import BytesIO\nimport urllib.parse\n\nfrom typing import Dict, Any, Callable, Optional, Type, Union\nfrom types import TracebackType\nimport typing",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/simple_httpclient.py"
    },
    {
      "symbolName": "_on_timeout",
      "sourceCode": "def _on_timeout(self, key: object, info: Optional[str] = None) -> None:\n        \"\"\"Timeout callback of request.\n\n        Construct a timeout HTTPResponse when a timeout occurs.\n\n        :arg object key: A simple object to mark the request.\n        :info string key: More detailed timeout information.\n        \"\"\"\n        request, callback, timeout_handle = self.waiting[key]\n        self.queue.remove((key, request, callback))\n\n        error_message = f\"Timeout {info}\" if info else \"Timeout\"\n        timeout_response = HTTPResponse(\n            request,\n            599,\n            error=HTTPTimeoutError(error_message),\n            request_time=self.io_loop.time() - request.start_time,\n        )\n        self.io_loop.add_callback(callback, timeout_response)\n        del self.waiting[key]",
      "importString": "from tornado.escape import _unicode\nfrom tornado import gen, version\nfrom tornado.httpclient import (\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n_RequestProxy\nHTTPRequest\n)\nfrom tornado import httputil\nfrom tornado.http1connection import HTTP1Connection, HTTP1ConnectionParameters\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.netutil import (\nResolver\nOverrideResolver\n_client_ssl_defaults\nis_valid_ip\n)\nfrom tornado.log import gen_log\nfrom tornado.tcpclient import TCPClient\n\nimport base64\nimport collections\nimport copy\nimport functools\nimport re\nimport socket\nimport ssl\nimport sys\nimport time\nfrom io import BytesIO\nimport urllib.parse\n\nfrom typing import Dict, Any, Callable, Optional, Type, Union\nfrom types import TracebackType\nimport typing",
      "lineNum": 19,
      "relativeDocumentPath": "tornado/simple_httpclient.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        client: Optional[SimpleAsyncHTTPClient],\n        request: HTTPRequest,\n        release_callback: Callable[[], None],\n        final_callback: Callable[[HTTPResponse], None],\n        max_buffer_size: int,\n        tcp_client: TCPClient,\n        max_header_size: int,\n        max_body_size: int,\n    ) -> None:\n        self.io_loop = IOLoop.current()\n        self.start_time = self.io_loop.time()\n        self.start_wall_time = time.time()\n        self.client = client\n        self.request = request\n        self.release_callback = release_callback\n        self.final_callback = final_callback\n        self.max_buffer_size = max_buffer_size\n        self.tcp_client = tcp_client\n        self.max_header_size = max_header_size\n        self.max_body_size = max_body_size\n        self.code = None  # type: Optional[int]\n        self.headers = None  # type: Optional[httputil.HTTPHeaders]\n        self.chunks = []  # type: List[bytes]\n        self._decompressor = None\n        # Timeout handle returned by IOLoop.add_timeout\n        self._timeout = None  # type: object\n        self._sockaddr = None\n        IOLoop.current().add_future(\n            gen.convert_yielded(self.run()), lambda f: f.result()\n        )",
      "importString": "from tornado.escape import _unicode\nfrom tornado import gen, version\nfrom tornado.httpclient import (\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n_RequestProxy\nHTTPRequest\n)\nfrom tornado import httputil\nfrom tornado.http1connection import HTTP1Connection, HTTP1ConnectionParameters\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.netutil import (\nResolver\nOverrideResolver\n_client_ssl_defaults\nis_valid_ip\n)\nfrom tornado.log import gen_log\nfrom tornado.tcpclient import TCPClient\n\nimport base64\nimport collections\nimport copy\nimport functools\nimport re\nimport socket\nimport ssl\nimport sys\nimport time\nfrom io import BytesIO\nimport urllib.parse\n\nfrom typing import Dict, Any, Callable, Optional, Type, Union\nfrom types import TracebackType\nimport typing",
      "lineNum": 31,
      "relativeDocumentPath": "tornado/simple_httpclient.py"
    },
    {
      "symbolName": "run",
      "sourceCode": "async def run(self) -> None:\n        try:\n            self.parsed = urllib.parse.urlsplit(_unicode(self.request.url))\n            if self.parsed.scheme not in (\"http\", \"https\"):\n                raise ValueError(\"Unsupported url scheme: %s\" % self.request.url)\n            # urlsplit results have hostname and port results, but they\n            # didn't support ipv6 literals until python 2.7.\n            netloc = self.parsed.netloc\n            if \"@\" in netloc:\n                userpass, _, netloc = netloc.rpartition(\"@\")\n            host, port = httputil.split_host_and_port(netloc)\n            if port is None:\n                port = 443 if self.parsed.scheme == \"https\" else 80\n            if re.match(r\"^\\[.*\\]$\", host):\n                # raw ipv6 addresses in urls are enclosed in brackets\n                host = host[1:-1]\n            self.parsed_hostname = host  # save final host for _on_connect\n\n            if self.request.allow_ipv6 is False:\n                af = socket.AF_INET\n            else:\n                af = socket.AF_UNSPEC\n\n            ssl_options = self._get_ssl_options(self.parsed.scheme)\n\n            source_ip = None\n            if self.request.network_interface:\n                if is_valid_ip(self.request.network_interface):\n                    source_ip = self.request.network_interface\n                else:\n                    raise ValueError(\n                        \"Unrecognized IPv4 or IPv6 address for network_interface, got %r\"\n                        % (self.request.network_interface,)\n                    )\n\n            if self.request.connect_timeout and self.request.request_timeout:\n                timeout = min(\n                    self.request.connect_timeout, self.request.request_timeout\n                )\n            elif self.request.connect_timeout:\n                timeout = self.request.connect_timeout\n            elif self.request.request_timeout:\n                timeout = self.request.request_timeout\n            else:\n                timeout = 0\n            if timeout:\n                self._timeout = self.io_loop.add_timeout(\n                    self.start_time + timeout,\n                    functools.partial(self._on_timeout, \"while connecting\"),\n                )\n            stream = await self.tcp_client.connect(\n                host,\n                port,\n                af=af,\n                ssl_options=ssl_options,\n                max_buffer_size=self.max_buffer_size,\n                source_ip=source_ip,\n            )\n\n            if self.final_callback is None:\n                # final_callback is cleared if we've hit our timeout.\n                stream.close()\n                return\n            self.stream = stream\n            self.stream.set_close_callback(self.on_connection_close)\n            self._remove_timeout()\n            if self.final_callback is None:\n                return\n            if self.request.request_timeout:\n                self._timeout = self.io_loop.add_timeout(\n                    self.start_time + self.request.request_timeout,\n                    functools.partial(self._on_timeout, \"during request\"),\n                )\n            if (\n                self.request.method not in self._SUPPORTED_METHODS\n                and not self.request.allow_nonstandard_methods\n            ):\n                raise KeyError(\"unknown method %s\" % self.request.method)\n            for key in (\n                \"proxy_host\",\n                \"proxy_port\",\n                \"proxy_username\",\n                \"proxy_password\",\n                \"proxy_auth_mode\",\n            ):\n                if getattr(self.request, key, None):\n                    raise NotImplementedError(\"%s not supported\" % key)\n            if \"Connection\" not in self.request.headers:\n                self.request.headers[\"Connection\"] = \"close\"\n            if \"Host\" not in self.request.headers:\n                if \"@\" in self.parsed.netloc:\n                    self.request.headers[\"Host\"] = self.parsed.netloc.rpartition(\"@\")[\n                        -1\n                    ]\n                else:\n                    self.request.headers[\"Host\"] = self.parsed.netloc\n            username, password = None, None\n            if self.parsed.username is not None:\n                username, password = self.parsed.username, self.parsed.password\n            elif self.request.auth_username is not None:\n                username = self.request.auth_username\n                password = self.request.auth_password or \"\"\n            if username is not None:\n                assert password is not None\n                if self.request.auth_mode not in (None, \"basic\"):\n                    raise ValueError(\"unsupported auth_mode %s\", self.request.auth_mode)\n                self.request.headers[\"Authorization\"] = \"Basic \" + _unicode(\n                    base64.b64encode(\n                        httputil.encode_username_password(username, password)\n                    )\n                )\n            if self.request.user_agent:\n                self.request.headers[\"User-Agent\"] = self.request.user_agent\n            elif self.request.headers.get(\"User-Agent\") is None:\n                self.request.headers[\"User-Agent\"] = f\"Tornado/{version}\"\n            if not self.request.allow_nonstandard_methods:\n                # Some HTTP methods nearly always have bodies while others\n                # almost never do. Fail in this case unless the user has\n                # opted out of sanity checks with allow_nonstandard_methods.\n                body_expected = self.request.method in (\"POST\", \"PATCH\", \"PUT\")\n                body_present = (\n                    self.request.body is not None\n                    or self.request.body_producer is not None\n                )\n                if (body_expected and not body_present) or (\n                    body_present and not body_expected\n                ):\n                    raise ValueError(\n                        \"Body must %sbe None for method %s (unless \"\n                        \"allow_nonstandard_methods is true)\"\n                        % (\"not \" if body_expected else \"\", self.request.method)\n                    )\n            if self.request.expect_100_continue:\n                self.request.headers[\"Expect\"] = \"100-continue\"\n            if self.request.body is not None:\n                # When body_producer is used the caller is responsible for\n                # setting Content-Length (or else chunked encoding will be used).\n                self.request.headers[\"Content-Length\"] = str(len(self.request.body))\n            if (\n                self.request.method == \"POST\"\n                and \"Content-Type\" not in self.request.headers\n            ):\n                self.request.headers[\"Content-Type\"] = (\n                    \"application/x-www-form-urlencoded\"\n                )\n            if self.request.decompress_response:\n                self.request.headers[\"Accept-Encoding\"] = \"gzip\"\n            req_path = (self.parsed.path or \"/\") + (\n                (\"?\" + self.parsed.query) if self.parsed.query else \"\"\n            )\n            self.connection = self._create_connection(stream)\n            start_line = httputil.RequestStartLine(self.request.method, req_path, \"\")\n            self.connection.write_headers(start_line, self.request.headers)\n            if self.request.expect_100_continue:\n                await self.connection.read_response(self)\n            else:\n                await self._write_body(True)\n        except Exception:\n            if not self._handle_exception(*sys.exc_info()):\n                raise",
      "importString": "from tornado.escape import _unicode\nfrom tornado import gen, version\nfrom tornado.httpclient import (\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n_RequestProxy\nHTTPRequest\n)\nfrom tornado import httputil\nfrom tornado.http1connection import HTTP1Connection, HTTP1ConnectionParameters\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.netutil import (\nResolver\nOverrideResolver\n_client_ssl_defaults\nis_valid_ip\n)\nfrom tornado.log import gen_log\nfrom tornado.tcpclient import TCPClient\n\nimport base64\nimport collections\nimport copy\nimport functools\nimport re\nimport socket\nimport ssl\nimport sys\nimport time\nfrom io import BytesIO\nimport urllib.parse\n\nfrom typing import Dict, Any, Callable, Optional, Type, Union\nfrom types import TracebackType\nimport typing",
      "lineNum": 159,
      "relativeDocumentPath": "tornado/simple_httpclient.py"
    },
    {
      "symbolName": "_get_ssl_options",
      "sourceCode": "def _get_ssl_options(\n        self, scheme: str\n    ) -> Union[None, Dict[str, Any], ssl.SSLContext]:\n        if scheme == \"https\":\n            if self.request.ssl_options is not None:\n                return self.request.ssl_options\n            # If we are using the defaults, don't construct a\n            # new SSLContext.\n            if (\n                self.request.validate_cert\n                and self.request.ca_certs is None\n                and self.request.client_cert is None\n                and self.request.client_key is None\n            ):\n                return _client_ssl_defaults\n            ssl_ctx = ssl.create_default_context(\n                ssl.Purpose.SERVER_AUTH, cafile=self.request.ca_certs\n            )\n            if not self.request.validate_cert:\n                ssl_ctx.check_hostname = False\n                ssl_ctx.verify_mode = ssl.CERT_NONE\n            if self.request.client_cert is not None:\n                ssl_ctx.load_cert_chain(\n                    self.request.client_cert, self.request.client_key\n                )\n            if hasattr(ssl, \"OP_NO_COMPRESSION\"):\n                # See netutil.ssl_options_to_context\n                ssl_ctx.options |= ssl.OP_NO_COMPRESSION\n            return ssl_ctx\n        return None",
      "importString": "from tornado.escape import _unicode\nfrom tornado import gen, version\nfrom tornado.httpclient import (\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n_RequestProxy\nHTTPRequest\n)\nfrom tornado import httputil\nfrom tornado.http1connection import HTTP1Connection, HTTP1ConnectionParameters\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.netutil import (\nResolver\nOverrideResolver\n_client_ssl_defaults\nis_valid_ip\n)\nfrom tornado.log import gen_log\nfrom tornado.tcpclient import TCPClient\n\nimport base64\nimport collections\nimport copy\nimport functools\nimport re\nimport socket\nimport ssl\nimport sys\nimport time\nfrom io import BytesIO\nimport urllib.parse\n\nfrom typing import Dict, Any, Callable, Optional, Type, Union\nfrom types import TracebackType\nimport typing",
      "lineNum": 29,
      "relativeDocumentPath": "tornado/simple_httpclient.py"
    },
    {
      "symbolName": "_on_timeout",
      "sourceCode": "def _on_timeout(self, info: Optional[str] = None) -> None:\n        \"\"\"Timeout callback of _HTTPConnection instance.\n\n        Raise a `HTTPTimeoutError` when a timeout occurs.\n\n        :info string key: More detailed timeout information.\n        \"\"\"\n        self._timeout = None\n        error_message = f\"Timeout {info}\" if info else \"Timeout\"\n        if self.final_callback is not None:\n            self._handle_exception(\n                HTTPTimeoutError, HTTPTimeoutError(error_message), None\n            )",
      "importString": "from tornado.escape import _unicode\nfrom tornado import gen, version\nfrom tornado.httpclient import (\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n_RequestProxy\nHTTPRequest\n)\nfrom tornado import httputil\nfrom tornado.http1connection import HTTP1Connection, HTTP1ConnectionParameters\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.netutil import (\nResolver\nOverrideResolver\n_client_ssl_defaults\nis_valid_ip\n)\nfrom tornado.log import gen_log\nfrom tornado.tcpclient import TCPClient\n\nimport base64\nimport collections\nimport copy\nimport functools\nimport re\nimport socket\nimport ssl\nimport sys\nimport time\nfrom io import BytesIO\nimport urllib.parse\n\nfrom typing import Dict, Any, Callable, Optional, Type, Union\nfrom types import TracebackType\nimport typing",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/simple_httpclient.py"
    },
    {
      "symbolName": "_create_connection",
      "sourceCode": "def _create_connection(self, stream: IOStream) -> HTTP1Connection:\n        stream.set_nodelay(True)\n        connection = HTTP1Connection(\n            stream,\n            True,\n            HTTP1ConnectionParameters(\n                no_keep_alive=True,\n                max_header_size=self.max_header_size,\n                max_body_size=self.max_body_size,\n                decompress=bool(self.request.decompress_response),\n            ),\n            self._sockaddr,\n        )\n        return connection",
      "importString": "from tornado.escape import _unicode\nfrom tornado import gen, version\nfrom tornado.httpclient import (\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n_RequestProxy\nHTTPRequest\n)\nfrom tornado import httputil\nfrom tornado.http1connection import HTTP1Connection, HTTP1ConnectionParameters\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.netutil import (\nResolver\nOverrideResolver\n_client_ssl_defaults\nis_valid_ip\n)\nfrom tornado.log import gen_log\nfrom tornado.tcpclient import TCPClient\n\nimport base64\nimport collections\nimport copy\nimport functools\nimport re\nimport socket\nimport ssl\nimport sys\nimport time\nfrom io import BytesIO\nimport urllib.parse\n\nfrom typing import Dict, Any, Callable, Optional, Type, Union\nfrom types import TracebackType\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/simple_httpclient.py"
    },
    {
      "symbolName": "_write_body",
      "sourceCode": "async def _write_body(self, start_read: bool) -> None:\n        if self.request.body is not None:\n            self.connection.write(self.request.body)\n        elif self.request.body_producer is not None:\n            fut = self.request.body_producer(self.connection.write)\n            if fut is not None:\n                await fut\n        self.connection.finish()\n        if start_read:\n            try:\n                await self.connection.read_response(self)\n            except StreamClosedError:\n                if not self._handle_exception(*sys.exc_info()):\n                    raise",
      "importString": "from tornado.escape import _unicode\nfrom tornado import gen, version\nfrom tornado.httpclient import (\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n_RequestProxy\nHTTPRequest\n)\nfrom tornado import httputil\nfrom tornado.http1connection import HTTP1Connection, HTTP1ConnectionParameters\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.netutil import (\nResolver\nOverrideResolver\n_client_ssl_defaults\nis_valid_ip\n)\nfrom tornado.log import gen_log\nfrom tornado.tcpclient import TCPClient\n\nimport base64\nimport collections\nimport copy\nimport functools\nimport re\nimport socket\nimport ssl\nimport sys\nimport time\nfrom io import BytesIO\nimport urllib.parse\n\nfrom typing import Dict, Any, Callable, Optional, Type, Union\nfrom types import TracebackType\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/simple_httpclient.py"
    },
    {
      "symbolName": "_handle_exception",
      "sourceCode": "def _handle_exception(\n        self,\n        typ: \"Optional[Type[BaseException]]\",\n        value: Optional[BaseException],\n        tb: Optional[TracebackType],\n    ) -> bool:\n        if self.final_callback is not None:\n            self._remove_timeout()\n            if isinstance(value, StreamClosedError):\n                if value.real_error is None:\n                    value = HTTPStreamClosedError(\"Stream closed\")\n                else:\n                    value = value.real_error\n            self._run_callback(\n                HTTPResponse(\n                    self.request,\n                    599,\n                    error=value,\n                    request_time=self.io_loop.time() - self.start_time,\n                    start_time=self.start_wall_time,\n                )\n            )\n\n            if hasattr(self, \"stream\"):\n                # TODO: this may cause a StreamClosedError to be raised\n                # by the connection's Future.  Should we cancel the\n                # connection more gracefully?\n                self.stream.close()\n            return True\n        else:\n            # If our callback has already been called, we are probably\n            # catching an exception that is not caused by us but rather\n            # some child of our callback. Rather than drop it on the floor,\n            # pass it along, unless it's just the stream being closed.\n            return isinstance(value, StreamClosedError)",
      "importString": "from tornado.escape import _unicode\nfrom tornado import gen, version\nfrom tornado.httpclient import (\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n_RequestProxy\nHTTPRequest\n)\nfrom tornado import httputil\nfrom tornado.http1connection import HTTP1Connection, HTTP1ConnectionParameters\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.netutil import (\nResolver\nOverrideResolver\n_client_ssl_defaults\nis_valid_ip\n)\nfrom tornado.log import gen_log\nfrom tornado.tcpclient import TCPClient\n\nimport base64\nimport collections\nimport copy\nimport functools\nimport re\nimport socket\nimport ssl\nimport sys\nimport time\nfrom io import BytesIO\nimport urllib.parse\n\nfrom typing import Dict, Any, Callable, Optional, Type, Union\nfrom types import TracebackType\nimport typing",
      "lineNum": 34,
      "relativeDocumentPath": "tornado/simple_httpclient.py"
    },
    {
      "symbolName": "headers_received",
      "sourceCode": "async def headers_received(\n        self,\n        first_line: Union[httputil.ResponseStartLine, httputil.RequestStartLine],\n        headers: httputil.HTTPHeaders,\n    ) -> None:\n        assert isinstance(first_line, httputil.ResponseStartLine)\n        if self.request.expect_100_continue and first_line.code == 100:\n            await self._write_body(False)\n            return\n        self.code = first_line.code\n        self.reason = first_line.reason\n        self.headers = headers\n\n        if self._should_follow_redirect():\n            return\n\n        if self.request.header_callback is not None:\n            # Reassemble the start line.\n            self.request.header_callback(\"%s %s %s\\r\\n\" % first_line)\n            for k, v in self.headers.get_all():\n                self.request.header_callback(f\"{k}: {v}\\r\\n\")\n            self.request.header_callback(\"\\r\\n\")",
      "importString": "from tornado.escape import _unicode\nfrom tornado import gen, version\nfrom tornado.httpclient import (\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n_RequestProxy\nHTTPRequest\n)\nfrom tornado import httputil\nfrom tornado.http1connection import HTTP1Connection, HTTP1ConnectionParameters\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.netutil import (\nResolver\nOverrideResolver\n_client_ssl_defaults\nis_valid_ip\n)\nfrom tornado.log import gen_log\nfrom tornado.tcpclient import TCPClient\n\nimport base64\nimport collections\nimport copy\nimport functools\nimport re\nimport socket\nimport ssl\nimport sys\nimport time\nfrom io import BytesIO\nimport urllib.parse\n\nfrom typing import Dict, Any, Callable, Optional, Type, Union\nfrom types import TracebackType\nimport typing",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/simple_httpclient.py"
    },
    {
      "symbolName": "finish",
      "sourceCode": "def finish(self) -> None:\n        assert self.code is not None\n        data = b\"\".join(self.chunks)\n        self._remove_timeout()\n        original_request = getattr(self.request, \"original_request\", self.request)\n        if self._should_follow_redirect():\n            assert isinstance(self.request, _RequestProxy)\n            assert self.headers is not None\n            new_request = copy.copy(self.request.request)\n            new_request.url = urllib.parse.urljoin(\n                self.request.url, self.headers[\"Location\"]\n            )\n            assert self.request.max_redirects is not None\n            new_request.max_redirects = self.request.max_redirects - 1\n            del new_request.headers[\"Host\"]\n            # https://tools.ietf.org/html/rfc7231#section-6.4\n            #\n            # The original HTTP spec said that after a 301 or 302\n            # redirect, the request method should be preserved.\n            # However, browsers implemented this by changing the\n            # method to GET, and the behavior stuck. 303 redirects\n            # always specified this POST-to-GET behavior, arguably\n            # for *all* methods, but libcurl < 7.70 only does this\n            # for POST, while libcurl >= 7.70 does it for other methods.\n            if (self.code == 303 and self.request.method != \"HEAD\") or (\n                self.code in (301, 302) and self.request.method == \"POST\"\n            ):\n                new_request.method = \"GET\"\n                new_request.body = None  # type: ignore\n                for h in [\n                    \"Content-Length\",\n                    \"Content-Type\",\n                    \"Content-Encoding\",\n                    \"Transfer-Encoding\",\n                ]:\n                    try:\n                        del self.request.headers[h]\n                    except KeyError:\n                        pass\n            new_request.original_request = original_request  # type: ignore\n            final_callback = self.final_callback\n            self.final_callback = None  # type: ignore\n            self._release()\n            assert self.client is not None\n            fut = self.client.fetch(new_request, raise_error=False)\n            fut.add_done_callback(lambda f: final_callback(f.result()))\n            self._on_end_request()\n            return\n        if self.request.streaming_callback:\n            buffer = BytesIO()\n        else:\n            buffer = BytesIO(data)  # TODO: don't require one big string?\n        response = HTTPResponse(\n            original_request,\n            self.code,\n            reason=getattr(self, \"reason\", None),\n            headers=self.headers,\n            request_time=self.io_loop.time() - self.start_time,\n            start_time=self.start_wall_time,\n            buffer=buffer,\n            effective_url=self.request.url,\n        )\n        self._run_callback(response)\n        self._on_end_request()",
      "importString": "from tornado.escape import _unicode\nfrom tornado import gen, version\nfrom tornado.httpclient import (\nHTTPResponse\nHTTPError\nAsyncHTTPClient\nmain\n_RequestProxy\nHTTPRequest\n)\nfrom tornado import httputil\nfrom tornado.http1connection import HTTP1Connection, HTTP1ConnectionParameters\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.netutil import (\nResolver\nOverrideResolver\n_client_ssl_defaults\nis_valid_ip\n)\nfrom tornado.log import gen_log\nfrom tornado.tcpclient import TCPClient\n\nimport base64\nimport collections\nimport copy\nimport functools\nimport re\nimport socket\nimport ssl\nimport sys\nimport time\nfrom io import BytesIO\nimport urllib.parse\n\nfrom typing import Dict, Any, Callable, Optional, Type, Union\nfrom types import TracebackType\nimport typing",
      "lineNum": 63,
      "relativeDocumentPath": "tornado/simple_httpclient.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        addrinfo: List[Tuple],\n        connect: Callable[\n            [socket.AddressFamily, Tuple], Tuple[IOStream, \"Future[IOStream]\"]\n        ],\n    ) -> None:\n        self.io_loop = IOLoop.current()\n        self.connect = connect\n\n        self.future = (\n            Future()\n        )  # type: Future[Tuple[socket.AddressFamily, Any, IOStream]]\n        self.timeout = None  # type: Optional[object]\n        self.connect_timeout = None  # type: Optional[object]\n        self.last_error = None  # type: Optional[Exception]\n        self.remaining = len(addrinfo)\n        self.primary_addrs, self.secondary_addrs = self.split(addrinfo)\n        self.streams = set()  # type: Set[IOStream]",
      "importString": "import functools\nimport socket\nimport numbers\nimport datetime\nimport ssl\nimport typing\nfrom tornado.concurrent import Future, future_add_done_callback\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import IOStream\nfrom tornado import gen\nfrom tornado.netutil import Resolver\nfrom tornado.gen import TimeoutError\n\nfrom typing import Any, Union, Dict, Tuple, List, Callable, Iterator, Optional",
      "lineNum": 18,
      "relativeDocumentPath": "tornado/tcpclient.py"
    },
    {
      "symbolName": "split",
      "sourceCode": "@staticmethod\n    def split(\n        addrinfo: List[Tuple],\n    ) -> Tuple[\n        List[Tuple[socket.AddressFamily, Tuple]],\n        List[Tuple[socket.AddressFamily, Tuple]],\n    ]:\n        \"\"\"Partition the ``addrinfo`` list by address family.\n\n        Returns two lists.  The first list contains the first entry from\n        ``addrinfo`` and all others with the same family, and the\n        second list contains all other addresses (normally one list will\n        be AF_INET and the other AF_INET6, although non-standard resolvers\n        may return additional families).\n        \"\"\"\n        primary = []\n        secondary = []\n        primary_af = addrinfo[0][0]\n        for af, addr in addrinfo:\n            if af == primary_af:\n                primary.append((af, addr))\n            else:\n                secondary.append((af, addr))\n        return primary, secondary",
      "importString": "import functools\nimport socket\nimport numbers\nimport datetime\nimport ssl\nimport typing\nfrom tornado.concurrent import Future, future_add_done_callback\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import IOStream\nfrom tornado import gen\nfrom tornado.netutil import Resolver\nfrom tornado.gen import TimeoutError\n\nfrom typing import Any, Union, Dict, Tuple, List, Callable, Iterator, Optional",
      "lineNum": 23,
      "relativeDocumentPath": "tornado/tcpclient.py"
    },
    {
      "symbolName": "try_connect",
      "sourceCode": "def try_connect(self, addrs: Iterator[Tuple[socket.AddressFamily, Tuple]]) -> None:\n        try:\n            af, addr = next(addrs)\n        except StopIteration:\n            # We've reached the end of our queue, but the other queue\n            # might still be working.  Send a final error on the future\n            # only when both queues are finished.\n            if self.remaining == 0 and not self.future.done():\n                self.future.set_exception(\n                    self.last_error or IOError(\"connection failed\")\n                )\n            return\n        stream, future = self.connect(af, addr)\n        self.streams.add(stream)\n        future_add_done_callback(\n            future, functools.partial(self.on_connect_done, addrs, af, addr)\n        )",
      "importString": "import functools\nimport socket\nimport numbers\nimport datetime\nimport ssl\nimport typing\nfrom tornado.concurrent import Future, future_add_done_callback\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import IOStream\nfrom tornado import gen\nfrom tornado.netutil import Resolver\nfrom tornado.gen import TimeoutError\n\nfrom typing import Any, Union, Dict, Tuple, List, Callable, Iterator, Optional",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/tcpclient.py"
    },
    {
      "symbolName": "on_connect_done",
      "sourceCode": "def on_connect_done(\n        self,\n        addrs: Iterator[Tuple[socket.AddressFamily, Tuple]],\n        af: socket.AddressFamily,\n        addr: Tuple,\n        future: \"Future[IOStream]\",\n    ) -> None:\n        self.remaining -= 1\n        try:\n            stream = future.result()\n        except Exception as e:\n            if self.future.done():\n                return\n            # Error: try again (but remember what happened so we have an\n            # error to raise in the end)\n            self.last_error = e\n            self.try_connect(addrs)\n            if self.timeout is not None:\n                # If the first attempt failed, don't wait for the\n                # timeout to try an address from the secondary queue.\n                self.io_loop.remove_timeout(self.timeout)\n                self.on_timeout()\n            return\n        self.clear_timeouts()\n        if self.future.done():\n            # This is a late arrival; just drop it.\n            stream.close()\n        else:\n            self.streams.discard(stream)\n            self.future.set_result((af, addr, stream))\n            self.close_streams()",
      "importString": "import functools\nimport socket\nimport numbers\nimport datetime\nimport ssl\nimport typing\nfrom tornado.concurrent import Future, future_add_done_callback\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import IOStream\nfrom tornado import gen\nfrom tornado.netutil import Resolver\nfrom tornado.gen import TimeoutError\n\nfrom typing import Any, Union, Dict, Tuple, List, Callable, Iterator, Optional",
      "lineNum": 30,
      "relativeDocumentPath": "tornado/tcpclient.py"
    },
    {
      "symbolName": "connect",
      "sourceCode": "async def connect(\n        self,\n        host: str,\n        port: int,\n        af: socket.AddressFamily = socket.AF_UNSPEC,\n        ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n        max_buffer_size: Optional[int] = None,\n        source_ip: Optional[str] = None,\n        source_port: Optional[int] = None,\n        timeout: Optional[Union[float, datetime.timedelta]] = None,\n    ) -> IOStream:\n        \"\"\"Connect to the given host and port.\n\n        Asynchronously returns an `.IOStream` (or `.SSLIOStream` if\n        ``ssl_options`` is not None).\n\n        Using the ``source_ip`` kwarg, one can specify the source\n        IP address to use when establishing the connection.\n        In case the user needs to resolve and\n        use a specific interface, it has to be handled outside\n        of Tornado as this depends very much on the platform.\n\n        Raises `TimeoutError` if the input future does not complete before\n        ``timeout``, which may be specified in any form allowed by\n        `.IOLoop.add_timeout` (i.e. a `datetime.timedelta` or an absolute time\n        relative to `.IOLoop.time`)\n\n        Similarly, when the user requires a certain source port, it can\n        be specified using the ``source_port`` arg.\n\n        .. versionchanged:: 4.5\n           Added the ``source_ip`` and ``source_port`` arguments.\n\n        .. versionchanged:: 5.0\n           Added the ``timeout`` argument.\n        \"\"\"\n        if timeout is not None:\n            if isinstance(timeout, numbers.Real):\n                timeout = IOLoop.current().time() + timeout\n            elif isinstance(timeout, datetime.timedelta):\n                timeout = IOLoop.current().time() + timeout.total_seconds()\n            else:\n                raise TypeError(\"Unsupported timeout %r\" % timeout)\n        if timeout is not None:\n            addrinfo = await gen.with_timeout(\n                timeout, self.resolver.resolve(host, port, af)\n            )\n        else:\n            addrinfo = await self.resolver.resolve(host, port, af)\n        connector = _Connector(\n            addrinfo,\n            functools.partial(\n                self._create_stream,\n                max_buffer_size,\n                source_ip=source_ip,\n                source_port=source_port,\n            ),\n        )\n        af, addr, stream = await connector.start(connect_timeout=timeout)\n        # TODO: For better performance we could cache the (af, addr)\n        # information here and re-use it on subsequent connections to\n        # the same host. (http://tools.ietf.org/html/rfc6555#section-4.2)\n        if ssl_options is not None:\n            if timeout is not None:\n                stream = await gen.with_timeout(\n                    timeout,\n                    stream.start_tls(\n                        False, ssl_options=ssl_options, server_hostname=host\n                    ),\n                )\n            else:\n                stream = await stream.start_tls(\n                    False, ssl_options=ssl_options, server_hostname=host\n                )\n        return stream",
      "importString": "import functools\nimport socket\nimport numbers\nimport datetime\nimport ssl\nimport typing\nfrom tornado.concurrent import Future, future_add_done_callback\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import IOStream\nfrom tornado import gen\nfrom tornado.netutil import Resolver\nfrom tornado.gen import TimeoutError\n\nfrom typing import Any, Union, Dict, Tuple, List, Callable, Iterator, Optional",
      "lineNum": 74,
      "relativeDocumentPath": "tornado/tcpclient.py"
    },
    {
      "symbolName": "_create_stream",
      "sourceCode": "def _create_stream(\n        self,\n        max_buffer_size: Optional[int],\n        af: socket.AddressFamily,\n        addr: Tuple,\n        source_ip: Optional[str] = None,\n        source_port: Optional[int] = None,\n    ) -> Tuple[IOStream, \"Future[IOStream]\"]:\n        # Always connect in plaintext; we'll convert to ssl if necessary\n        # after one connection has completed.\n        source_port_bind = source_port if isinstance(source_port, int) else 0\n        source_ip_bind = source_ip\n        if source_port_bind and not source_ip:\n            # User required a specific port, but did not specify\n            # a certain source IP, will bind to the default loopback.\n            source_ip_bind = \"::1\" if af == socket.AF_INET6 else \"127.0.0.1\"\n            # Trying to use the same address family as the requested af socket:\n            # - 127.0.0.1 for IPv4\n            # - ::1 for IPv6\n        socket_obj = socket.socket(af)\n        if source_port_bind or source_ip_bind:\n            # If the user requires binding also to a specific IP/port.\n            try:\n                socket_obj.bind((source_ip_bind, source_port_bind))\n            except OSError:\n                socket_obj.close()\n                # Fail loudly if unable to use the IP/port.\n                raise\n        try:\n            stream = IOStream(socket_obj, max_buffer_size=max_buffer_size)\n        except OSError as e:\n            fu = Future()  # type: Future[IOStream]\n            fu.set_exception(e)\n            return stream, fu\n        else:\n            return stream, stream.connect(addr)",
      "importString": "import functools\nimport socket\nimport numbers\nimport datetime\nimport ssl\nimport typing\nfrom tornado.concurrent import Future, future_add_done_callback\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import IOStream\nfrom tornado import gen\nfrom tornado.netutil import Resolver\nfrom tornado.gen import TimeoutError\n\nfrom typing import Any, Union, Dict, Tuple, List, Callable, Iterator, Optional",
      "lineNum": 35,
      "relativeDocumentPath": "tornado/tcpclient.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n        max_buffer_size: Optional[int] = None,\n        read_chunk_size: Optional[int] = None,\n    ) -> None:\n        self.ssl_options = ssl_options\n        self._sockets = {}  # type: Dict[int, socket.socket]\n        self._handlers = {}  # type: Dict[int, Callable[[], None]]\n        self._pending_sockets = []  # type: List[socket.socket]\n        self._started = False\n        self._stopped = False\n        self.max_buffer_size = max_buffer_size\n        self.read_chunk_size = read_chunk_size\n\n        # Verify the SSL options. Otherwise we don't get errors until clients\n        # connect. This doesn't verify that the keys are legitimate, but\n        # the SSL module doesn't do that until there is a connected socket\n        # which seems like too much work\n        if self.ssl_options is not None and isinstance(self.ssl_options, dict):\n            # Only certfile is required: it can contain both keys\n            if \"certfile\" not in self.ssl_options:\n                raise KeyError('missing key \"certfile\" in ssl_options')\n\n            if not os.path.exists(self.ssl_options[\"certfile\"]):\n                raise ValueError(\n                    'certfile \"%s\" does not exist' % self.ssl_options[\"certfile\"]\n                )\n            if \"keyfile\" in self.ssl_options and not os.path.exists(\n                self.ssl_options[\"keyfile\"]\n            ):\n                raise ValueError(\n                    'keyfile \"%s\" does not exist' % self.ssl_options[\"keyfile\"]\n                )",
      "importString": "import errno\nimport os\nimport socket\nimport ssl\nfrom tornado import gen\nfrom tornado.log import app_log\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import IOStream, SSLIOStream\nfrom tornado.netutil import (\nbind_sockets\nadd_accept_handler\nssl_wrap_socket\n_DEFAULT_BACKLOG\n)\nfrom tornado import process\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import Union, Dict, Any, Iterable, Optional, Awaitable",
      "lineNum": 33,
      "relativeDocumentPath": "tornado/tcpserver.py"
    },
    {
      "symbolName": "listen",
      "sourceCode": "def listen(\n        self,\n        port: int,\n        address: Optional[str] = None,\n        family: socket.AddressFamily = socket.AF_UNSPEC,\n        backlog: int = _DEFAULT_BACKLOG,\n        flags: Optional[int] = None,\n        reuse_port: bool = False,\n    ) -> None:\n        \"\"\"Starts accepting connections on the given port.\n\n        This method may be called more than once to listen on multiple ports.\n        `listen` takes effect immediately; it is not necessary to call\n        `TCPServer.start` afterwards.  It is, however, necessary to start the\n        event loop if it is not already running.\n\n        All arguments have the same meaning as in\n        `tornado.netutil.bind_sockets`.\n\n        .. versionchanged:: 6.2\n\n           Added ``family``, ``backlog``, ``flags``, and ``reuse_port``\n           arguments to match `tornado.netutil.bind_sockets`.\n        \"\"\"\n        sockets = bind_sockets(\n            port,\n            address=address,\n            family=family,\n            backlog=backlog,\n            flags=flags,\n            reuse_port=reuse_port,\n        )\n        self.add_sockets(sockets)",
      "importString": "import errno\nimport os\nimport socket\nimport ssl\nfrom tornado import gen\nfrom tornado.log import app_log\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import IOStream, SSLIOStream\nfrom tornado.netutil import (\nbind_sockets\nadd_accept_handler\nssl_wrap_socket\n_DEFAULT_BACKLOG\n)\nfrom tornado import process\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import Union, Dict, Any, Iterable, Optional, Awaitable",
      "lineNum": 32,
      "relativeDocumentPath": "tornado/tcpserver.py"
    },
    {
      "symbolName": "add_sockets",
      "sourceCode": "def add_sockets(self, sockets: Iterable[socket.socket]) -> None:\n        \"\"\"Makes this server start accepting connections on the given sockets.\n\n        The ``sockets`` parameter is a list of socket objects such as\n        those returned by `~tornado.netutil.bind_sockets`.\n        `add_sockets` is typically used in combination with that\n        method and `tornado.process.fork_processes` to provide greater\n        control over the initialization of a multi-process server.\n        \"\"\"\n        for sock in sockets:\n            self._sockets[sock.fileno()] = sock\n            self._handlers[sock.fileno()] = add_accept_handler(\n                sock, self._handle_connection\n            )",
      "importString": "import errno\nimport os\nimport socket\nimport ssl\nfrom tornado import gen\nfrom tornado.log import app_log\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import IOStream, SSLIOStream\nfrom tornado.netutil import (\nbind_sockets\nadd_accept_handler\nssl_wrap_socket\n_DEFAULT_BACKLOG\n)\nfrom tornado import process\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import Union, Dict, Any, Iterable, Optional, Awaitable",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/tcpserver.py"
    },
    {
      "symbolName": "bind",
      "sourceCode": "def bind(\n        self,\n        port: int,\n        address: Optional[str] = None,\n        family: socket.AddressFamily = socket.AF_UNSPEC,\n        backlog: int = _DEFAULT_BACKLOG,\n        flags: Optional[int] = None,\n        reuse_port: bool = False,\n    ) -> None:\n        \"\"\"Binds this server to the given port on the given address.\n\n        To start the server, call `start`. If you want to run this server in a\n        single process, you can call `listen` as a shortcut to the sequence of\n        `bind` and `start` calls.\n\n        Address may be either an IP address or hostname.  If it's a hostname,\n        the server will listen on all IP addresses associated with the name.\n        Address may be an empty string or None to listen on all available\n        interfaces.  Family may be set to either `socket.AF_INET` or\n        `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise both\n        will be used if available.\n\n        The ``backlog`` argument has the same meaning as for `socket.listen\n        <socket.socket.listen>`. The ``reuse_port`` argument has the same\n        meaning as for `.bind_sockets`.\n\n        This method may be called multiple times prior to `start` to listen on\n        multiple ports or interfaces.\n\n        .. versionchanged:: 4.4\n           Added the ``reuse_port`` argument.\n\n        .. versionchanged:: 6.2\n           Added the ``flags`` argument to match `.bind_sockets`.\n\n        .. deprecated:: 6.2\n           Use either ``listen()`` or ``add_sockets()`` instead of ``bind()``\n           and ``start()``.\n        \"\"\"\n        sockets = bind_sockets(\n            port,\n            address=address,\n            family=family,\n            backlog=backlog,\n            flags=flags,\n            reuse_port=reuse_port,\n        )\n        if self._started:\n            self.add_sockets(sockets)\n        else:\n            self._pending_sockets.extend(sockets)",
      "importString": "import errno\nimport os\nimport socket\nimport ssl\nfrom tornado import gen\nfrom tornado.log import app_log\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import IOStream, SSLIOStream\nfrom tornado.netutil import (\nbind_sockets\nadd_accept_handler\nssl_wrap_socket\n_DEFAULT_BACKLOG\n)\nfrom tornado import process\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import Union, Dict, Any, Iterable, Optional, Awaitable",
      "lineNum": 50,
      "relativeDocumentPath": "tornado/tcpserver.py"
    },
    {
      "symbolName": "start",
      "sourceCode": "def start(\n        self, num_processes: Optional[int] = 1, max_restarts: Optional[int] = None\n    ) -> None:\n        \"\"\"Starts this server in the `.IOLoop`.\n\n        By default, we run the server in this process and do not fork any\n        additional child process.\n\n        If num_processes is ``None`` or <= 0, we detect the number of cores\n        available on this machine and fork that number of child\n        processes. If num_processes is given and > 1, we fork that\n        specific number of sub-processes.\n\n        Since we use processes and not threads, there is no shared memory\n        between any server code.\n\n        Note that multiple processes are not compatible with the autoreload\n        module (or the ``autoreload=True`` option to `tornado.web.Application`\n        which defaults to True when ``debug=True``).\n        When using multiple processes, no IOLoops can be created or\n        referenced until after the call to ``TCPServer.start(n)``.\n\n        Values of ``num_processes`` other than 1 are not supported on Windows.\n\n        The ``max_restarts`` argument is passed to `.fork_processes`.\n\n        .. versionchanged:: 6.0\n\n           Added ``max_restarts`` argument.\n\n        .. deprecated:: 6.2\n           Use either ``listen()`` or ``add_sockets()`` instead of ``bind()``\n           and ``start()``.\n        \"\"\"\n        assert not self._started\n        self._started = True\n        if num_processes != 1:\n            process.fork_processes(num_processes, max_restarts)\n        sockets = self._pending_sockets\n        self._pending_sockets = []\n        self.add_sockets(sockets)",
      "importString": "import errno\nimport os\nimport socket\nimport ssl\nfrom tornado import gen\nfrom tornado.log import app_log\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import IOStream, SSLIOStream\nfrom tornado.netutil import (\nbind_sockets\nadd_accept_handler\nssl_wrap_socket\n_DEFAULT_BACKLOG\n)\nfrom tornado import process\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import Union, Dict, Any, Iterable, Optional, Awaitable",
      "lineNum": 40,
      "relativeDocumentPath": "tornado/tcpserver.py"
    },
    {
      "symbolName": "stop",
      "sourceCode": "def stop(self) -> None:\n        \"\"\"Stops listening for new connections.\n\n        Requests currently in progress may still continue after the\n        server is stopped.\n        \"\"\"\n        if self._stopped:\n            return\n        self._stopped = True\n        for fd, sock in self._sockets.items():\n            assert sock.fileno() == fd\n            # Unregister socket from IOLoop\n            self._handlers.pop(fd)()\n            sock.close()",
      "importString": "import errno\nimport os\nimport socket\nimport ssl\nfrom tornado import gen\nfrom tornado.log import app_log\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import IOStream, SSLIOStream\nfrom tornado.netutil import (\nbind_sockets\nadd_accept_handler\nssl_wrap_socket\n_DEFAULT_BACKLOG\n)\nfrom tornado import process\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import Union, Dict, Any, Iterable, Optional, Awaitable",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/tcpserver.py"
    },
    {
      "symbolName": "handle_stream",
      "sourceCode": "def handle_stream(\n        self, stream: IOStream, address: tuple\n    ) -> Optional[Awaitable[None]]:\n        \"\"\"Override to handle a new `.IOStream` from an incoming connection.\n\n        This method may be a coroutine; if so any exceptions it raises\n        asynchronously will be logged. Accepting of incoming connections\n        will not be blocked by this coroutine.\n\n        If this `TCPServer` is configured for SSL, ``handle_stream``\n        may be called before the SSL handshake has completed. Use\n        `.SSLIOStream.wait_for_handshake` if you need to verify the client's\n        certificate or use NPN/ALPN.\n\n        .. versionchanged:: 4.2\n           Added the option for this method to be a coroutine.\n        \"\"\"\n        raise NotImplementedError()",
      "importString": "import errno\nimport os\nimport socket\nimport ssl\nfrom tornado import gen\nfrom tornado.log import app_log\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import IOStream, SSLIOStream\nfrom tornado.netutil import (\nbind_sockets\nadd_accept_handler\nssl_wrap_socket\n_DEFAULT_BACKLOG\n)\nfrom tornado import process\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import Union, Dict, Any, Iterable, Optional, Awaitable",
      "lineNum": 17,
      "relativeDocumentPath": "tornado/tcpserver.py"
    },
    {
      "symbolName": "_handle_connection",
      "sourceCode": "def _handle_connection(self, connection: socket.socket, address: Any) -> None:\n        if self.ssl_options is not None:\n            assert ssl, \"OpenSSL required for SSL\"\n            try:\n                connection = ssl_wrap_socket(\n                    connection,\n                    self.ssl_options,\n                    server_side=True,\n                    do_handshake_on_connect=False,\n                )\n            except ssl.SSLError as err:\n                if err.args[0] == ssl.SSL_ERROR_EOF:\n                    return connection.close()\n                else:\n                    raise\n            except OSError as err:\n                # If the connection is closed immediately after it is created\n                # (as in a port scan), we can get one of several errors.\n                # wrap_socket makes an internal call to getpeername,\n                # which may return either EINVAL (Mac OS X) or ENOTCONN\n                # (Linux).  If it returns ENOTCONN, this error is\n                # silently swallowed by the ssl module, so we need to\n                # catch another error later on (AttributeError in\n                # SSLIOStream._do_ssl_handshake).\n                # To test this behavior, try nmap with the -sT flag.\n                # https://github.com/tornadoweb/tornado/pull/750\n                if errno_from_exception(err) in (errno.ECONNABORTED, errno.EINVAL):\n                    return connection.close()\n                else:\n                    raise\n        try:\n            if self.ssl_options is not None:\n                stream = SSLIOStream(\n                    connection,\n                    max_buffer_size=self.max_buffer_size,\n                    read_chunk_size=self.read_chunk_size,\n                )  # type: IOStream\n            else:\n                stream = IOStream(\n                    connection,\n                    max_buffer_size=self.max_buffer_size,\n                    read_chunk_size=self.read_chunk_size,\n                )\n\n            future = self.handle_stream(stream, address)\n            if future is not None:\n                IOLoop.current().add_future(\n                    gen.convert_yielded(future), lambda f: f.result()\n                )\n        except Exception:\n            app_log.error(\"Error in connection callback\", exc_info=True)",
      "importString": "import errno\nimport os\nimport socket\nimport ssl\nfrom tornado import gen\nfrom tornado.log import app_log\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import IOStream, SSLIOStream\nfrom tornado.netutil import (\nbind_sockets\nadd_accept_handler\nssl_wrap_socket\n_DEFAULT_BACKLOG\n)\nfrom tornado import process\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import Union, Dict, Any, Iterable, Optional, Awaitable",
      "lineNum": 50,
      "relativeDocumentPath": "tornado/tcpserver.py"
    },
    {
      "symbolName": "filter_whitespace",
      "sourceCode": "def filter_whitespace(mode: str, text: str) -> str:\n    \"\"\"Transform whitespace in ``text`` according to ``mode``.\n\n    Available modes are:\n\n    * ``all``: Return all whitespace unmodified.\n    * ``single``: Collapse consecutive whitespace with a single whitespace\n      character, preserving newlines.\n    * ``oneline``: Collapse all runs of whitespace into a single space\n      character, removing all newlines in the process.\n\n    .. versionadded:: 4.3\n    \"\"\"\n    if mode == \"all\":\n        return text\n    elif mode == \"single\":\n        text = re.sub(r\"([\\t ]+)\", \" \", text)\n        text = re.sub(r\"(\\s*\\n\\s*)\", \"\\n\", text)\n        return text\n    elif mode == \"oneline\":\n        return re.sub(r\"(\\s+)\", \" \", text)\n    else:\n        raise Exception(\"invalid whitespace mode %s\" % mode)",
      "importString": "import datetime\nfrom io import StringIO\nimport linecache\nimport os.path\nimport posixpath\nimport re\nimport threading\n\nfrom tornado import escape\nfrom tornado.log import app_log\nfrom tornado.util import ObjectDict, exec_in, unicode_type\n\nfrom typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing",
      "lineNum": 22,
      "relativeDocumentPath": "tornado/template.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        template_string: Union[str, bytes],\n        name: str = \"<string>\",\n        loader: Optional[\"BaseLoader\"] = None,\n        compress_whitespace: Union[bool, _UnsetMarker] = _UNSET,\n        autoescape: Optional[Union[str, _UnsetMarker]] = _UNSET,\n        whitespace: Optional[str] = None,\n    ) -> None:\n        \"\"\"Construct a Template.\n\n        :arg str template_string: the contents of the template file.\n        :arg str name: the filename from which the template was loaded\n            (used for error message).\n        :arg tornado.template.BaseLoader loader: the `~tornado.template.BaseLoader` responsible\n            for this template, used to resolve ``{% include %}`` and ``{% extend %}`` directives.\n        :arg bool compress_whitespace: Deprecated since Tornado 4.3.\n            Equivalent to ``whitespace=\"single\"`` if true and\n            ``whitespace=\"all\"`` if false.\n        :arg str autoescape: The name of a function in the template\n            namespace, or ``None`` to disable escaping by default.\n        :arg str whitespace: A string specifying treatment of whitespace;\n            see `filter_whitespace` for options.\n\n        .. versionchanged:: 4.3\n           Added ``whitespace`` parameter; deprecated ``compress_whitespace``.\n        \"\"\"\n        self.name = escape.native_str(name)\n\n        if compress_whitespace is not _UNSET:\n            # Convert deprecated compress_whitespace (bool) to whitespace (str).\n            if whitespace is not None:\n                raise Exception(\"cannot set both whitespace and compress_whitespace\")\n            whitespace = \"single\" if compress_whitespace else \"all\"\n        if whitespace is None:\n            if loader and loader.whitespace:\n                whitespace = loader.whitespace\n            else:\n                # Whitespace defaults by filename.\n                if name.endswith(\".html\") or name.endswith(\".js\"):\n                    whitespace = \"single\"\n                else:\n                    whitespace = \"all\"\n        # Validate the whitespace setting.\n        assert whitespace is not None\n        filter_whitespace(whitespace, \"\")\n\n        if not isinstance(autoescape, _UnsetMarker):\n            self.autoescape = autoescape  # type: Optional[str]\n        elif loader:\n            self.autoescape = loader.autoescape\n        else:\n            self.autoescape = _DEFAULT_AUTOESCAPE\n\n        self.namespace = loader.namespace if loader else {}\n        reader = _TemplateReader(name, escape.native_str(template_string), whitespace)\n        self.file = _File(self, _parse(reader, self))\n        self.code = self._generate_python(loader)\n        self.loader = loader\n        try:\n            # Under python2.5, the fake filename used here must match\n            # the module name used in __name__ below.\n            # The dont_inherit flag prevents template.py's future imports\n            # from being applied to the generated code.\n            self.compiled = compile(\n                escape.to_unicode(self.code),\n                \"%s.generated.py\" % self.name.replace(\".\", \"_\"),\n                \"exec\",\n                dont_inherit=True,\n            )\n        except Exception:\n            formatted_code = _format_code(self.code).rstrip()\n            app_log.error(\"%s code:\\n%s\", self.name, formatted_code)\n            raise",
      "importString": "import datetime\nfrom io import StringIO\nimport linecache\nimport os.path\nimport posixpath\nimport re\nimport threading\n\nfrom tornado import escape\nfrom tornado.log import app_log\nfrom tornado.util import ObjectDict, exec_in, unicode_type\n\nfrom typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing",
      "lineNum": 73,
      "relativeDocumentPath": "tornado/template.py"
    },
    {
      "symbolName": "generate",
      "sourceCode": "def generate(self, **kwargs: Any) -> bytes:\n        \"\"\"Generate this template with the given arguments.\"\"\"\n        namespace = {\n            \"escape\": escape.xhtml_escape,\n            \"xhtml_escape\": escape.xhtml_escape,\n            \"url_escape\": escape.url_escape,\n            \"json_encode\": escape.json_encode,\n            \"squeeze\": escape.squeeze,\n            \"linkify\": escape.linkify,\n            \"datetime\": datetime,\n            \"_tt_utf8\": escape.utf8,  # for internal use\n            \"_tt_string_types\": (unicode_type, bytes),\n            # __name__ and __loader__ allow the traceback mechanism to find\n            # the generated source code.\n            \"__name__\": self.name.replace(\".\", \"_\"),\n            \"__loader__\": ObjectDict(get_source=lambda name: self.code),\n        }\n        namespace.update(self.namespace)\n        namespace.update(kwargs)\n        exec_in(self.compiled, namespace)\n        execute = typing.cast(Callable[[], bytes], namespace[\"_tt_execute\"])\n        # Clear the traceback module's cache of source data now that\n        # we've generated a new template (mainly for this module's\n        # unittests, where different tests reuse the same name).\n        linecache.clearcache()\n        return execute()",
      "importString": "import datetime\nfrom io import StringIO\nimport linecache\nimport os.path\nimport posixpath\nimport re\nimport threading\n\nfrom tornado import escape\nfrom tornado.log import app_log\nfrom tornado.util import ObjectDict, exec_in, unicode_type\n\nfrom typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing",
      "lineNum": 25,
      "relativeDocumentPath": "tornado/template.py"
    },
    {
      "symbolName": "_generate_python",
      "sourceCode": "def _generate_python(self, loader: Optional[\"BaseLoader\"]) -> str:\n        buffer = StringIO()\n        try:\n            # named_blocks maps from names to _NamedBlock objects\n            named_blocks = {}  # type: Dict[str, _NamedBlock]\n            ancestors = self._get_ancestors(loader)\n            ancestors.reverse()\n            for ancestor in ancestors:\n                ancestor.find_named_blocks(loader, named_blocks)\n            writer = _CodeWriter(buffer, named_blocks, loader, ancestors[0].template)\n            ancestors[0].generate(writer)\n            return buffer.getvalue()\n        finally:\n            buffer.close()",
      "importString": "import datetime\nfrom io import StringIO\nimport linecache\nimport os.path\nimport posixpath\nimport re\nimport threading\n\nfrom tornado import escape\nfrom tornado.log import app_log\nfrom tornado.util import ObjectDict, exec_in, unicode_type\n\nfrom typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/template.py"
    },
    {
      "symbolName": "_get_ancestors",
      "sourceCode": "def _get_ancestors(self, loader: Optional[\"BaseLoader\"]) -> List[\"_File\"]:\n        ancestors = [self.file]\n        for chunk in self.file.body.chunks:\n            if isinstance(chunk, _ExtendsBlock):\n                if not loader:\n                    raise ParseError(\n                        \"{% extends %} block found, but no \" \"template loader\"\n                    )\n                template = loader.load(chunk.name, self.name)\n                ancestors.extend(template._get_ancestors(loader))\n        return ancestors",
      "importString": "import datetime\nfrom io import StringIO\nimport linecache\nimport os.path\nimport posixpath\nimport re\nimport threading\n\nfrom tornado import escape\nfrom tornado.log import app_log\nfrom tornado.util import ObjectDict, exec_in, unicode_type\n\nfrom typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/template.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        autoescape: Optional[str] = _DEFAULT_AUTOESCAPE,\n        namespace: Optional[Dict[str, Any]] = None,\n        whitespace: Optional[str] = None,\n    ) -> None:\n        \"\"\"Construct a template loader.\n\n        :arg str autoescape: The name of a function in the template\n            namespace, such as \"xhtml_escape\", or ``None`` to disable\n            autoescaping by default.\n        :arg dict namespace: A dictionary to be added to the default template\n            namespace, or ``None``.\n        :arg str whitespace: A string specifying default behavior for\n            whitespace in templates; see `filter_whitespace` for options.\n            Default is \"single\" for files ending in \".html\" and \".js\" and\n            \"all\" for other files.\n\n        .. versionchanged:: 4.3\n           Added ``whitespace`` parameter.\n        \"\"\"\n        self.autoescape = autoescape\n        self.namespace = namespace or {}\n        self.whitespace = whitespace\n        self.templates = {}  # type: Dict[str, Template]\n        # self.lock protects self.templates.  It's a reentrant lock\n        # because templates may load other templates via `include` or\n        # `extends`.  Note that thanks to the GIL this code would be safe\n        # even without the lock, but could lead to wasted work as multiple\n        # threads tried to compile the same template simultaneously.\n        self.lock = threading.RLock()",
      "importString": "import datetime\nfrom io import StringIO\nimport linecache\nimport os.path\nimport posixpath\nimport re\nimport threading\n\nfrom tornado import escape\nfrom tornado.log import app_log\nfrom tornado.util import ObjectDict, exec_in, unicode_type\n\nfrom typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing",
      "lineNum": 30,
      "relativeDocumentPath": "tornado/template.py"
    },
    {
      "symbolName": "resolve_path",
      "sourceCode": "def resolve_path(self, name: str, parent_path: Optional[str] = None) -> str:\n        if (\n            parent_path\n            and not parent_path.startswith(\"<\")\n            and not parent_path.startswith(\"/\")\n            and not name.startswith(\"/\")\n        ):\n            current_path = os.path.join(self.root, parent_path)\n            file_dir = os.path.dirname(os.path.abspath(current_path))\n            relative_path = os.path.abspath(os.path.join(file_dir, name))\n            if relative_path.startswith(self.root):\n                name = relative_path[len(self.root) + 1 :]\n        return name",
      "importString": "import datetime\nfrom io import StringIO\nimport linecache\nimport os.path\nimport posixpath\nimport re\nimport threading\n\nfrom tornado import escape\nfrom tornado.log import app_log\nfrom tornado.util import ObjectDict, exec_in, unicode_type\n\nfrom typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/template.py"
    },
    {
      "symbolName": "generate",
      "sourceCode": "def generate(self, writer: \"_CodeWriter\") -> None:\n        method_name = \"_tt_apply%d\" % writer.apply_counter\n        writer.apply_counter += 1\n        writer.write_line(\"def %s():\" % method_name, self.line)\n        with writer.indent():\n            writer.write_line(\"_tt_buffer = []\", self.line)\n            writer.write_line(\"_tt_append = _tt_buffer.append\", self.line)\n            self.body.generate(writer)\n            writer.write_line(\"return _tt_utf8('').join(_tt_buffer)\", self.line)\n        writer.write_line(\n            f\"_tt_append(_tt_utf8({self.method}({method_name}())))\", self.line\n        )",
      "importString": "import datetime\nfrom io import StringIO\nimport linecache\nimport os.path\nimport posixpath\nimport re\nimport threading\n\nfrom tornado import escape\nfrom tornado.log import app_log\nfrom tornado.util import ObjectDict, exec_in, unicode_type\n\nfrom typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/template.py"
    },
    {
      "symbolName": "generate",
      "sourceCode": "def generate(self, writer: \"_CodeWriter\") -> None:\n        writer.write_line(\"_tt_tmp = %s\" % self.expression, self.line)\n        writer.write_line(\n            \"if isinstance(_tt_tmp, _tt_string_types):\" \" _tt_tmp = _tt_utf8(_tt_tmp)\",\n            self.line,\n        )\n        writer.write_line(\"else: _tt_tmp = _tt_utf8(str(_tt_tmp))\", self.line)\n        if not self.raw and writer.current_template.autoescape is not None:\n            # In python3 functions like xhtml_escape return unicode,\n            # so we have to convert to utf8 again.\n            writer.write_line(\n                \"_tt_tmp = _tt_utf8(%s(_tt_tmp))\" % writer.current_template.autoescape,\n                self.line,\n            )\n        writer.write_line(\"_tt_append(_tt_tmp)\", self.line)",
      "importString": "import datetime\nfrom io import StringIO\nimport linecache\nimport os.path\nimport posixpath\nimport re\nimport threading\n\nfrom tornado import escape\nfrom tornado.log import app_log\nfrom tornado.util import ObjectDict, exec_in, unicode_type\n\nfrom typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/template.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        file: TextIO,\n        named_blocks: Dict[str, _NamedBlock],\n        loader: Optional[BaseLoader],\n        current_template: Template,\n    ) -> None:\n        self.file = file\n        self.named_blocks = named_blocks\n        self.loader = loader\n        self.current_template = current_template\n        self.apply_counter = 0\n        self.include_stack = []  # type: List[Tuple[Template, int]]\n        self._indent = 0",
      "importString": "import datetime\nfrom io import StringIO\nimport linecache\nimport os.path\nimport posixpath\nimport re\nimport threading\n\nfrom tornado import escape\nfrom tornado.log import app_log\nfrom tornado.util import ObjectDict, exec_in, unicode_type\n\nfrom typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/template.py"
    },
    {
      "symbolName": "indent",
      "sourceCode": "def indent(self) -> \"ContextManager\":\n        class Indenter:\n            def __enter__(_) -> \"_CodeWriter\":\n                self._indent += 1\n                return self\n\n            def __exit__(_, *args: Any) -> None:\n                assert self._indent > 0\n                self._indent -= 1\n\n        return Indenter()",
      "importString": "import datetime\nfrom io import StringIO\nimport linecache\nimport os.path\nimport posixpath\nimport re\nimport threading\n\nfrom tornado import escape\nfrom tornado.log import app_log\nfrom tornado.util import ObjectDict, exec_in, unicode_type\n\nfrom typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/template.py"
    },
    {
      "symbolName": "include",
      "sourceCode": "def include(self, template: Template, line: int) -> \"ContextManager\":\n        self.include_stack.append((self.current_template, line))\n        self.current_template = template\n\n        class IncludeTemplate:\n            def __enter__(_) -> \"_CodeWriter\":\n                return self\n\n            def __exit__(_, *args: Any) -> None:\n                self.current_template = self.include_stack.pop()[0]\n\n        return IncludeTemplate()",
      "importString": "import datetime\nfrom io import StringIO\nimport linecache\nimport os.path\nimport posixpath\nimport re\nimport threading\n\nfrom tornado import escape\nfrom tornado.log import app_log\nfrom tornado.util import ObjectDict, exec_in, unicode_type\n\nfrom typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/template.py"
    },
    {
      "symbolName": "write_line",
      "sourceCode": "def write_line(\n        self, line: str, line_number: int, indent: Optional[int] = None\n    ) -> None:\n        if indent is None:\n            indent = self._indent\n        line_comment = \"  # %s:%d\" % (self.current_template.name, line_number)\n        if self.include_stack:\n            ancestors = [\n                \"%s:%d\" % (tmpl.name, lineno) for (tmpl, lineno) in self.include_stack\n            ]\n            line_comment += \" (via %s)\" % \", \".join(reversed(ancestors))\n        print(\"    \" * indent + line + line_comment, file=self.file)",
      "importString": "import datetime\nfrom io import StringIO\nimport linecache\nimport os.path\nimport posixpath\nimport re\nimport threading\n\nfrom tornado import escape\nfrom tornado.log import app_log\nfrom tornado.util import ObjectDict, exec_in, unicode_type\n\nfrom typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/template.py"
    },
    {
      "symbolName": "find",
      "sourceCode": "def find(self, needle: str, start: int = 0, end: Optional[int] = None) -> int:\n        assert start >= 0, start\n        pos = self.pos\n        start += pos\n        if end is None:\n            index = self.text.find(needle, start)\n        else:\n            end += pos\n            assert end >= start\n            index = self.text.find(needle, start, end)\n        if index != -1:\n            index -= pos\n        return index",
      "importString": "import datetime\nfrom io import StringIO\nimport linecache\nimport os.path\nimport posixpath\nimport re\nimport threading\n\nfrom tornado import escape\nfrom tornado.log import app_log\nfrom tornado.util import ObjectDict, exec_in, unicode_type\n\nfrom typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/template.py"
    },
    {
      "symbolName": "__getitem__",
      "sourceCode": "def __getitem__(self, key: Union[int, slice]) -> str:\n        if isinstance(key, slice):\n            size = len(self)\n            start, stop, step = key.indices(size)\n            if start is None:\n                start = self.pos\n            else:\n                start += self.pos\n            if stop is not None:\n                stop += self.pos\n            return self.text[slice(start, stop, step)]\n        elif key < 0:\n            return self.text[key]\n        else:\n            return self.text[self.pos + key]",
      "importString": "import datetime\nfrom io import StringIO\nimport linecache\nimport os.path\nimport posixpath\nimport re\nimport threading\n\nfrom tornado import escape\nfrom tornado.log import app_log\nfrom tornado.util import ObjectDict, exec_in, unicode_type\n\nfrom typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/template.py"
    },
    {
      "symbolName": "_parse",
      "sourceCode": "def _parse(\n    reader: _TemplateReader,\n    template: Template,\n    in_block: Optional[str] = None,\n    in_loop: Optional[str] = None,\n) -> _ChunkList:\n    body = _ChunkList([])\n    while True:\n        # Find next template directive\n        curly = 0\n        while True:\n            curly = reader.find(\"{\", curly)\n            if curly == -1 or curly + 1 == reader.remaining():\n                # EOF\n                if in_block:\n                    reader.raise_parse_error(\n                        \"Missing {%% end %%} block for %s\" % in_block\n                    )\n                body.chunks.append(\n                    _Text(reader.consume(), reader.line, reader.whitespace)\n                )\n                return body\n            # If the first curly brace is not the start of a special token,\n            # start searching from the character after it\n            if reader[curly + 1] not in (\"{\", \"%\", \"#\"):\n                curly += 1\n                continue\n            # When there are more than 2 curlies in a row, use the\n            # innermost ones.  This is useful when generating languages\n            # like latex where curlies are also meaningful\n            if (\n                curly + 2 < reader.remaining()\n                and reader[curly + 1] == \"{\"\n                and reader[curly + 2] == \"{\"\n            ):\n                curly += 1\n                continue\n            break\n\n        # Append any text before the special token\n        if curly > 0:\n            cons = reader.consume(curly)\n            body.chunks.append(_Text(cons, reader.line, reader.whitespace))\n\n        start_brace = reader.consume(2)\n        line = reader.line\n\n        # Template directives may be escaped as \"{{!\" or \"{%!\".\n        # In this case output the braces and consume the \"!\".\n        # This is especially useful in conjunction with jquery templates,\n        # which also use double braces.\n        if reader.remaining() and reader[0] == \"!\":\n            reader.consume(1)\n            body.chunks.append(_Text(start_brace, line, reader.whitespace))\n            continue\n\n        # Comment\n        if start_brace == \"{#\":\n            end = reader.find(\"#}\")\n            if end == -1:\n                reader.raise_parse_error(\"Missing end comment #}\")\n            contents = reader.consume(end).strip()\n            reader.consume(2)\n            continue\n\n        # Expression\n        if start_brace == \"{{\":\n            end = reader.find(\"}}\")\n            if end == -1:\n                reader.raise_parse_error(\"Missing end expression }}\")\n            contents = reader.consume(end).strip()\n            reader.consume(2)\n            if not contents:\n                reader.raise_parse_error(\"Empty expression\")\n            body.chunks.append(_Expression(contents, line))\n            continue\n\n        # Block\n        assert start_brace == \"{%\", start_brace\n        end = reader.find(\"%}\")\n        if end == -1:\n            reader.raise_parse_error(\"Missing end block %}\")\n        contents = reader.consume(end).strip()\n        reader.consume(2)\n        if not contents:\n            reader.raise_parse_error(\"Empty block tag ({% %})\")\n\n        operator, space, suffix = contents.partition(\" \")\n        suffix = suffix.strip()\n\n        # Intermediate (\"else\", \"elif\", etc) blocks\n        intermediate_blocks = {\n            \"else\": {\"if\", \"for\", \"while\", \"try\"},\n            \"elif\": {\"if\"},\n            \"except\": {\"try\"},\n            \"finally\": {\"try\"},\n        }\n        allowed_parents = intermediate_blocks.get(operator)\n        if allowed_parents is not None:\n            if not in_block:\n                reader.raise_parse_error(f\"{operator} outside {allowed_parents} block\")\n            if in_block not in allowed_parents:\n                reader.raise_parse_error(\n                    f\"{operator} block cannot be attached to {in_block} block\"\n                )\n            body.chunks.append(_IntermediateControlBlock(contents, line))\n            continue\n\n        # End tag\n        elif operator == \"end\":\n            if not in_block:\n                reader.raise_parse_error(\"Extra {% end %} block\")\n            return body\n\n        elif operator in (\n            \"extends\",\n            \"include\",\n            \"set\",\n            \"import\",\n            \"from\",\n            \"comment\",\n            \"autoescape\",\n            \"whitespace\",\n            \"raw\",\n            \"module\",\n        ):\n            if operator == \"comment\":\n                continue\n            if operator == \"extends\":\n                suffix = suffix.strip('\"').strip(\"'\")\n                if not suffix:\n                    reader.raise_parse_error(\"extends missing file path\")\n                block = _ExtendsBlock(suffix)  # type: _Node\n            elif operator in (\"import\", \"from\"):\n                if not suffix:\n                    reader.raise_parse_error(\"import missing statement\")\n                block = _Statement(contents, line)\n            elif operator == \"include\":\n                suffix = suffix.strip('\"').strip(\"'\")\n                if not suffix:\n                    reader.raise_parse_error(\"include missing file path\")\n                block = _IncludeBlock(suffix, reader, line)\n            elif operator == \"set\":\n                if not suffix:\n                    reader.raise_parse_error(\"set missing statement\")\n                block = _Statement(suffix, line)\n            elif operator == \"autoescape\":\n                fn = suffix.strip()  # type: Optional[str]\n                if fn == \"None\":\n                    fn = None\n                template.autoescape = fn\n                continue\n            elif operator == \"whitespace\":\n                mode = suffix.strip()\n                # Validate the selected mode\n                filter_whitespace(mode, \"\")\n                reader.whitespace = mode\n                continue\n            elif operator == \"raw\":\n                block = _Expression(suffix, line, raw=True)\n            elif operator == \"module\":\n                block = _Module(suffix, line)\n            body.chunks.append(block)\n            continue\n\n        elif operator in (\"apply\", \"block\", \"try\", \"if\", \"for\", \"while\"):\n            # parse inner body recursively\n            if operator in (\"for\", \"while\"):\n                block_body = _parse(reader, template, operator, operator)\n            elif operator == \"apply\":\n                # apply creates a nested function so syntactically it's not\n                # in the loop.\n                block_body = _parse(reader, template, operator, None)\n            else:\n                block_body = _parse(reader, template, operator, in_loop)\n\n            if operator == \"apply\":\n                if not suffix:\n                    reader.raise_parse_error(\"apply missing method name\")\n                block = _ApplyBlock(suffix, line, block_body)\n            elif operator == \"block\":\n                if not suffix:\n                    reader.raise_parse_error(\"block missing name\")\n                block = _NamedBlock(suffix, block_body, template, line)\n            else:\n                block = _ControlBlock(contents, line, block_body)\n            body.chunks.append(block)\n            continue\n\n        elif operator in (\"break\", \"continue\"):\n            if not in_loop:\n                reader.raise_parse_error(\n                    \"{} outside {} block\".format(operator, {\"for\", \"while\"})\n                )\n            body.chunks.append(_Statement(contents, line))\n            continue\n\n        else:\n            reader.raise_parse_error(\"unknown operator: %r\" % operator)",
      "importString": "import datetime\nfrom io import StringIO\nimport linecache\nimport os.path\nimport posixpath\nimport re\nimport threading\n\nfrom tornado import escape\nfrom tornado.log import app_log\nfrom tornado.util import ObjectDict, exec_in, unicode_type\n\nfrom typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing",
      "lineNum": 198,
      "relativeDocumentPath": "tornado/template.py"
    },
    {
      "symbolName": "bind_unused_port",
      "sourceCode": "def bind_unused_port(\n    reuse_port: bool = False, address: str = \"127.0.0.1\"\n) -> Tuple[socket.socket, int]:\n    \"\"\"Binds a server socket to an available port on localhost.\n\n    Returns a tuple (socket, port).\n\n    .. versionchanged:: 4.4\n       Always binds to ``127.0.0.1`` without resolving the name\n       ``localhost``.\n\n    .. versionchanged:: 6.2\n       Added optional ``address`` argument to\n       override the default \"127.0.0.1\".\n    \"\"\"\n    sock = netutil.bind_sockets(\n        0, address, family=socket.AF_INET, reuse_port=reuse_port\n    )[0]\n    port = sock.getsockname()[1]\n    return sock, port",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 19,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "get_async_test_timeout",
      "sourceCode": "def get_async_test_timeout() -> float:\n    \"\"\"Get the global timeout setting for async tests.\n\n    Returns a float, the timeout in seconds.\n\n    .. versionadded:: 3.1\n    \"\"\"\n    env = os.environ.get(\"ASYNC_TEST_TIMEOUT\")\n    if env is not None:\n        try:\n            return float(env)\n        except ValueError:\n            pass\n    return 5",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "setUp",
      "sourceCode": "def setUp(self) -> None:\n        py_ver = sys.version_info\n        if ((3, 10, 0) <= py_ver < (3, 10, 9)) or ((3, 11, 0) <= py_ver <= (3, 11, 1)):\n            # Early releases in the Python 3.10 and 3.1 series had deprecation\n            # warnings that were later reverted; we must suppress them here.\n            setup_with_context_manager(self, warnings.catch_warnings())\n            warnings.filterwarnings(\n                \"ignore\",\n                message=\"There is no current event loop\",\n                category=DeprecationWarning,\n                module=r\"tornado\\..*\",\n            )\n        super().setUp()\n        if type(self).get_new_ioloop is not AsyncTestCase.get_new_ioloop:\n            warnings.warn(\"get_new_ioloop is deprecated\", DeprecationWarning)\n        self.io_loop = self.get_new_ioloop()\n        asyncio.set_event_loop(self.io_loop.asyncio_loop)",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "tearDown",
      "sourceCode": "def tearDown(self) -> None:\n        # Native coroutines tend to produce warnings if they're not\n        # allowed to run to completion. It's difficult to ensure that\n        # this always happens in tests, so cancel any tasks that are\n        # still pending by the time we get here.\n        asyncio_loop = self.io_loop.asyncio_loop  # type: ignore\n        tasks = asyncio.all_tasks(asyncio_loop)\n        # Tasks that are done may still appear here and may contain\n        # non-cancellation exceptions, so filter them out.\n        tasks = [t for t in tasks if not t.done()]  # type: ignore\n        for t in tasks:\n            t.cancel()\n        # Allow the tasks to run and finalize themselves (which means\n        # raising a CancelledError inside the coroutine). This may\n        # just transform the \"task was destroyed but it is pending\"\n        # warning into a \"uncaught CancelledError\" warning, but\n        # catching CancelledErrors in coroutines that may leak is\n        # simpler than ensuring that no coroutines leak.\n        if tasks:\n            done, pending = self.io_loop.run_sync(lambda: asyncio.wait(tasks))\n            assert not pending\n            # If any task failed with anything but a CancelledError, raise it.\n            for f in done:\n                try:\n                    f.result()\n                except asyncio.CancelledError:\n                    pass\n\n        # Clean up Subprocess, so it can be used again with a new ioloop.\n        Subprocess.uninitialize()\n        asyncio.set_event_loop(None)\n        if not isinstance(self.io_loop, _NON_OWNED_IOLOOPS):\n            # Try to clean up any file descriptors left open in the ioloop.\n            # This avoids leaks, especially when tests are run repeatedly\n            # in the same process with autoreload (because curl does not\n            # set FD_CLOEXEC on its file descriptors)\n            self.io_loop.close(all_fds=True)\n        super().tearDown()\n        # In case an exception escaped or the StackContext caught an exception\n        # when there wasn't a wait() to re-raise it, do so here.\n        # This is our last chance to raise an exception in a way that the\n        # unittest machinery understands.\n        self.__rethrow()",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 42,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "get_new_ioloop",
      "sourceCode": "def get_new_ioloop(self) -> IOLoop:\n        \"\"\"Returns the `.IOLoop` to use for this test.\n\n        By default, a new `.IOLoop` is created for each test.\n        Subclasses may override this method to return\n        `.IOLoop.current()` if it is not appropriate to use a new\n        `.IOLoop` in each tests (for example, if there are global\n        singletons using the default `.IOLoop`) or if a per-test event\n        loop is being provided by another system (such as\n        ``pytest-asyncio``).\n\n        .. deprecated:: 6.3\n           This method will be removed in Tornado 7.0.\n        \"\"\"\n        return IOLoop(make_current=False)",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "_handle_exception",
      "sourceCode": "def _handle_exception(\n        self, typ: Type[Exception], value: Exception, tb: TracebackType\n    ) -> bool:\n        if self.__failure is None:\n            self.__failure = (typ, value, tb)\n        else:\n            app_log.error(\n                \"multiple unhandled exceptions in test\", exc_info=(typ, value, tb)\n            )\n        self.stop()\n        return True",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "_callTestMethod",
      "sourceCode": "def _callTestMethod(self, method: Callable) -> None:\n        \"\"\"Run the given test method, raising an error if it returns non-None.\n\n        Failure to decorate asynchronous test methods with ``@gen_test`` can lead to tests\n        incorrectly passing.\n\n        Remove this override when Python 3.10 support is dropped. This check (in the form of a\n        DeprecationWarning) became a part of the standard library in 3.11.\n\n        Note that ``_callTestMethod`` is not documented as a public interface. However, it is\n        present in all supported versions of Python (3.8+), and if it goes away in the future that's\n        OK because we can just remove this override as noted above.\n        \"\"\"\n        # Calling super()._callTestMethod would hide the return value, even in python 3.8-3.10\n        # where the check isn't being done for us.\n        result = method()\n        if isinstance(result, Generator) or inspect.iscoroutine(result):\n            raise TypeError(\n                \"Generator and coroutine test methods should be\"\n                \" decorated with tornado.testing.gen_test\"\n            )\n        elif result is not None:\n            raise ValueError(\"Return value from test method ignored: %r\" % result)",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 22,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "stop",
      "sourceCode": "def stop(self, _arg: Any = None, **kwargs: Any) -> None:\n        \"\"\"Stops the `.IOLoop`, causing one pending (or future) call to `wait()`\n        to return.\n\n        Keyword arguments or a single positional argument passed to `stop()` are\n        saved and will be returned by `wait()`.\n\n        .. deprecated:: 5.1\n\n           `stop` and `wait` are deprecated; use ``@gen_test`` instead.\n        \"\"\"\n        assert _arg is None or not kwargs\n        self.__stop_args = kwargs or _arg\n        if self.__running:\n            self.io_loop.stop()\n            self.__running = False\n        self.__stopped = True",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "wait",
      "sourceCode": "def wait(\n        self,\n        condition: Optional[Callable[..., bool]] = None,\n        timeout: Optional[float] = None,\n    ) -> Any:\n        \"\"\"Runs the `.IOLoop` until stop is called or timeout has passed.\n\n        In the event of a timeout, an exception will be thrown. The\n        default timeout is 5 seconds; it may be overridden with a\n        ``timeout`` keyword argument or globally with the\n        ``ASYNC_TEST_TIMEOUT`` environment variable.\n\n        If ``condition`` is not ``None``, the `.IOLoop` will be restarted\n        after `stop()` until ``condition()`` returns ``True``.\n\n        .. versionchanged:: 3.1\n           Added the ``ASYNC_TEST_TIMEOUT`` environment variable.\n\n        .. deprecated:: 5.1\n\n           `stop` and `wait` are deprecated; use ``@gen_test`` instead.\n        \"\"\"\n        if timeout is None:\n            timeout = get_async_test_timeout()\n\n        if not self.__stopped:\n            if timeout:\n\n                def timeout_func() -> None:\n                    try:\n                        raise self.failureException(\n                            \"Async operation timed out after %s seconds\" % timeout\n                        )\n                    except Exception:\n                        self.__failure = sys.exc_info()\n                    self.stop()\n\n                self.__timeout = self.io_loop.add_timeout(\n                    self.io_loop.time() + timeout, timeout_func\n                )\n            while True:\n                self.__running = True\n                self.io_loop.start()\n                if self.__failure is not None or condition is None or condition():\n                    break\n            if self.__timeout is not None:\n                self.io_loop.remove_timeout(self.__timeout)\n                self.__timeout = None\n        assert self.__stopped\n        self.__stopped = False\n        self.__rethrow()\n        result = self.__stop_args\n        self.__stop_args = None\n        return result",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 53,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "fetch",
      "sourceCode": "def fetch(\n        self, path: str, raise_error: bool = False, **kwargs: Any\n    ) -> HTTPResponse:\n        \"\"\"Convenience method to synchronously fetch a URL.\n\n        The given path will be appended to the local server's host and\n        port.  Any additional keyword arguments will be passed directly to\n        `.AsyncHTTPClient.fetch` (and so could be used to pass\n        ``method=\"POST\"``, ``body=\"...\"``, etc).\n\n        If the path begins with http:// or https://, it will be treated as a\n        full URL and will be fetched as-is.\n\n        If ``raise_error`` is ``True``, a `tornado.httpclient.HTTPError` will\n        be raised if the response code is not 200. This is the same behavior\n        as the ``raise_error`` argument to `.AsyncHTTPClient.fetch`, but\n        the default is ``False`` here (it's ``True`` in `.AsyncHTTPClient`)\n        because tests often need to deal with non-200 response codes.\n\n        .. versionchanged:: 5.0\n           Added support for absolute URLs.\n\n        .. versionchanged:: 5.1\n\n           Added the ``raise_error`` argument.\n\n        .. deprecated:: 5.1\n\n           This method currently turns any exception into an\n           `.HTTPResponse` with status code 599. In Tornado 6.0,\n           errors other than `tornado.httpclient.HTTPError` will be\n           passed through, and ``raise_error=False`` will only\n           suppress errors that would be raised due to non-200\n           response codes.\n\n        \"\"\"\n        if path.lower().startswith((\"http://\", \"https://\")):\n            url = path\n        else:\n            url = self.get_url(path)\n        return self.io_loop.run_sync(\n            lambda: self.http_client.fetch(url, raise_error=raise_error, **kwargs),\n            timeout=get_async_test_timeout(),\n        )",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 43,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "default_ssl_options",
      "sourceCode": "@staticmethod\n    def default_ssl_options() -> Dict[str, Any]:\n        # Testing keys were generated with:\n        # openssl req -new -keyout tornado/test/test.key \\\n        #     -out tornado/test/test.crt \\\n        #     -nodes -days 3650 -x509 \\\n        #     -subj \"/CN=foo.example.com\" -addext \"subjectAltName = DNS:foo.example.com\"\n        module_dir = os.path.dirname(__file__)\n        return dict(\n            certfile=os.path.join(module_dir, \"test\", \"test.crt\"),\n            keyfile=os.path.join(module_dir, \"test\", \"test.key\"),\n        )",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "gen_test",
      "sourceCode": "def gen_test(  # noqa: F811\n    func: Optional[Callable[..., Union[Generator, \"Coroutine\"]]] = None,\n    timeout: Optional[float] = None,\n) -> Union[\n    Callable[..., None],\n    Callable[[Callable[..., Union[Generator, \"Coroutine\"]]], Callable[..., None]],\n]:\n    \"\"\"Testing equivalent of ``@gen.coroutine``, to be applied to test methods.\n\n    ``@gen.coroutine`` cannot be used on tests because the `.IOLoop` is not\n    already running.  ``@gen_test`` should be applied to test methods\n    on subclasses of `AsyncTestCase`.\n\n    Example::\n\n        class MyTest(AsyncHTTPTestCase):\n            @gen_test\n            def test_something(self):\n                response = yield self.http_client.fetch(self.get_url('/'))\n\n    By default, ``@gen_test`` times out after 5 seconds. The timeout may be\n    overridden globally with the ``ASYNC_TEST_TIMEOUT`` environment variable,\n    or for each test with the ``timeout`` keyword argument::\n\n        class MyTest(AsyncHTTPTestCase):\n            @gen_test(timeout=10)\n            def test_something_slow(self):\n                response = yield self.http_client.fetch(self.get_url('/'))\n\n    Note that ``@gen_test`` is incompatible with `AsyncTestCase.stop`,\n    `AsyncTestCase.wait`, and `AsyncHTTPTestCase.fetch`. Use ``yield\n    self.http_client.fetch(self.get_url())`` as shown above instead.\n\n    .. versionadded:: 3.1\n       The ``timeout`` argument and ``ASYNC_TEST_TIMEOUT`` environment\n       variable.\n\n    .. versionchanged:: 4.0\n       The wrapper now passes along ``*args, **kwargs`` so it can be used\n       on functions with arguments.\n\n    \"\"\"\n    if timeout is None:\n        timeout = get_async_test_timeout()\n\n    def wrap(f: Callable[..., Union[Generator, \"Coroutine\"]]) -> Callable[..., None]:\n        # Stack up several decorators to allow us to access the generator\n        # object itself.  In the innermost wrapper, we capture the generator\n        # and save it in an attribute of self.  Next, we run the wrapped\n        # function through @gen.coroutine.  Finally, the coroutine is\n        # wrapped again to make it synchronous with run_sync.\n        #\n        # This is a good case study arguing for either some sort of\n        # extensibility in the gen decorators or cancellation support.\n        @functools.wraps(f)\n        def pre_coroutine(self, *args, **kwargs):\n            # type: (AsyncTestCase, *Any, **Any) -> Union[Generator, Coroutine]\n            # Type comments used to avoid pypy3 bug.\n            result = f(self, *args, **kwargs)\n            if isinstance(result, Generator) or inspect.iscoroutine(result):\n                self._test_generator = result\n            else:\n                self._test_generator = None\n            return result\n\n        if inspect.iscoroutinefunction(f):\n            coro = pre_coroutine\n        else:\n            coro = gen.coroutine(pre_coroutine)  # type: ignore[assignment]\n\n        @functools.wraps(coro)\n        def post_coroutine(self, *args, **kwargs):\n            # type: (AsyncTestCase, *Any, **Any) -> None\n            try:\n                return self.io_loop.run_sync(\n                    functools.partial(coro, self, *args, **kwargs), timeout=timeout\n                )\n            except TimeoutError as e:\n                # run_sync raises an error with an unhelpful traceback.\n                # If the underlying generator is still running, we can throw the\n                # exception back into it so the stack trace is replaced by the\n                # point where the test is stopped. The only reason the generator\n                # would not be running would be if it were cancelled, which means\n                # a native coroutine, so we can rely on the cr_running attribute.\n                if self._test_generator is not None and getattr(\n                    self._test_generator, \"cr_running\", True\n                ):\n                    self._test_generator.throw(e)\n                    # In case the test contains an overly broad except\n                    # clause, we may get back here.\n                # Coroutine was stopped or didn't raise a useful stack trace,\n                # so re-raise the original exception which is better than nothing.\n                raise\n\n        return post_coroutine\n\n    if func is not None:\n        # Used like:\n        #     @gen_test\n        #     def f(self):\n        #         pass\n        return wrap(func)\n    else:\n        # Used like @gen_test(timeout=10)\n        return wrap",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 104,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "wrap",
      "sourceCode": "def wrap(f: Callable[..., Union[Generator, \"Coroutine\"]]) -> Callable[..., None]:\n        # Stack up several decorators to allow us to access the generator\n        # object itself.  In the innermost wrapper, we capture the generator\n        # and save it in an attribute of self.  Next, we run the wrapped\n        # function through @gen.coroutine.  Finally, the coroutine is\n        # wrapped again to make it synchronous with run_sync.\n        #\n        # This is a good case study arguing for either some sort of\n        # extensibility in the gen decorators or cancellation support.\n        @functools.wraps(f)\n        def pre_coroutine(self, *args, **kwargs):\n            # type: (AsyncTestCase, *Any, **Any) -> Union[Generator, Coroutine]\n            # Type comments used to avoid pypy3 bug.\n            result = f(self, *args, **kwargs)\n            if isinstance(result, Generator) or inspect.iscoroutine(result):\n                self._test_generator = result\n            else:\n                self._test_generator = None\n            return result\n\n        if inspect.iscoroutinefunction(f):\n            coro = pre_coroutine\n        else:\n            coro = gen.coroutine(pre_coroutine)  # type: ignore[assignment]\n\n        @functools.wraps(coro)\n        def post_coroutine(self, *args, **kwargs):\n            # type: (AsyncTestCase, *Any, **Any) -> None\n            try:\n                return self.io_loop.run_sync(\n                    functools.partial(coro, self, *args, **kwargs), timeout=timeout\n                )\n            except TimeoutError as e:\n                # run_sync raises an error with an unhelpful traceback.\n                # If the underlying generator is still running, we can throw the\n                # exception back into it so the stack trace is replaced by the\n                # point where the test is stopped. The only reason the generator\n                # would not be running would be if it were cancelled, which means\n                # a native coroutine, so we can rely on the cr_running attribute.\n                if self._test_generator is not None and getattr(\n                    self._test_generator, \"cr_running\", True\n                ):\n                    self._test_generator.throw(e)\n                    # In case the test contains an overly broad except\n                    # clause, we may get back here.\n                # Coroutine was stopped or didn't raise a useful stack trace,\n                # so re-raise the original exception which is better than nothing.\n                raise\n\n        return post_coroutine",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 49,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "post_coroutine",
      "sourceCode": "@functools.wraps(coro)\n        def post_coroutine(self, *args, **kwargs):\n            # type: (AsyncTestCase, *Any, **Any) -> None\n            try:\n                return self.io_loop.run_sync(\n                    functools.partial(coro, self, *args, **kwargs), timeout=timeout\n                )\n            except TimeoutError as e:\n                # run_sync raises an error with an unhelpful traceback.\n                # If the underlying generator is still running, we can throw the\n                # exception back into it so the stack trace is replaced by the\n                # point where the test is stopped. The only reason the generator\n                # would not be running would be if it were cancelled, which means\n                # a native coroutine, so we can rely on the cr_running attribute.\n                if self._test_generator is not None and getattr(\n                    self._test_generator, \"cr_running\", True\n                ):\n                    self._test_generator.throw(e)\n                    # In case the test contains an overly broad except\n                    # clause, we may get back here.\n                # Coroutine was stopped or didn't raise a useful stack trace,\n                # so re-raise the original exception which is better than nothing.\n                raise",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 22,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        logger: Union[logging.Logger, basestring_type],\n        regex: str,\n        required: bool = True,\n        level: Optional[int] = None,\n    ) -> None:\n        \"\"\"Constructs an ExpectLog context manager.\n\n        :param logger: Logger object (or name of logger) to watch.  Pass an\n            empty string to watch the root logger.\n        :param regex: Regular expression to match.  Any log entries on the\n            specified logger that match this regex will be suppressed.\n        :param required: If true, an exception will be raised if the end of the\n            ``with`` statement is reached without matching any log entries.\n        :param level: A constant from the ``logging`` module indicating the\n            expected log level. If this parameter is provided, only log messages\n            at this level will be considered to match. Additionally, the\n            supplied ``logger`` will have its level adjusted if necessary (for\n            the duration of the ``ExpectLog`` to enable the expected message.\n\n        .. versionchanged:: 6.1\n           Added the ``level`` parameter.\n\n        .. deprecated:: 6.3\n           In Tornado 7.0, only ``WARNING`` and higher logging levels will be\n           matched by default. To match ``INFO`` and lower levels, the ``level``\n           argument must be used. This is changing to minimize differences\n           between ``tornado.testing.main`` (which enables ``INFO`` logs by\n           default) and most other test runners (including those in IDEs)\n           which have ``INFO`` logs disabled by default.\n        \"\"\"\n        if isinstance(logger, basestring_type):\n            logger = logging.getLogger(logger)\n        self.logger = logger\n        self.regex = re.compile(regex)\n        self.required = required\n        # matched and deprecated_level_matched are a counter for the respective event.\n        self.matched = 0\n        self.deprecated_level_matched = 0\n        self.logged_stack = False\n        self.level = level\n        self.orig_level = None  # type: Optional[int]",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 42,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "filter",
      "sourceCode": "def filter(self, record: logging.LogRecord) -> bool:\n        if record.exc_info:\n            self.logged_stack = True\n        message = record.getMessage()\n        if self.regex.match(message):\n            if self.level is None and record.levelno < logging.WARNING:\n                # We're inside the logging machinery here so generating a DeprecationWarning\n                # here won't be reported cleanly (if warnings-as-errors is enabled, the error\n                # just gets swallowed by the logging module), and even if it were it would\n                # have the wrong stack trace. Just remember this fact and report it in\n                # __exit__ instead.\n                self.deprecated_level_matched += 1\n            if self.level is not None and record.levelno != self.level:\n                app_log.warning(\n                    \"Got expected log message %r at unexpected level (%s vs %s)\"\n                    % (message, logging.getLevelName(self.level), record.levelname)\n                )\n                return True\n            self.matched += 1\n            return False\n        return True",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "__exit__",
      "sourceCode": "def __exit__(\n        self,\n        typ: \"Optional[Type[BaseException]]\",\n        value: Optional[BaseException],\n        tb: Optional[TracebackType],\n    ) -> None:\n        if self.orig_level is not None:\n            self.logger.setLevel(self.orig_level)\n        self.logger.removeFilter(self)\n        if not typ and self.required and not self.matched:\n            raise Exception(\"did not get expected log message\")\n        if (\n            not typ\n            and self.required\n            and (self.deprecated_level_matched >= self.matched)\n        ):\n            warnings.warn(\n                \"ExpectLog matched at INFO or below without level argument\",\n                DeprecationWarning,\n            )",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 19,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "setup_with_context_manager",
      "sourceCode": "def setup_with_context_manager(testcase: unittest.TestCase, cm: Any) -> Any:\n    \"\"\"Use a context manager to setUp a test case.\n\n    Example::\n\n        def setUp(self):\n            setup_with_context_manager(self, warnings.catch_warnings())\n            warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n            # The catch_warnings context manager will be deactivated\n            # automatically in tearDown.\n\n    \"\"\"\n    val = cm.__enter__()\n    testcase.addCleanup(cm.__exit__, None, None, None)\n    return val",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "main",
      "sourceCode": "def main(**kwargs: Any) -> None:\n    \"\"\"A simple test runner.\n\n    This test runner is essentially equivalent to `unittest.main` from\n    the standard library, but adds support for Tornado-style option\n    parsing and log formatting. It is *not* necessary to use this\n    `main` function to run tests using `AsyncTestCase`; these tests\n    are self-contained and can run with any test runner.\n\n    The easiest way to run a test is via the command line::\n\n        python -m tornado.testing tornado.test.web_test\n\n    See the standard library ``unittest`` module for ways in which\n    tests can be specified.\n\n    Projects with many tests may wish to define a test script like\n    ``tornado/test/runtests.py``.  This script should define a method\n    ``all()`` which returns a test suite and then call\n    `tornado.testing.main()`.  Note that even when a test script is\n    used, the ``all()`` test suite may be overridden by naming a\n    single test on the command line::\n\n        # Runs all tests\n        python -m tornado.test.runtests\n        # Runs one test\n        python -m tornado.test.runtests tornado.test.web_test\n\n    Additional keyword arguments passed through to ``unittest.main()``.\n    For example, use ``tornado.testing.main(verbosity=2)``\n    to show many test details as they are run.\n    See http://docs.python.org/library/unittest.html#unittest.main\n    for full argument list.\n\n    .. versionchanged:: 5.0\n\n       This function produces no output of its own; only that produced\n       by the `unittest` module (previously it would add a PASS or FAIL\n       log message).\n    \"\"\"\n    from tornado.options import define, options, parse_command_line\n\n    define(\n        \"exception_on_interrupt\",\n        type=bool,\n        default=True,\n        help=(\n            \"If true (default), ctrl-c raises a KeyboardInterrupt \"\n            \"exception.  This prints a stack trace but cannot interrupt \"\n            \"certain operations.  If false, the process is more reliably \"\n            \"killed, but does not print a stack trace.\"\n        ),\n    )\n\n    # support the same options as unittest's command-line interface\n    define(\"verbose\", type=bool)\n    define(\"quiet\", type=bool)\n    define(\"failfast\", type=bool)\n    define(\"catch\", type=bool)\n    define(\"buffer\", type=bool)\n\n    argv = [sys.argv[0]] + parse_command_line(sys.argv)\n\n    if not options.exception_on_interrupt:\n        signal.signal(signal.SIGINT, signal.SIG_DFL)\n\n    if options.verbose is not None:\n        kwargs[\"verbosity\"] = 2\n    if options.quiet is not None:\n        kwargs[\"verbosity\"] = 0\n    if options.failfast is not None:\n        kwargs[\"failfast\"] = True\n    if options.catch is not None:\n        kwargs[\"catchbreak\"] = True\n    if options.buffer is not None:\n        kwargs[\"buffer\"] = True\n\n    if __name__ == \"__main__\" and len(argv) == 1:\n        print(\"No tests specified\", file=sys.stderr)\n        sys.exit(1)\n    # In order to be able to run tests by their fully-qualified name\n    # on the command line without importing all tests here,\n    # module must be set to None.  Python 3.2's unittest.main ignores\n    # defaultTest if no module is given (it tries to do its own\n    # test discovery, which is incompatible with auto2to3), so don't\n    # set module if we're not asking for a specific test.\n    if len(argv) > 1:\n        unittest.main(module=None, argv=argv, **kwargs)  # type: ignore\n    else:\n        unittest.main(defaultTest=\"all\", argv=argv, **kwargs)",
      "importString": "from collections.abc import Generator\nimport functools\nimport inspect\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\nimport unittest\nimport warnings\n\nfrom tornado import gen\nfrom tornado.httpclient import AsyncHTTPClient, HTTPResponse\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop, TimeoutError\nfrom tornado import netutil\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nfrom tornado.process import Subprocess\nfrom tornado.log import app_log\nfrom tornado.util import raise_exc_info, basestring_type\nfrom tornado.web import Application\n\nimport typing\nfrom typing import Tuple, Any, Callable, Type, Dict, Union, Optional, Coroutine\nfrom types import TracebackType",
      "lineNum": 89,
      "relativeDocumentPath": "tornado/testing.py"
    },
    {
      "symbolName": "decompress",
      "sourceCode": "def decompress(self, value: bytes, max_length: int = 0) -> bytes:\n        \"\"\"Decompress a chunk, returning newly-available data.\n\n        Some data may be buffered for later processing; `flush` must\n        be called when there is no more input data to ensure that\n        all data was processed.\n\n        If ``max_length`` is given, some input data may be left over\n        in ``unconsumed_tail``; you must retrieve this value and pass\n        it back to a future call to `decompress` if it is not empty.\n        \"\"\"\n        return self.decompressobj.decompress(value, max_length)",
      "importString": "import array\nfrom inspect import getfullargspec\nimport os\nimport re\nimport typing\nimport zlib\nfrom typing import (\nAny\nOptional\nDict\nMapping\nList\nTuple\nMatch\nCallable\nType\nSequence\n)",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/util.py"
    },
    {
      "symbolName": "import_object",
      "sourceCode": "def import_object(name: str) -> Any:\n    \"\"\"Imports an object by name.\n\n    ``import_object('x')`` is equivalent to ``import x``.\n    ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n\n    >>> import tornado.escape\n    >>> import_object('tornado.escape') is tornado.escape\n    True\n    >>> import_object('tornado.escape.utf8') is tornado.escape.utf8\n    True\n    >>> import_object('tornado') is tornado\n    True\n    >>> import_object('tornado.missing_module')\n    Traceback (most recent call last):\n        ...\n    ImportError: No module named missing_module\n    \"\"\"\n    if name.count(\".\") == 0:\n        return __import__(name)\n\n    parts = name.split(\".\")\n    obj = __import__(\".\".join(parts[:-1]), fromlist=[parts[-1]])\n    try:\n        return getattr(obj, parts[-1])\n    except AttributeError:\n        raise ImportError(\"No module named %s\" % parts[-1])",
      "importString": "import array\nfrom inspect import getfullargspec\nimport os\nimport re\nimport typing\nimport zlib\nfrom typing import (\nAny\nOptional\nDict\nMapping\nList\nTuple\nMatch\nCallable\nType\nSequence\n)",
      "lineNum": 26,
      "relativeDocumentPath": "tornado/util.py"
    },
    {
      "symbolName": "raise_exc_info",
      "sourceCode": "def raise_exc_info(\n    exc_info: Tuple[Optional[type], Optional[BaseException], Optional[\"TracebackType\"]],\n) -> typing.NoReturn:\n    try:\n        if exc_info[1] is not None:\n            raise exc_info[1].with_traceback(exc_info[2])\n        else:\n            raise TypeError(\"raise_exc_info called with no exception\")\n    finally:\n        # Clear the traceback reference from our stack frame to\n        # minimize circular references that slow down GC.\n        exc_info = (None, None, None)",
      "importString": "import array\nfrom inspect import getfullargspec\nimport os\nimport re\nimport typing\nimport zlib\nfrom typing import (\nAny\nOptional\nDict\nMapping\nList\nTuple\nMatch\nCallable\nType\nSequence\n)",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/util.py"
    },
    {
      "symbolName": "errno_from_exception",
      "sourceCode": "def errno_from_exception(e: BaseException) -> Optional[int]:\n    \"\"\"Provides the errno from an Exception object.\n\n    There are cases that the errno attribute was not set so we pull\n    the errno out of the args but if someone instantiates an Exception\n    without any args you will get a tuple error. So this function\n    abstracts all that behavior to give you a safe way to get the\n    errno.\n    \"\"\"\n\n    if hasattr(e, \"errno\"):\n        return e.errno  # type: ignore\n    elif e.args:\n        return e.args[0]\n    else:\n        return None",
      "importString": "import array\nfrom inspect import getfullargspec\nimport os\nimport re\nimport typing\nimport zlib\nfrom typing import (\nAny\nOptional\nDict\nMapping\nList\nTuple\nMatch\nCallable\nType\nSequence\n)",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/util.py"
    },
    {
      "symbolName": "__new__",
      "sourceCode": "def __new__(cls, *args: Any, **kwargs: Any) -> Any:\n        base = cls.configurable_base()\n        init_kwargs = {}  # type: Dict[str, Any]\n        if cls is base:\n            impl = cls.configured_class()\n            if base.__impl_kwargs:\n                init_kwargs.update(base.__impl_kwargs)\n        else:\n            impl = cls\n        init_kwargs.update(kwargs)\n        if impl.configurable_base() is not base:\n            # The impl class is itself configurable, so recurse.\n            return impl(*args, **init_kwargs)\n        instance = super().__new__(impl)\n        # initialize vs __init__ chosen for compatibility with AsyncHTTPClient\n        # singleton magic.  If we get rid of that we can switch to __init__\n        # here too.\n        instance.initialize(*args, **init_kwargs)\n        return instance",
      "importString": "import array\nfrom inspect import getfullargspec\nimport os\nimport re\nimport typing\nimport zlib\nfrom typing import (\nAny\nOptional\nDict\nMapping\nList\nTuple\nMatch\nCallable\nType\nSequence\n)",
      "lineNum": 18,
      "relativeDocumentPath": "tornado/util.py"
    },
    {
      "symbolName": "configurable_base",
      "sourceCode": "@classmethod\n    def configurable_base(cls):\n        # type: () -> Type[Configurable]\n        \"\"\"Returns the base class of a configurable hierarchy.\n\n        This will normally return the class in which it is defined.\n        (which is *not* necessarily the same as the ``cls`` classmethod\n        parameter).\n\n        \"\"\"\n        raise NotImplementedError()",
      "importString": "import array\nfrom inspect import getfullargspec\nimport os\nimport re\nimport typing\nimport zlib\nfrom typing import (\nAny\nOptional\nDict\nMapping\nList\nTuple\nMatch\nCallable\nType\nSequence\n)",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/util.py"
    },
    {
      "symbolName": "configure",
      "sourceCode": "@classmethod\n    def configure(cls, impl, **kwargs):\n        # type: (Union[None, str, Type[Configurable]], Any) -> None\n        \"\"\"Sets the class to use when the base class is instantiated.\n\n        Keyword arguments will be saved and added to the arguments passed\n        to the constructor.  This can be used to set global defaults for\n        some parameters.\n        \"\"\"\n        base = cls.configurable_base()\n        if isinstance(impl, str):\n            impl = typing.cast(Type[Configurable], import_object(impl))\n        if impl is not None and not issubclass(impl, cls):\n            raise ValueError(\"Invalid subclass of %s\" % cls)\n        base.__impl_class = impl\n        base.__impl_kwargs = kwargs",
      "importString": "import array\nfrom inspect import getfullargspec\nimport os\nimport re\nimport typing\nimport zlib\nfrom typing import (\nAny\nOptional\nDict\nMapping\nList\nTuple\nMatch\nCallable\nType\nSequence\n)",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/util.py"
    },
    {
      "symbolName": "configured_class",
      "sourceCode": "@classmethod\n    def configured_class(cls):\n        # type: () -> Type[Configurable]\n        \"\"\"Returns the currently configured class.\"\"\"\n        base = cls.configurable_base()\n        # Manually mangle the private name to see whether this base\n        # has been configured (and not another base higher in the\n        # hierarchy).\n        if base.__dict__.get(\"_Configurable__impl_class\") is None:\n            base.__impl_class = cls.configurable_default()\n        if base.__impl_class is not None:\n            return base.__impl_class\n        else:\n            # Should be impossible, but mypy wants an explicit check.\n            raise ValueError(\"configured class not found\")",
      "importString": "import array\nfrom inspect import getfullargspec\nimport os\nimport re\nimport typing\nimport zlib\nfrom typing import (\nAny\nOptional\nDict\nMapping\nList\nTuple\nMatch\nCallable\nType\nSequence\n)",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/util.py"
    },
    {
      "symbolName": "_getargnames",
      "sourceCode": "def _getargnames(self, func: Callable) -> List[str]:\n        try:\n            return getfullargspec(func).args\n        except TypeError:\n            if hasattr(func, \"func_code\"):\n                # Cython-generated code has all the attributes needed\n                # by inspect.getfullargspec, but the inspect module only\n                # works with ordinary functions. Inline the portion of\n                # getfullargspec that we need here. Note that for static\n                # functions the @cython.binding(True) decorator must\n                # be used (for methods it works out of the box).\n                code = func.func_code  # type: ignore\n                return code.co_varnames[: code.co_argcount]\n            raise",
      "importString": "import array\nfrom inspect import getfullargspec\nimport os\nimport re\nimport typing\nimport zlib\nfrom typing import (\nAny\nOptional\nDict\nMapping\nList\nTuple\nMatch\nCallable\nType\nSequence\n)",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/util.py"
    },
    {
      "symbolName": "get_old_value",
      "sourceCode": "def get_old_value(\n        self, args: Sequence[Any], kwargs: Dict[str, Any], default: Any = None\n    ) -> Any:\n        \"\"\"Returns the old value of the named argument without replacing it.\n\n        Returns ``default`` if the argument is not present.\n        \"\"\"\n        if self.arg_pos is not None and len(args) > self.arg_pos:\n            return args[self.arg_pos]\n        else:\n            return kwargs.get(self.name, default)",
      "importString": "import array\nfrom inspect import getfullargspec\nimport os\nimport re\nimport typing\nimport zlib\nfrom typing import (\nAny\nOptional\nDict\nMapping\nList\nTuple\nMatch\nCallable\nType\nSequence\n)",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/util.py"
    },
    {
      "symbolName": "replace",
      "sourceCode": "def replace(\n        self, new_value: Any, args: Sequence[Any], kwargs: Dict[str, Any]\n    ) -> Tuple[Any, Sequence[Any], Dict[str, Any]]:\n        \"\"\"Replace the named argument in ``args, kwargs`` with ``new_value``.\n\n        Returns ``(old_value, args, kwargs)``.  The returned ``args`` and\n        ``kwargs`` objects may not be the same as the input objects, or\n        the input objects may be mutated.\n\n        If the named argument was not found, ``new_value`` will be added\n        to ``kwargs`` and None will be returned as ``old_value``.\n        \"\"\"\n        if self.arg_pos is not None and len(args) > self.arg_pos:\n            # The arg to replace is passed positionally\n            old_value = args[self.arg_pos]\n            args = list(args)  # *args is normally a tuple\n            args[self.arg_pos] = new_value\n        else:\n            # The arg to replace is either omitted or passed by keyword.\n            old_value = kwargs.get(self.name)\n            kwargs[self.name] = new_value\n        return old_value, args, kwargs",
      "importString": "import array\nfrom inspect import getfullargspec\nimport os\nimport re\nimport typing\nimport zlib\nfrom typing import (\nAny\nOptional\nDict\nMapping\nList\nTuple\nMatch\nCallable\nType\nSequence\n)",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/util.py"
    },
    {
      "symbolName": "_websocket_mask_python",
      "sourceCode": "def _websocket_mask_python(mask: bytes, data: bytes) -> bytes:\n    \"\"\"Websocket masking function.\n\n    `mask` is a `bytes` object of length 4; `data` is a `bytes` object of any length.\n    Returns a `bytes` object of the same length as `data` with the mask applied\n    as specified in section 5.3 of RFC 6455.\n\n    This pure-python implementation may be replaced by an optimized version when available.\n    \"\"\"\n    mask_arr = array.array(\"B\", mask)\n    unmasked_arr = array.array(\"B\", data)\n    for i in range(len(data)):\n        unmasked_arr[i] = unmasked_arr[i] ^ mask_arr[i % 4]\n    return unmasked_arr.tobytes()",
      "importString": "import array\nfrom inspect import getfullargspec\nimport os\nimport re\nimport typing\nimport zlib\nfrom typing import (\nAny\nOptional\nDict\nMapping\nList\nTuple\nMatch\nCallable\nType\nSequence\n)",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/util.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        application: \"Application\",\n        request: httputil.HTTPServerRequest,\n        **kwargs: Any,\n    ) -> None:\n        super().__init__()\n\n        self.application = application\n        self.request = request\n        self._headers_written = False\n        self._finished = False\n        self._auto_finish = True\n        self._prepared_future = None\n        self.ui = ObjectDict(\n            (n, self._ui_method(m)) for n, m in application.ui_methods.items()\n        )\n        # UIModules are available as both `modules` and `_tt_modules` in the\n        # template namespace.  Historically only `modules` was available\n        # but could be clobbered by user additions to the namespace.\n        # The template {% module %} directive looks in `_tt_modules` to avoid\n        # possible conflicts.\n        self.ui[\"_tt_modules\"] = _UIModuleNamespace(self, application.ui_modules)\n        self.ui[\"modules\"] = self.ui[\"_tt_modules\"]\n        self.clear()\n        assert self.request.connection is not None\n        # TODO: need to add set_close_callback to HTTPConnection interface\n        self.request.connection.set_close_callback(  # type: ignore\n            self.on_connection_close\n        )\n        self.initialize(**kwargs)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 30,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "prepare",
      "sourceCode": "def prepare(self) -> Optional[Awaitable[None]]:\n        \"\"\"Called at the beginning of a request before  `get`/`post`/etc.\n\n        Override this method to perform common initialization regardless\n        of the request method. There is no guarantee that ``prepare`` will\n        be called if an error occurs that is handled by the framework.\n\n        Asynchronous support: Use ``async def`` or decorate this method with\n        `.gen.coroutine` to make it asynchronous.\n        If this method returns an  ``Awaitable`` execution will not proceed\n        until the ``Awaitable`` is done.\n\n        .. versionadded:: 3.1\n           Asynchronous support.\n        \"\"\"\n        pass",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "on_finish",
      "sourceCode": "def on_finish(self) -> None:\n        \"\"\"Called after the end of a request.\n\n        Override this method to perform cleanup, logging, etc. This method is primarily intended as\n        a counterpart to `prepare`. However, there are a few error cases where ``on_finish`` may be\n        called when ``prepare`` has not. (These are considered bugs and may be fixed in the future,\n        but for now you may need to check to see if the initialization work done in ``prepare`` has\n        occurred)\n\n        ``on_finish`` may not produce any output, as it is called after the response has been sent\n        to the client.\n        \"\"\"\n        pass",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "on_connection_close",
      "sourceCode": "def on_connection_close(self) -> None:\n        \"\"\"Called in async handlers if the client closed the connection.\n\n        Override this to clean up resources associated with\n        long-lived connections.  Note that this method is called only if\n        the connection was closed during asynchronous processing; if you\n        need to do cleanup after every request override `on_finish`\n        instead.\n\n        Proxies may keep a connection open for a time (perhaps\n        indefinitely) after the client has gone away, so this method\n        may not be called promptly after the end user closes their\n        connection.\n        \"\"\"\n        if _has_stream_request_body(self.__class__):\n            if not self.request._body_future.done():\n                self.request._body_future.set_exception(iostream.StreamClosedError())\n                self.request._body_future.exception()",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 17,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "clear",
      "sourceCode": "def clear(self) -> None:\n        \"\"\"Resets all headers and content for this response.\"\"\"\n        self._headers = httputil.HTTPHeaders(\n            {\n                \"Server\": \"TornadoServer/%s\" % tornado.version,\n                \"Content-Type\": \"text/html; charset=UTF-8\",\n                \"Date\": httputil.format_timestamp(time.time()),\n            }\n        )\n        self.set_default_headers()\n        self._write_buffer = []  # type: List[bytes]\n        self._status_code = 200\n        self._reason = httputil.responses[200]",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "set_status",
      "sourceCode": "def set_status(self, status_code: int, reason: Optional[str] = None) -> None:\n        \"\"\"Sets the status code for our response.\n\n        :arg int status_code: Response status code.\n        :arg str reason: Human-readable reason phrase describing the status\n            code. If ``None``, it will be filled in from\n            `http.client.responses` or \"Unknown\".\n\n        .. versionchanged:: 5.0\n\n           No longer validates that the response code is in\n           `http.client.responses`.\n        \"\"\"\n        self._status_code = status_code\n        if reason is not None:\n            self._reason = escape.native_str(reason)\n        else:\n            self._reason = httputil.responses.get(status_code, \"Unknown\")",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 17,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "_convert_header_value",
      "sourceCode": "def _convert_header_value(self, value: _HeaderTypes) -> str:\n        # Convert the input value to a str. This type check is a bit\n        # subtle: The bytes case only executes on python 3, and the\n        # unicode case only executes on python 2, because the other\n        # cases are covered by the first match for str.\n        if isinstance(value, str):\n            retval = value\n        elif isinstance(value, bytes):\n            # Non-ascii characters in headers are not well supported,\n            # but if you pass bytes, use latin1 so they pass through as-is.\n            retval = value.decode(\"latin1\")\n        elif isinstance(value, numbers.Integral):\n            # return immediately since we know the converted value will be safe\n            return str(value)\n        elif isinstance(value, datetime.datetime):\n            return httputil.format_timestamp(value)\n        else:\n            raise TypeError(\"Unsupported header value %r\" % value)\n        # If \\n is allowed into the header, it is possible to inject\n        # additional headers or split the request.\n        if RequestHandler._VALID_HEADER_CHARS.fullmatch(retval) is None:\n            raise ValueError(\"Unsafe header value %r\", retval)\n        return retval",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 22,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_argument",
      "sourceCode": "def get_argument(  # noqa: F811\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the request more than once, we return the\n        last value.\n\n        This method searches both the query and body arguments.\n        \"\"\"\n        return self._get_argument(name, default, self.request.arguments, strip)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_arguments",
      "sourceCode": "def get_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        This method searches both the query and body arguments.\n        \"\"\"\n\n        # Make sure `get_arguments` isn't accidentally being called with a\n        # positional argument that's assumed to be a default (like in\n        # `get_argument`.)\n        assert isinstance(strip, bool)\n\n        return self._get_arguments(name, self.request.arguments, strip)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_body_argument",
      "sourceCode": "def get_body_argument(  # noqa: F811\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name\n        from the request body.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.body_arguments, strip)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 17,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_query_argument",
      "sourceCode": "def get_query_argument(  # noqa: F811\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name\n        from the request query string.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.query_arguments, strip)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 17,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "_get_argument",
      "sourceCode": "def _get_argument(\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker],\n        source: Dict[str, List[bytes]],\n        strip: bool = True,\n    ) -> Optional[str]:\n        args = self._get_arguments(name, source, strip=strip)\n        if not args:\n            if isinstance(default, _ArgDefaultMarker):\n                raise MissingArgumentError(name)\n            return default\n        return args[-1]",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "_get_arguments",
      "sourceCode": "def _get_arguments(\n        self, name: str, source: Dict[str, List[bytes]], strip: bool = True\n    ) -> List[str]:\n        values = []\n        for v in source.get(name, []):\n            s = self.decode_argument(v, name=name)\n            if isinstance(s, unicode_type):\n                # Get rid of any weird control chars (unless decoding gave\n                # us bytes, in which case leave it alone)\n                s = RequestHandler._remove_control_chars_regex.sub(\" \", s)\n            if strip:\n                s = s.strip()\n            values.append(s)\n        return values",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "decode_argument",
      "sourceCode": "def decode_argument(self, value: bytes, name: Optional[str] = None) -> str:\n        \"\"\"Decodes an argument from the request.\n\n        The argument has been percent-decoded and is now a byte string.\n        By default, this method decodes the argument as utf-8 and returns\n        a unicode string, but this may be overridden in subclasses.\n\n        This method is used as a filter for both `get_argument()` and for\n        values extracted from the url and passed to `get()`/`post()`/etc.\n\n        The name of the argument is provided if known, but may be None\n        (e.g. for unnamed groups in the url regex).\n        \"\"\"\n        try:\n            return _unicode(value)\n        except UnicodeDecodeError:\n            raise HTTPError(\n                400, \"Invalid unicode in {}: {!r}\".format(name or \"url\", value[:40])\n            )",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 18,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_cookie",
      "sourceCode": "def get_cookie(self, name: str, default: Optional[str] = None) -> Optional[str]:\n        \"\"\"Returns the value of the request cookie with the given name.\n\n        If the named cookie is not present, returns ``default``.\n\n        This method only returns cookies that were present in the request.\n        It does not see the outgoing cookies set by `set_cookie` in this\n        handler.\n        \"\"\"\n        if self.request.cookies is not None and name in self.request.cookies:\n            return self.request.cookies[name].value\n        return default",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "set_cookie",
      "sourceCode": "def set_cookie(\n        self,\n        name: str,\n        value: Union[str, bytes],\n        domain: Optional[str] = None,\n        expires: Optional[Union[float, Tuple, datetime.datetime]] = None,\n        path: str = \"/\",\n        expires_days: Optional[float] = None,\n        # Keyword-only args start here for historical reasons.\n        *,\n        max_age: Optional[int] = None,\n        httponly: bool = False,\n        secure: bool = False,\n        samesite: Optional[str] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Sets an outgoing cookie name/value with the given options.\n\n        Newly-set cookies are not immediately visible via `get_cookie`;\n        they are not present until the next request.\n\n        Most arguments are passed directly to `http.cookies.Morsel` directly.\n        See https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Set-Cookie\n        for more information.\n\n        ``expires`` may be a numeric timestamp as returned by `time.time`,\n        a time tuple as returned by `time.gmtime`, or a\n        `datetime.datetime` object. ``expires_days`` is provided as a convenience\n        to set an expiration time in days from today (if both are set, ``expires``\n        is used).\n\n        .. deprecated:: 6.3\n           Keyword arguments are currently accepted case-insensitively.\n           In Tornado 7.0 this will be changed to only accept lowercase\n           arguments.\n        \"\"\"\n        # The cookie library only accepts type str, in both python 2 and 3\n        name = escape.native_str(name)\n        value = escape.native_str(value)\n        if re.search(r\"[\\x00-\\x20]\", name + value):\n            # Don't let us accidentally inject bad stuff\n            raise ValueError(f\"Invalid cookie {name!r}: {value!r}\")\n        if not hasattr(self, \"_new_cookie\"):\n            self._new_cookie = (\n                http.cookies.SimpleCookie()\n            )  # type: http.cookies.SimpleCookie\n        if name in self._new_cookie:\n            del self._new_cookie[name]\n        self._new_cookie[name] = value\n        morsel = self._new_cookie[name]\n        if domain:\n            morsel[\"domain\"] = domain\n        if expires_days is not None and not expires:\n            expires = datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(\n                days=expires_days\n            )\n        if expires:\n            morsel[\"expires\"] = httputil.format_timestamp(expires)\n        if path:\n            morsel[\"path\"] = path\n        if max_age:\n            # Note change from _ to -.\n            morsel[\"max-age\"] = str(max_age)\n        if httponly:\n            # Note that SimpleCookie ignores the value here. The presense of an\n            # httponly (or secure) key is treated as true.\n            morsel[\"httponly\"] = True\n        if secure:\n            morsel[\"secure\"] = True\n        if samesite:\n            morsel[\"samesite\"] = samesite\n        if kwargs:\n            # The setitem interface is case-insensitive, so continue to support\n            # kwargs for backwards compatibility until we can remove deprecated\n            # features.\n            for k, v in kwargs.items():\n                morsel[k] = v\n            warnings.warn(\n                f\"Deprecated arguments to set_cookie: {set(kwargs.keys())} \"\n                \"(should be lowercase)\",\n                DeprecationWarning,\n            )",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 81,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "clear_cookie",
      "sourceCode": "def clear_cookie(self, name: str, **kwargs: Any) -> None:\n        \"\"\"Deletes the cookie with the given name.\n\n        This method accepts the same arguments as `set_cookie`, except for\n        ``expires`` and ``max_age``. Clearing a cookie requires the same\n        ``domain`` and ``path`` arguments as when it was set. In some cases the\n        ``samesite`` and ``secure`` arguments are also required to match. Other\n        arguments are ignored.\n\n        Similar to `set_cookie`, the effect of this method will not be\n        seen until the following request.\n\n        .. versionchanged:: 6.3\n\n           Now accepts all keyword arguments that ``set_cookie`` does.\n           The ``samesite`` and ``secure`` flags have recently become\n           required for clearing ``samesite=\"none\"`` cookies.\n        \"\"\"\n        for excluded_arg in [\"expires\", \"max_age\"]:\n            if excluded_arg in kwargs:\n                raise TypeError(\n                    f\"clear_cookie() got an unexpected keyword argument '{excluded_arg}'\"\n                )\n        expires = datetime.datetime.now(datetime.timezone.utc) - datetime.timedelta(\n            days=365\n        )\n        self.set_cookie(name, value=\"\", expires=expires, **kwargs)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 26,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "clear_all_cookies",
      "sourceCode": "def clear_all_cookies(self, **kwargs: Any) -> None:\n        \"\"\"Attempt to delete all the cookies the user sent with this request.\n\n        See `clear_cookie` for more information on keyword arguments. Due to\n        limitations of the cookie protocol, it is impossible to determine on the\n        server side which values are necessary for the ``domain``, ``path``,\n        ``samesite``, or ``secure`` arguments, this method can only be\n        successful if you consistently use the same values for these arguments\n        when setting cookies.\n\n        Similar to `set_cookie`, the effect of this method will not be seen\n        until the following request.\n\n        .. versionchanged:: 3.2\n\n           Added the ``path`` and ``domain`` parameters.\n\n        .. versionchanged:: 6.3\n\n           Now accepts all keyword arguments that ``set_cookie`` does.\n\n        .. deprecated:: 6.3\n\n           The increasingly complex rules governing cookies have made it\n           impossible for a ``clear_all_cookies`` method to work reliably\n           since all we know about cookies are their names. Applications\n           should generally use ``clear_cookie`` one at a time instead.\n        \"\"\"\n        for name in self.request.cookies:\n            self.clear_cookie(name, **kwargs)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 29,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "set_signed_cookie",
      "sourceCode": "def set_signed_cookie(\n        self,\n        name: str,\n        value: Union[str, bytes],\n        expires_days: Optional[float] = 30,\n        version: Optional[int] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Signs and timestamps a cookie so it cannot be forged.\n\n        You must specify the ``cookie_secret`` setting in your Application\n        to use this method. It should be a long, random sequence of bytes\n        to be used as the HMAC secret for the signature.\n\n        To read a cookie set with this method, use `get_signed_cookie()`.\n\n        Note that the ``expires_days`` parameter sets the lifetime of the\n        cookie in the browser, but is independent of the ``max_age_days``\n        parameter to `get_signed_cookie`.\n        A value of None limits the lifetime to the current browser session.\n\n        Secure cookies may contain arbitrary byte values, not just unicode\n        strings (unlike regular cookies)\n\n        Similar to `set_cookie`, the effect of this method will not be\n        seen until the following request.\n\n        .. versionchanged:: 3.2.1\n\n           Added the ``version`` argument.  Introduced cookie version 2\n           and made it the default.\n\n        .. versionchanged:: 6.3\n\n           Renamed from ``set_secure_cookie`` to ``set_signed_cookie`` to\n           avoid confusion with other uses of \"secure\" in cookie attributes\n           and prefixes. The old name remains as an alias.\n        \"\"\"\n        self.set_cookie(\n            name,\n            self.create_signed_value(name, value, version=version),\n            expires_days=expires_days,\n            **kwargs,\n        )",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 43,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "create_signed_value",
      "sourceCode": "def create_signed_value(\n        self, name: str, value: Union[str, bytes], version: Optional[int] = None\n    ) -> bytes:\n        \"\"\"Signs and timestamps a string so it cannot be forged.\n\n        Normally used via set_signed_cookie, but provided as a separate\n        method for non-cookie uses.  To decode a value not stored\n        as a cookie use the optional value argument to get_signed_cookie.\n\n        .. versionchanged:: 3.2.1\n\n           Added the ``version`` argument.  Introduced cookie version 2\n           and made it the default.\n        \"\"\"\n        self.require_setting(\"cookie_secret\", \"secure cookies\")\n        secret = self.application.settings[\"cookie_secret\"]\n        key_version = None\n        if isinstance(secret, dict):\n            if self.application.settings.get(\"key_version\") is None:\n                raise Exception(\"key_version setting must be used for secret_key dicts\")\n            key_version = self.application.settings[\"key_version\"]\n\n        return create_signed_value(\n            secret, name, value, version=version, key_version=key_version\n        )",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 24,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_signed_cookie",
      "sourceCode": "def get_signed_cookie(\n        self,\n        name: str,\n        value: Optional[str] = None,\n        max_age_days: float = 31,\n        min_version: Optional[int] = None,\n    ) -> Optional[bytes]:\n        \"\"\"Returns the given signed cookie if it validates, or None.\n\n        The decoded cookie value is returned as a byte string (unlike\n        `get_cookie`).\n\n        Similar to `get_cookie`, this method only returns cookies that\n        were present in the request. It does not see outgoing cookies set by\n        `set_signed_cookie` in this handler.\n\n        .. versionchanged:: 3.2.1\n\n           Added the ``min_version`` argument.  Introduced cookie version 2;\n           both versions 1 and 2 are accepted by default.\n\n         .. versionchanged:: 6.3\n\n           Renamed from ``get_secure_cookie`` to ``get_signed_cookie`` to\n           avoid confusion with other uses of \"secure\" in cookie attributes\n           and prefixes. The old name remains as an alias.\n\n        \"\"\"\n        self.require_setting(\"cookie_secret\", \"secure cookies\")\n        if value is None:\n            value = self.get_cookie(name)\n        return decode_signed_value(\n            self.application.settings[\"cookie_secret\"],\n            name,\n            value,\n            max_age_days=max_age_days,\n            min_version=min_version,\n        )",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 37,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_signed_cookie_key_version",
      "sourceCode": "def get_signed_cookie_key_version(\n        self, name: str, value: Optional[str] = None\n    ) -> Optional[int]:\n        \"\"\"Returns the signing key version of the secure cookie.\n\n        The version is returned as int.\n\n        .. versionchanged:: 6.3\n\n           Renamed from ``get_secure_cookie_key_version`` to\n           ``set_signed_cookie_key_version`` to avoid confusion with other\n           uses of \"secure\" in cookie attributes and prefixes. The old name\n           remains as an alias.\n\n        \"\"\"\n        self.require_setting(\"cookie_secret\", \"secure cookies\")\n        if value is None:\n            value = self.get_cookie(name)\n        if value is None:\n            return None\n        return get_signature_key_version(value)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "redirect",
      "sourceCode": "def redirect(\n        self, url: str, permanent: bool = False, status: Optional[int] = None\n    ) -> None:\n        \"\"\"Sends a redirect to the given (optionally relative) URL.\n\n        If the ``status`` argument is specified, that value is used as the\n        HTTP status code; otherwise either 301 (permanent) or 302\n        (temporary) is chosen based on the ``permanent`` argument.\n        The default is 302 (temporary).\n        \"\"\"\n        if self._headers_written:\n            raise Exception(\"Cannot redirect after headers have been written\")\n        if status is None:\n            status = 301 if permanent else 302\n        else:\n            assert isinstance(status, int) and 300 <= status <= 399\n        self.set_status(status)\n        self.set_header(\"Location\", utf8(url))\n        self.finish()",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 18,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "write",
      "sourceCode": "def write(self, chunk: Union[str, bytes, dict]) -> None:\n        \"\"\"Writes the given chunk to the output buffer.\n\n        To write the output to the network, use the `flush()` method below.\n\n        If the given chunk is a dictionary, we write it as JSON and set\n        the Content-Type of the response to be ``application/json``.\n        (if you want to send JSON as a different ``Content-Type``, call\n        ``set_header`` *after* calling ``write()``).\n\n        Note that lists are not converted to JSON because of a potential\n        cross-site security vulnerability.  All JSON output should be\n        wrapped in a dictionary.  More details at\n        http://haacked.com/archive/2009/06/25/json-hijacking.aspx/ and\n        https://github.com/facebook/tornado/issues/1009\n        \"\"\"\n        if self._finished:\n            raise RuntimeError(\"Cannot write() after finish()\")\n        if not isinstance(chunk, (bytes, unicode_type, dict)):\n            message = \"write() only accepts bytes, unicode, and dict objects\"\n            if isinstance(chunk, list):\n                message += (\n                    \". Lists not accepted for security reasons; see \"\n                    + \"http://www.tornadoweb.org/en/stable/web.html#tornado.web.RequestHandler.write\"  # noqa: E501\n                )\n            raise TypeError(message)\n        if isinstance(chunk, dict):\n            chunk = escape.json_encode(chunk)\n            self.set_header(\"Content-Type\", \"application/json; charset=UTF-8\")\n        chunk = utf8(chunk)\n        self._write_buffer.append(chunk)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 30,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "render",
      "sourceCode": "def render(self, template_name: str, **kwargs: Any) -> \"Future[None]\":\n        \"\"\"Renders the template with the given arguments as the response.\n\n        ``render()`` calls ``finish()``, so no other output methods can be called\n        after it.\n\n        Returns a `.Future` with the same semantics as the one returned by `finish`.\n        Awaiting this `.Future` is optional.\n\n        .. versionchanged:: 5.1\n\n           Now returns a `.Future` instead of ``None``.\n        \"\"\"\n        if self._finished:\n            raise RuntimeError(\"Cannot render() after finish()\")\n        html = self.render_string(template_name, **kwargs)\n\n        # Insert the additional JS and CSS added by the modules on the page\n        js_embed = []\n        js_files = []\n        css_embed = []\n        css_files = []\n        html_heads = []\n        html_bodies = []\n        for module in getattr(self, \"_active_modules\", {}).values():\n            embed_part = module.embedded_javascript()\n            if embed_part:\n                js_embed.append(utf8(embed_part))\n            file_part = module.javascript_files()\n            if file_part:\n                if isinstance(file_part, (unicode_type, bytes)):\n                    js_files.append(_unicode(file_part))\n                else:\n                    js_files.extend(file_part)\n            embed_part = module.embedded_css()\n            if embed_part:\n                css_embed.append(utf8(embed_part))\n            file_part = module.css_files()\n            if file_part:\n                if isinstance(file_part, (unicode_type, bytes)):\n                    css_files.append(_unicode(file_part))\n                else:\n                    css_files.extend(file_part)\n            head_part = module.html_head()\n            if head_part:\n                html_heads.append(utf8(head_part))\n            body_part = module.html_body()\n            if body_part:\n                html_bodies.append(utf8(body_part))\n\n        if js_files:\n            # Maintain order of JavaScript files given by modules\n            js = self.render_linked_js(js_files)\n            sloc = html.rindex(b\"</body>\")\n            html = html[:sloc] + utf8(js) + b\"\\n\" + html[sloc:]\n        if js_embed:\n            js_bytes = self.render_embed_js(js_embed)\n            sloc = html.rindex(b\"</body>\")\n            html = html[:sloc] + js_bytes + b\"\\n\" + html[sloc:]\n        if css_files:\n            css = self.render_linked_css(css_files)\n            hloc = html.index(b\"</head>\")\n            html = html[:hloc] + utf8(css) + b\"\\n\" + html[hloc:]\n        if css_embed:\n            css_bytes = self.render_embed_css(css_embed)\n            hloc = html.index(b\"</head>\")\n            html = html[:hloc] + css_bytes + b\"\\n\" + html[hloc:]\n        if html_heads:\n            hloc = html.index(b\"</head>\")\n            html = html[:hloc] + b\"\".join(html_heads) + b\"\\n\" + html[hloc:]\n        if html_bodies:\n            hloc = html.index(b\"</body>\")\n            html = html[:hloc] + b\"\".join(html_bodies) + b\"\\n\" + html[hloc:]\n        return self.finish(html)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 73,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "render_linked_js",
      "sourceCode": "def render_linked_js(self, js_files: Iterable[str]) -> str:\n        \"\"\"Default method used to render the final js links for the\n        rendered webpage.\n\n        Override this method in a sub-classed controller to change the output.\n        \"\"\"\n        paths = []\n        unique_paths = set()  # type: Set[str]\n\n        for path in js_files:\n            if not is_absolute(path):\n                path = self.static_url(path)\n            if path not in unique_paths:\n                paths.append(path)\n                unique_paths.add(path)\n\n        return \"\".join(\n            '<script src=\"'\n            + escape.xhtml_escape(p)\n            + '\" type=\"text/javascript\"></script>'\n            for p in paths\n        )",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "render_embed_js",
      "sourceCode": "def render_embed_js(self, js_embed: Iterable[bytes]) -> bytes:\n        \"\"\"Default method used to render the final embedded js for the\n        rendered webpage.\n\n        Override this method in a sub-classed controller to change the output.\n        \"\"\"\n        return (\n            b'<script type=\"text/javascript\">\\n//<![CDATA[\\n'\n            + b\"\\n\".join(js_embed)\n            + b\"\\n//]]>\\n</script>\"\n        )",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "render_linked_css",
      "sourceCode": "def render_linked_css(self, css_files: Iterable[str]) -> str:\n        \"\"\"Default method used to render the final css links for the\n        rendered webpage.\n\n        Override this method in a sub-classed controller to change the output.\n        \"\"\"\n        paths = []\n        unique_paths = set()  # type: Set[str]\n\n        for path in css_files:\n            if not is_absolute(path):\n                path = self.static_url(path)\n            if path not in unique_paths:\n                paths.append(path)\n                unique_paths.add(path)\n\n        return \"\".join(\n            '<link href=\"' + escape.xhtml_escape(p) + '\" '\n            'type=\"text/css\" rel=\"stylesheet\"/>'\n            for p in paths\n        )",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "render_string",
      "sourceCode": "def render_string(self, template_name: str, **kwargs: Any) -> bytes:\n        \"\"\"Generate the given template with the given arguments.\n\n        We return the generated byte string (in utf8). To generate and\n        write a template as a response, use render() above.\n        \"\"\"\n        # If no template_path is specified, use the path of the calling file\n        template_path = self.get_template_path()\n        if not template_path:\n            frame = sys._getframe(0)\n            web_file = frame.f_code.co_filename\n            while frame.f_code.co_filename == web_file and frame.f_back is not None:\n                frame = frame.f_back\n            assert frame.f_code.co_filename is not None\n            template_path = os.path.dirname(frame.f_code.co_filename)\n        with RequestHandler._template_loader_lock:\n            if template_path not in RequestHandler._template_loaders:\n                loader = self.create_template_loader(template_path)\n                RequestHandler._template_loaders[template_path] = loader\n            else:\n                loader = RequestHandler._template_loaders[template_path]\n        t = loader.load(template_name)\n        namespace = self.get_template_namespace()\n        namespace.update(kwargs)\n        return t.generate(**namespace)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 24,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_template_namespace",
      "sourceCode": "def get_template_namespace(self) -> Dict[str, Any]:\n        \"\"\"Returns a dictionary to be used as the default template namespace.\n\n        May be overridden by subclasses to add or modify values.\n\n        The results of this method will be combined with additional\n        defaults in the `tornado.template` module and keyword arguments\n        to `render` or `render_string`.\n        \"\"\"\n        namespace = dict(\n            handler=self,\n            request=self.request,\n            current_user=self.current_user,\n            locale=self.locale,\n            _=self.locale.translate,\n            pgettext=self.locale.pgettext,\n            static_url=self.static_url,\n            xsrf_form_html=self.xsrf_form_html,\n            reverse_url=self.reverse_url,\n        )\n        namespace.update(self.ui)\n        return namespace",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 21,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "create_template_loader",
      "sourceCode": "def create_template_loader(self, template_path: str) -> template.BaseLoader:\n        \"\"\"Returns a new template loader for the given path.\n\n        May be overridden by subclasses.  By default returns a\n        directory-based loader on the given path, using the\n        ``autoescape`` and ``template_whitespace`` application\n        settings.  If a ``template_loader`` application setting is\n        supplied, uses that instead.\n        \"\"\"\n        settings = self.application.settings\n        if \"template_loader\" in settings:\n            return settings[\"template_loader\"]\n        kwargs = {}\n        if \"autoescape\" in settings:\n            # autoescape=None means \"no escaping\", so we have to be sure\n            # to only pass this kwarg if the user asked for it.\n            kwargs[\"autoescape\"] = settings[\"autoescape\"]\n        if \"template_whitespace\" in settings:\n            kwargs[\"whitespace\"] = settings[\"template_whitespace\"]\n        return template.Loader(template_path, **kwargs)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 19,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "flush",
      "sourceCode": "def flush(self, include_footers: bool = False) -> \"Future[None]\":\n        \"\"\"Flushes the current output buffer to the network.\n\n        .. versionchanged:: 4.0\n           Now returns a `.Future` if no callback is given.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed.\n        \"\"\"\n        assert self.request.connection is not None\n        chunk = b\"\".join(self._write_buffer)\n        self._write_buffer = []\n        if not self._headers_written:\n            self._headers_written = True\n            for transform in self._transforms:\n                assert chunk is not None\n                (\n                    self._status_code,\n                    self._headers,\n                    chunk,\n                ) = transform.transform_first_chunk(\n                    self._status_code, self._headers, chunk, include_footers\n                )\n            # Ignore the chunk and only write the headers for HEAD requests\n            if self.request.method == \"HEAD\":\n                chunk = b\"\"\n\n            # Finalize the cookie headers (which have been stored in a side\n            # object so an outgoing cookie could be overwritten before it\n            # is sent).\n            if hasattr(self, \"_new_cookie\"):\n                for cookie in self._new_cookie.values():\n                    self.add_header(\"Set-Cookie\", cookie.OutputString(None))\n\n            start_line = httputil.ResponseStartLine(\"\", self._status_code, self._reason)\n            return self.request.connection.write_headers(\n                start_line, self._headers, chunk\n            )\n        else:\n            for transform in self._transforms:\n                chunk = transform.transform_chunk(chunk, include_footers)\n            # Ignore the chunk and only write the headers for HEAD requests\n            if self.request.method != \"HEAD\":\n                return self.request.connection.write(chunk)\n            else:\n                future = Future()  # type: Future[None]\n                future.set_result(None)\n                return future",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 48,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "finish",
      "sourceCode": "def finish(self, chunk: Optional[Union[str, bytes, dict]] = None) -> \"Future[None]\":\n        \"\"\"Finishes this response, ending the HTTP request.\n\n        Passing a ``chunk`` to ``finish()`` is equivalent to passing that\n        chunk to ``write()`` and then calling ``finish()`` with no arguments.\n\n        Returns a `.Future` which may optionally be awaited to track the sending\n        of the response to the client. This `.Future` resolves when all the response\n        data has been sent, and raises an error if the connection is closed before all\n        data can be sent.\n\n        .. versionchanged:: 5.1\n\n           Now returns a `.Future` instead of ``None``.\n        \"\"\"\n        if self._finished:\n            raise RuntimeError(\"finish() called twice\")\n\n        if chunk is not None:\n            self.write(chunk)\n\n        # Automatically support ETags and add the Content-Length header if\n        # we have not flushed any content yet.\n        if not self._headers_written:\n            if (\n                self._status_code == 200\n                and self.request.method in (\"GET\", \"HEAD\")\n                and \"Etag\" not in self._headers\n            ):\n                self.set_etag_header()\n                if self.check_etag_header():\n                    self._write_buffer = []\n                    self.set_status(304)\n            if self._status_code in (204, 304) or (100 <= self._status_code < 200):\n                assert not self._write_buffer, (\n                    \"Cannot send body with %s\" % self._status_code\n                )\n                self._clear_representation_headers()\n            elif \"Content-Length\" not in self._headers:\n                content_length = sum(len(part) for part in self._write_buffer)\n                self.set_header(\"Content-Length\", content_length)\n\n        assert self.request.connection is not None\n        # Now that the request is finished, clear the callback we\n        # set on the HTTPConnection (which would otherwise prevent the\n        # garbage collection of the RequestHandler when there\n        # are keepalive connections)\n        self.request.connection.set_close_callback(None)  # type: ignore\n\n        future = self.flush(include_footers=True)\n        self.request.connection.finish()\n        self._log()\n        self._finished = True\n        self.on_finish()\n        self._break_cycles()\n        return future",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 55,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "detach",
      "sourceCode": "def detach(self) -> iostream.IOStream:\n        \"\"\"Take control of the underlying stream.\n\n        Returns the underlying `.IOStream` object and stops all\n        further HTTP processing. Intended for implementing protocols\n        like websockets that tunnel over an HTTP handshake.\n\n        This method is only supported when HTTP/1.1 is used.\n\n        .. versionadded:: 5.1\n        \"\"\"\n        self._finished = True\n        # TODO: add detach to HTTPConnection?\n        return self.request.connection.detach()",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "send_error",
      "sourceCode": "def send_error(self, status_code: int = 500, **kwargs: Any) -> None:\n        \"\"\"Sends the given HTTP error code to the browser.\n\n        If `flush()` has already been called, it is not possible to send\n        an error, so this method will simply terminate the response.\n        If output has been written but not yet flushed, it will be discarded\n        and replaced with the error page.\n\n        Override `write_error()` to customize the error page that is returned.\n        Additional keyword arguments are passed through to `write_error`.\n        \"\"\"\n        if self._headers_written:\n            gen_log.error(\"Cannot send error response after headers written\")\n            if not self._finished:\n                # If we get an error between writing headers and finishing,\n                # we are unlikely to be able to finish due to a\n                # Content-Length mismatch. Try anyway to release the\n                # socket.\n                try:\n                    self.finish()\n                except Exception:\n                    gen_log.error(\"Failed to flush partial response\", exc_info=True)\n            return\n        self.clear()\n\n        reason = kwargs.get(\"reason\")\n        if \"exc_info\" in kwargs:\n            exception = kwargs[\"exc_info\"][1]\n            if isinstance(exception, HTTPError) and exception.reason:\n                reason = exception.reason\n        self.set_status(status_code, reason=reason)\n        try:\n            self.write_error(status_code, **kwargs)\n        except Exception:\n            app_log.error(\"Uncaught exception in write_error\", exc_info=True)\n        if not self._finished:\n            self.finish()",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 36,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "write_error",
      "sourceCode": "def write_error(self, status_code: int, **kwargs: Any) -> None:\n        \"\"\"Override to implement custom error pages.\n\n        ``write_error`` may call `write`, `render`, `set_header`, etc\n        to produce output as usual.\n\n        If this error was caused by an uncaught exception (including\n        HTTPError), an ``exc_info`` triple will be available as\n        ``kwargs[\"exc_info\"]``.  Note that this exception may not be\n        the \"current\" exception for purposes of methods like\n        ``sys.exc_info()`` or ``traceback.format_exc``.\n        \"\"\"\n        if self.settings.get(\"serve_traceback\") and \"exc_info\" in kwargs:\n            # in debug mode, try to send a traceback\n            self.set_header(\"Content-Type\", \"text/plain\")\n            for line in traceback.format_exception(*kwargs[\"exc_info\"]):\n                self.write(line)\n            self.finish()\n        else:\n            self.finish(\n                \"<html><title>%(code)d: %(message)s</title>\"\n                \"<body>%(code)d: %(message)s</body></html>\"\n                % {\"code\": status_code, \"message\": self._reason}\n            )",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 23,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_browser_locale",
      "sourceCode": "def get_browser_locale(self, default: str = \"en_US\") -> tornado.locale.Locale:\n        \"\"\"Determines the user's locale from ``Accept-Language`` header.\n\n        See http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.4\n        \"\"\"\n        if \"Accept-Language\" in self.request.headers:\n            languages = self.request.headers[\"Accept-Language\"].split(\",\")\n            locales = []\n            for language in languages:\n                parts = language.strip().split(\";\")\n                if len(parts) > 1 and parts[1].strip().startswith(\"q=\"):\n                    try:\n                        score = float(parts[1].strip()[2:])\n                        if score < 0:\n                            raise ValueError()\n                    except (ValueError, TypeError):\n                        score = 0.0\n                else:\n                    score = 1.0\n                if score > 0:\n                    locales.append((parts[0], score))\n            if locales:\n                locales.sort(key=lambda pair: pair[1], reverse=True)\n                codes = [loc[0] for loc in locales]\n                return locale.get(*codes)\n        return locale.get(default)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 25,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "xsrf_token",
      "sourceCode": "@property\n    def xsrf_token(self) -> bytes:\n        \"\"\"The XSRF-prevention token for the current user/session.\n\n        To prevent cross-site request forgery, we set an '_xsrf' cookie\n        and include the same '_xsrf' value as an argument with all POST\n        requests. If the two do not match, we reject the form submission\n        as a potential forgery.\n\n        See http://en.wikipedia.org/wiki/Cross-site_request_forgery\n\n        This property is of type `bytes`, but it contains only ASCII\n        characters. If a character string is required, there is no\n        need to base64-encode it; just decode the byte string as\n        UTF-8.\n\n        .. versionchanged:: 3.2.2\n           The xsrf token will now be have a random mask applied in every\n           request, which makes it safe to include the token in pages\n           that are compressed.  See http://breachattack.com for more\n           information on the issue fixed by this change.  Old (version 1)\n           cookies will be converted to version 2 when this method is called\n           unless the ``xsrf_cookie_version`` `Application` setting is\n           set to 1.\n\n        .. versionchanged:: 4.3\n           The ``xsrf_cookie_kwargs`` `Application` setting may be\n           used to supply additional cookie options (which will be\n           passed directly to `set_cookie`). For example,\n           ``xsrf_cookie_kwargs=dict(httponly=True, secure=True)``\n           will set the ``secure`` and ``httponly`` flags on the\n           ``_xsrf`` cookie.\n        \"\"\"\n        if not hasattr(self, \"_xsrf_token\"):\n            version, token, timestamp = self._get_raw_xsrf_token()\n            output_version = self.settings.get(\"xsrf_cookie_version\", 2)\n            cookie_kwargs = self.settings.get(\"xsrf_cookie_kwargs\", {})\n            if output_version == 1:\n                self._xsrf_token = binascii.b2a_hex(token)\n            elif output_version == 2:\n                mask = os.urandom(4)\n                self._xsrf_token = b\"|\".join(\n                    [\n                        b\"2\",\n                        binascii.b2a_hex(mask),\n                        binascii.b2a_hex(_websocket_mask(mask, token)),\n                        utf8(str(int(timestamp))),\n                    ]\n                )\n            else:\n                raise ValueError(\"unknown xsrf cookie version %d\", output_version)\n            if version is None:\n                if self.current_user and \"expires_days\" not in cookie_kwargs:\n                    cookie_kwargs[\"expires_days\"] = 30\n                cookie_name = self.settings.get(\"xsrf_cookie_name\", \"_xsrf\")\n                self.set_cookie(cookie_name, self._xsrf_token, **cookie_kwargs)\n        return self._xsrf_token",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 56,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "_get_raw_xsrf_token",
      "sourceCode": "def _get_raw_xsrf_token(self) -> Tuple[Optional[int], bytes, float]:\n        \"\"\"Read or generate the xsrf token in its raw form.\n\n        The raw_xsrf_token is a tuple containing:\n\n        * version: the version of the cookie from which this token was read,\n          or None if we generated a new token in this request.\n        * token: the raw token data; random (non-ascii) bytes.\n        * timestamp: the time this token was generated (will not be accurate\n          for version 1 cookies)\n        \"\"\"\n        if not hasattr(self, \"_raw_xsrf_token\"):\n            cookie_name = self.settings.get(\"xsrf_cookie_name\", \"_xsrf\")\n            cookie = self.get_cookie(cookie_name)\n            if cookie:\n                version, token, timestamp = self._decode_xsrf_token(cookie)\n            else:\n                version, token, timestamp = None, None, None\n            if token is None:\n                version = None\n                token = os.urandom(16)\n                timestamp = time.time()\n            assert token is not None\n            assert timestamp is not None\n            self._raw_xsrf_token = (version, token, timestamp)\n        return self._raw_xsrf_token",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 25,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "_decode_xsrf_token",
      "sourceCode": "def _decode_xsrf_token(\n        self, cookie: str\n    ) -> Tuple[Optional[int], Optional[bytes], Optional[float]]:\n        \"\"\"Convert a cookie string into a the tuple form returned by\n        _get_raw_xsrf_token.\n        \"\"\"\n\n        try:\n            m = _signed_value_version_re.match(utf8(cookie))\n\n            if m:\n                version = int(m.group(1))\n                if version == 2:\n                    _, mask_str, masked_token, timestamp_str = cookie.split(\"|\")\n\n                    mask = binascii.a2b_hex(utf8(mask_str))\n                    token = _websocket_mask(mask, binascii.a2b_hex(utf8(masked_token)))\n                    timestamp = int(timestamp_str)\n                    return version, token, timestamp\n                else:\n                    # Treat unknown versions as not present instead of failing.\n                    raise Exception(\"Unknown xsrf cookie version\")\n            else:\n                version = 1\n                try:\n                    token = binascii.a2b_hex(utf8(cookie))\n                except (binascii.Error, TypeError):\n                    token = utf8(cookie)\n                # We don't have a usable timestamp in older versions.\n                timestamp = int(time.time())\n                return (version, token, timestamp)\n        except Exception:\n            # Catch exceptions and return nothing instead of failing.\n            gen_log.debug(\"Uncaught exception in _decode_xsrf_token\", exc_info=True)\n            return None, None, None",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 34,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "check_xsrf_cookie",
      "sourceCode": "def check_xsrf_cookie(self) -> None:\n        \"\"\"Verifies that the ``_xsrf`` cookie matches the ``_xsrf`` argument.\n\n        To prevent cross-site request forgery, we set an ``_xsrf``\n        cookie and include the same value as a non-cookie\n        field with all ``POST`` requests. If the two do not match, we\n        reject the form submission as a potential forgery.\n\n        The ``_xsrf`` value may be set as either a form field named ``_xsrf``\n        or in a custom HTTP header named ``X-XSRFToken`` or ``X-CSRFToken``\n        (the latter is accepted for compatibility with Django).\n\n        See http://en.wikipedia.org/wiki/Cross-site_request_forgery\n\n        .. versionchanged:: 3.2.2\n           Added support for cookie version 2.  Both versions 1 and 2 are\n           supported.\n        \"\"\"\n        # Prior to release 1.1.1, this check was ignored if the HTTP header\n        # ``X-Requested-With: XMLHTTPRequest`` was present.  This exception\n        # has been shown to be insecure and has been removed.  For more\n        # information please see\n        # http://www.djangoproject.com/weblog/2011/feb/08/security/\n        # http://weblog.rubyonrails.org/2011/2/8/csrf-protection-bypass-in-ruby-on-rails\n        input_token = (\n            self.get_argument(\"_xsrf\", None)\n            or self.request.headers.get(\"X-Xsrftoken\")\n            or self.request.headers.get(\"X-Csrftoken\")\n        )\n        if not input_token:\n            raise HTTPError(403, \"'_xsrf' argument missing from POST\")\n        _, token, _ = self._decode_xsrf_token(input_token)\n        _, expected_token, _ = self._get_raw_xsrf_token()\n        if not token:\n            raise HTTPError(403, \"'_xsrf' argument has invalid format\")\n        if not hmac.compare_digest(utf8(token), utf8(expected_token)):\n            raise HTTPError(403, \"XSRF cookie does not match POST argument\")",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 36,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "xsrf_form_html",
      "sourceCode": "def xsrf_form_html(self) -> str:\n        \"\"\"An HTML ``<input/>`` element to be included with all POST forms.\n\n        It defines the ``_xsrf`` input value, which we check on all POST\n        requests to prevent cross-site request forgery. If you have set\n        the ``xsrf_cookies`` application setting, you must include this\n        HTML within all of your HTML forms.\n\n        In a template, this method should be called with ``{% module\n        xsrf_form_html() %}``\n\n        See `check_xsrf_cookie()` above for more information.\n        \"\"\"\n        return (\n            '<input type=\"hidden\" name=\"_xsrf\" value=\"'\n            + escape.xhtml_escape(self.xsrf_token)\n            + '\"/>'\n        )",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 17,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "static_url",
      "sourceCode": "def static_url(\n        self, path: str, include_host: Optional[bool] = None, **kwargs: Any\n    ) -> str:\n        \"\"\"Returns a static URL for the given relative static file path.\n\n        This method requires you set the ``static_path`` setting in your\n        application (which specifies the root directory of your static\n        files).\n\n        This method returns a versioned url (by default appending\n        ``?v=<signature>``), which allows the static files to be\n        cached indefinitely.  This can be disabled by passing\n        ``include_version=False`` (in the default implementation;\n        other static file implementations are not required to support\n        this, but they may support other options).\n\n        By default this method returns URLs relative to the current\n        host, but if ``include_host`` is true the URL returned will be\n        absolute.  If this handler has an ``include_host`` attribute,\n        that value will be used as the default for all `static_url`\n        calls that do not pass ``include_host`` as a keyword argument.\n\n        \"\"\"\n        self.require_setting(\"static_path\", \"static_url\")\n        get_url = self.settings.get(\n            \"static_handler_class\", StaticFileHandler\n        ).make_static_url\n\n        if include_host is None:\n            include_host = getattr(self, \"include_host\", False)\n\n        if include_host:\n            base = self.request.protocol + \"://\" + self.request.host\n        else:\n            base = \"\"\n\n        return base + get_url(self.settings, path, **kwargs)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 36,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "compute_etag",
      "sourceCode": "def compute_etag(self) -> Optional[str]:\n        \"\"\"Computes the etag header to be used for this request.\n\n        By default uses a hash of the content written so far.\n\n        May be overridden to provide custom etag implementations,\n        or may return None to disable tornado's default etag support.\n        \"\"\"\n        hasher = hashlib.sha1()\n        for part in self._write_buffer:\n            hasher.update(part)\n        return '\"%s\"' % hasher.hexdigest()",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "check_etag_header",
      "sourceCode": "def check_etag_header(self) -> bool:\n        \"\"\"Checks the ``Etag`` header against requests's ``If-None-Match``.\n\n        Returns ``True`` if the request's Etag matches and a 304 should be\n        returned. For example::\n\n            self.set_etag_header()\n            if self.check_etag_header():\n                self.set_status(304)\n                return\n\n        This method is called automatically when the request is finished,\n        but may be called earlier for applications that override\n        `compute_etag` and want to do an early check for ``If-None-Match``\n        before completing the request.  The ``Etag`` header should be set\n        (perhaps with `set_etag_header`) before calling this method.\n        \"\"\"\n        computed_etag = utf8(self._headers.get(\"Etag\", \"\"))\n        # Find all weak and strong etag values from If-None-Match header\n        # because RFC 7232 allows multiple etag values in a single header.\n        etags = re.findall(\n            rb'\\*|(?:W/)?\"[^\"]*\"', utf8(self.request.headers.get(\"If-None-Match\", \"\"))\n        )\n        if not computed_etag or not etags:\n            return False\n\n        match = False\n        if etags[0] == b\"*\":\n            match = True\n        else:\n            # Use a weak comparison when comparing entity-tags.\n            def val(x: bytes) -> bytes:\n                return x[2:] if x.startswith(b\"W/\") else x\n\n            for etag in etags:\n                if val(etag) == val(computed_etag):\n                    match = True\n                    break\n        return match",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 38,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "_execute",
      "sourceCode": "async def _execute(\n        self, transforms: List[\"OutputTransform\"], *args: bytes, **kwargs: bytes\n    ) -> None:\n        \"\"\"Executes this request with the given output transforms.\"\"\"\n        self._transforms = transforms\n        try:\n            if self.request.method not in self.SUPPORTED_METHODS:\n                raise HTTPError(405)\n\n            # If we're not in stream_request_body mode, this is the place where we parse the body.\n            if not _has_stream_request_body(self.__class__):\n                try:\n                    self.request._parse_body()\n                except httputil.HTTPInputError as e:\n                    raise HTTPError(400, \"Invalid body: %s\" % e) from e\n\n            self.path_args = [self.decode_argument(arg) for arg in args]\n            self.path_kwargs = {\n                k: self.decode_argument(v, name=k) for (k, v) in kwargs.items()\n            }\n            # If XSRF cookies are turned on, reject form submissions without\n            # the proper cookie\n            if self.request.method not in (\n                \"GET\",\n                \"HEAD\",\n                \"OPTIONS\",\n            ) and self.application.settings.get(\"xsrf_cookies\"):\n                self.check_xsrf_cookie()\n\n            result = self.prepare()\n            if result is not None:\n                result = await result  # type: ignore\n            if self._prepared_future is not None:\n                # Tell the Application we've finished with prepare()\n                # and are ready for the body to arrive.\n                future_set_result_unless_cancelled(self._prepared_future, None)\n            if self._finished:\n                return\n\n            if _has_stream_request_body(self.__class__):\n                # In streaming mode request.body is a Future that signals\n                # the body has been completely received.  The Future has no\n                # result; the data has been passed to self.data_received\n                # instead.\n                try:\n                    await self.request._body_future\n                except iostream.StreamClosedError:\n                    return\n\n            method = getattr(self, self.request.method.lower())\n            result = method(*self.path_args, **self.path_kwargs)\n            if result is not None:\n                result = await result\n            if self._auto_finish and not self._finished:\n                self.finish()\n        except Exception as e:\n            try:\n                self._handle_request_exception(e)\n            except Exception:\n                app_log.error(\"Exception in exception handler\", exc_info=True)\n            finally:\n                # Unset result to avoid circular references\n                result = None\n            if self._prepared_future is not None and not self._prepared_future.done():\n                # In case we failed before setting _prepared_future, do it\n                # now (to unblock the HTTP server).  Note that this is not\n                # in a finally block to avoid GC issues prior to Python 3.4.\n                self._prepared_future.set_result(None)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 67,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "_handle_request_exception",
      "sourceCode": "def _handle_request_exception(self, e: BaseException) -> None:\n        if isinstance(e, Finish):\n            # Not an error; just finish the request without logging.\n            if not self._finished:\n                self.finish(*e.args)\n            return\n        try:\n            self.log_exception(*sys.exc_info())\n        except Exception:\n            # An error here should still get a best-effort send_error()\n            # to avoid leaking the connection.\n            app_log.error(\"Error in exception logger\", exc_info=True)\n        if self._finished:\n            # Extra errors after the request has been finished should\n            # be logged, but there is no reason to continue to try and\n            # send a response.\n            return\n        if isinstance(e, HTTPError):\n            self.send_error(e.status_code, exc_info=sys.exc_info())\n        else:\n            self.send_error(500, exc_info=sys.exc_info())",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "log_exception",
      "sourceCode": "def log_exception(\n        self,\n        typ: \"Optional[Type[BaseException]]\",\n        value: Optional[BaseException],\n        tb: Optional[TracebackType],\n    ) -> None:\n        \"\"\"Override to customize logging of uncaught exceptions.\n\n        By default logs instances of `HTTPError` as warnings without\n        stack traces (on the ``tornado.general`` logger), and all\n        other exceptions as errors with stack traces (on the\n        ``tornado.application`` logger).\n\n        .. versionadded:: 3.1\n        \"\"\"\n        if isinstance(value, HTTPError):\n            log_message = value.get_message()\n            if log_message:\n                format = \"%d %s: %s\"\n                args = [value.status_code, self._request_summary(), log_message]\n                gen_log.warning(format, *args)\n        else:\n            app_log.error(\n                \"Uncaught exception %s\\n%r\",\n                self._request_summary(),\n                self.request,\n                exc_info=(typ, value, tb),  # type: ignore\n            )",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 27,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "stream_request_body",
      "sourceCode": "def stream_request_body(cls: Type[_RequestHandlerType]) -> Type[_RequestHandlerType]:\n    \"\"\"Apply to `RequestHandler` subclasses to enable streaming body support.\n\n    This decorator implies the following changes:\n\n    * `.HTTPServerRequest.body` is undefined, and body arguments will not\n      be included in `RequestHandler.get_argument`.\n    * `RequestHandler.prepare` is called when the request headers have been\n      read instead of after the entire body has been read.\n    * The subclass must define a method ``data_received(self, data):``, which\n      will be called zero or more times as data is available.  Note that\n      if the request has an empty body, ``data_received`` may not be called.\n    * ``prepare`` and ``data_received`` may return Futures (such as via\n      ``@gen.coroutine``, in which case the next method will not be called\n      until those futures have completed.\n    * The regular HTTP method (``post``, ``put``, etc) will be called after\n      the entire body has been read.\n\n    See the `file receiver demo <https://github.com/tornadoweb/tornado/tree/stable/demos/file_upload/>`_\n    for example usage.\n    \"\"\"  # noqa: E501\n    if not issubclass(cls, RequestHandler):\n        raise TypeError(\"expected subclass of RequestHandler, got %r\", cls)\n    cls._stream_request_body = True\n    return cls",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 24,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "removeslash",
      "sourceCode": "def removeslash(\n    method: Callable[..., Optional[Awaitable[None]]],\n) -> Callable[..., Optional[Awaitable[None]]]:\n    \"\"\"Use this decorator to remove trailing slashes from the request path.\n\n    For example, a request to ``/foo/`` would redirect to ``/foo`` with this\n    decorator. Your request handler mapping should use a regular expression\n    like ``r'/foo/*'`` in conjunction with using the decorator.\n    \"\"\"\n\n    @functools.wraps(method)\n    def wrapper(  # type: ignore\n        self: RequestHandler, *args, **kwargs\n    ) -> Optional[Awaitable[None]]:\n        if self.request.path.endswith(\"/\"):\n            if self.request.method in (\"GET\", \"HEAD\"):\n                uri = self.request.path.rstrip(\"/\")\n                if uri:  # don't try to redirect '/' to ''\n                    if self.request.query:\n                        uri += \"?\" + self.request.query\n                    self.redirect(uri, permanent=True)\n                    return None\n            else:\n                raise HTTPError(404)\n        return method(self, *args, **kwargs)\n\n    return wrapper",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 26,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "wrapper",
      "sourceCode": "@functools.wraps(method)\n    def wrapper(  # type: ignore\n        self: RequestHandler, *args, **kwargs\n    ) -> Optional[Awaitable[None]]:\n        if self.request.path.endswith(\"/\"):\n            if self.request.method in (\"GET\", \"HEAD\"):\n                uri = self.request.path.rstrip(\"/\")\n                if uri:  # don't try to redirect '/' to ''\n                    if self.request.query:\n                        uri += \"?\" + self.request.query\n                    self.redirect(uri, permanent=True)\n                    return None\n            else:\n                raise HTTPError(404)\n        return method(self, *args, **kwargs)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "addslash",
      "sourceCode": "def addslash(\n    method: Callable[..., Optional[Awaitable[None]]],\n) -> Callable[..., Optional[Awaitable[None]]]:\n    \"\"\"Use this decorator to add a missing trailing slash to the request path.\n\n    For example, a request to ``/foo`` would redirect to ``/foo/`` with this\n    decorator. Your request handler mapping should use a regular expression\n    like ``r'/foo/?'`` in conjunction with using the decorator.\n    \"\"\"\n\n    @functools.wraps(method)\n    def wrapper(  # type: ignore\n        self: RequestHandler, *args, **kwargs\n    ) -> Optional[Awaitable[None]]:\n        if not self.request.path.endswith(\"/\"):\n            if self.request.method in (\"GET\", \"HEAD\"):\n                uri = self.request.path + \"/\"\n                if self.request.query:\n                    uri += \"?\" + self.request.query\n                self.redirect(uri, permanent=True)\n                return None\n            raise HTTPError(404)\n        return method(self, *args, **kwargs)\n\n    return wrapper",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 24,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "wrapper",
      "sourceCode": "@functools.wraps(method)\n    def wrapper(  # type: ignore\n        self: RequestHandler, *args, **kwargs\n    ) -> Optional[Awaitable[None]]:\n        if not self.request.path.endswith(\"/\"):\n            if self.request.method in (\"GET\", \"HEAD\"):\n                uri = self.request.path + \"/\"\n                if self.request.query:\n                    uri += \"?\" + self.request.query\n                self.redirect(uri, permanent=True)\n                return None\n            raise HTTPError(404)\n        return method(self, *args, **kwargs)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        handlers: Optional[_RuleList] = None,\n        default_host: Optional[str] = None,\n        transforms: Optional[List[Type[\"OutputTransform\"]]] = None,\n        **settings: Any,\n    ) -> None:\n        if transforms is None:\n            self.transforms = []  # type: List[Type[OutputTransform]]\n            if settings.get(\"compress_response\") or settings.get(\"gzip\"):\n                self.transforms.append(GZipContentEncoding)\n        else:\n            self.transforms = transforms\n        self.default_host = default_host\n        self.settings = settings\n        self.ui_modules = {\n            \"linkify\": _linkify,\n            \"xsrf_form_html\": _xsrf_form_html,\n            \"Template\": TemplateModule,\n        }\n        self.ui_methods = {}  # type: Dict[str, Callable[..., str]]\n        self._load_ui_modules(settings.get(\"ui_modules\", {}))\n        self._load_ui_methods(settings.get(\"ui_methods\", {}))\n        if self.settings.get(\"static_path\"):\n            path = self.settings[\"static_path\"]\n            handlers = list(handlers or [])\n            static_url_prefix = settings.get(\"static_url_prefix\", \"/static/\")\n            static_handler_class = settings.get(\n                \"static_handler_class\", StaticFileHandler\n            )\n            static_handler_args = settings.get(\"static_handler_args\", {})\n            static_handler_args[\"path\"] = path\n            for pattern in [\n                re.escape(static_url_prefix) + r\"(.*)\",\n                r\"/(favicon\\.ico)\",\n                r\"/(robots\\.txt)\",\n            ]:\n                handlers.insert(0, (pattern, static_handler_class, static_handler_args))\n\n        if self.settings.get(\"debug\"):\n            self.settings.setdefault(\"autoreload\", True)\n            self.settings.setdefault(\"compiled_template_cache\", False)\n            self.settings.setdefault(\"static_hash_cache\", False)\n            self.settings.setdefault(\"serve_traceback\", True)\n\n        self.wildcard_router = _ApplicationRouter(self, handlers)\n        self.default_router = _ApplicationRouter(\n            self, [Rule(AnyMatches(), self.wildcard_router)]\n        )\n\n        # Automatically reload modified modules\n        if self.settings.get(\"autoreload\"):\n            from tornado import autoreload\n\n            autoreload.start()",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 54,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "listen",
      "sourceCode": "def listen(\n        self,\n        port: int,\n        address: Optional[str] = None,\n        *,\n        family: socket.AddressFamily = socket.AF_UNSPEC,\n        backlog: int = tornado.netutil._DEFAULT_BACKLOG,\n        flags: Optional[int] = None,\n        reuse_port: bool = False,\n        **kwargs: Any,\n    ) -> HTTPServer:\n        \"\"\"Starts an HTTP server for this application on the given port.\n\n        This is a convenience alias for creating an `.HTTPServer` object and\n        calling its listen method.  Keyword arguments not supported by\n        `HTTPServer.listen <.TCPServer.listen>` are passed to the `.HTTPServer`\n        constructor.  For advanced uses (e.g. multi-process mode), do not use\n        this method; create an `.HTTPServer` and call its\n        `.TCPServer.bind`/`.TCPServer.start` methods directly.\n\n        Note that after calling this method you still need to call\n        ``IOLoop.current().start()`` (or run within ``asyncio.run``) to start\n        the server.\n\n        Returns the `.HTTPServer` object.\n\n        .. versionchanged:: 4.3\n           Now returns the `.HTTPServer` object.\n\n        .. versionchanged:: 6.2\n           Added support for new keyword arguments in `.TCPServer.listen`,\n           including ``reuse_port``.\n        \"\"\"\n        server = HTTPServer(self, **kwargs)\n        server.listen(\n            port,\n            address=address,\n            family=family,\n            backlog=backlog,\n            flags=flags,\n            reuse_port=reuse_port,\n        )\n        return server",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 42,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "add_handlers",
      "sourceCode": "def add_handlers(self, host_pattern: str, host_handlers: _RuleList) -> None:\n        \"\"\"Appends the given handlers to our handler list.\n\n        Host patterns are processed sequentially in the order they were\n        added. All matching patterns will be considered.\n        \"\"\"\n        host_matcher = HostMatches(host_pattern)\n        rule = Rule(host_matcher, _ApplicationRouter(self, host_handlers))\n\n        self.default_router.rules.insert(-1, rule)\n\n        if self.default_host is not None:\n            self.wildcard_router.add_rules(\n                [(DefaultHostMatches(self, host_matcher.host_pattern), host_handlers)]\n            )",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "_load_ui_methods",
      "sourceCode": "def _load_ui_methods(self, methods: Any) -> None:\n        if isinstance(methods, types.ModuleType):\n            self._load_ui_methods({n: getattr(methods, n) for n in dir(methods)})\n        elif isinstance(methods, list):\n            for m in methods:\n                self._load_ui_methods(m)\n        else:\n            for name, fn in methods.items():\n                if (\n                    not name.startswith(\"_\")\n                    and hasattr(fn, \"__call__\")\n                    and name[0].lower() == name[0]\n                ):\n                    self.ui_methods[name] = fn",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "_load_ui_modules",
      "sourceCode": "def _load_ui_modules(self, modules: Any) -> None:\n        if isinstance(modules, types.ModuleType):\n            self._load_ui_modules({n: getattr(modules, n) for n in dir(modules)})\n        elif isinstance(modules, list):\n            for m in modules:\n                self._load_ui_modules(m)\n        else:\n            assert isinstance(modules, dict)\n            for name, cls in modules.items():\n                try:\n                    if issubclass(cls, UIModule):\n                        self.ui_modules[name] = cls\n                except TypeError:\n                    pass",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "find_handler",
      "sourceCode": "def find_handler(\n        self, request: httputil.HTTPServerRequest, **kwargs: Any\n    ) -> \"_HandlerDelegate\":\n        route = self.default_router.find_handler(request)\n        if route is not None:\n            return cast(\"_HandlerDelegate\", route)\n\n        if self.settings.get(\"default_handler_class\"):\n            return self.get_handler_delegate(\n                request,\n                self.settings[\"default_handler_class\"],\n                self.settings.get(\"default_handler_args\", {}),\n            )\n\n        return self.get_handler_delegate(request, ErrorHandler, {\"status_code\": 404})",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_handler_delegate",
      "sourceCode": "def get_handler_delegate(\n        self,\n        request: httputil.HTTPServerRequest,\n        target_class: Type[RequestHandler],\n        target_kwargs: Optional[Dict[str, Any]] = None,\n        path_args: Optional[List[bytes]] = None,\n        path_kwargs: Optional[Dict[str, bytes]] = None,\n    ) -> \"_HandlerDelegate\":\n        \"\"\"Returns `~.httputil.HTTPMessageDelegate` that can serve a request\n        for application and `RequestHandler` subclass.\n\n        :arg httputil.HTTPServerRequest request: current HTTP request.\n        :arg RequestHandler target_class: a `RequestHandler` class.\n        :arg dict target_kwargs: keyword arguments for ``target_class`` constructor.\n        :arg list path_args: positional arguments for ``target_class`` HTTP method that\n            will be executed while handling a request (``get``, ``post`` or any other).\n        :arg dict path_kwargs: keyword arguments for ``target_class`` HTTP method.\n        \"\"\"\n        return _HandlerDelegate(\n            self, request, target_class, target_kwargs, path_args, path_kwargs\n        )",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "reverse_url",
      "sourceCode": "def reverse_url(self, name: str, *args: Any) -> str:\n        \"\"\"Returns a URL path for handler named ``name``\n\n        The handler must be added to the application as a named `URLSpec`.\n\n        Args will be substituted for capturing groups in the `URLSpec` regex.\n        They will be converted to strings if necessary, encoded as utf8,\n        and url-escaped.\n        \"\"\"\n        reversed_url = self.default_router.reverse_url(name, *args)\n        if reversed_url is not None:\n            return reversed_url\n\n        raise KeyError(\"%s not found in named urls\" % name)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "log_request",
      "sourceCode": "def log_request(self, handler: RequestHandler) -> None:\n        \"\"\"Writes a completed HTTP request to the logs.\n\n        By default writes to the python root logger.  To change\n        this behavior either subclass Application and override this method,\n        or pass a function in the application settings dictionary as\n        ``log_function``.\n        \"\"\"\n        if \"log_function\" in self.settings:\n            self.settings[\"log_function\"](handler)\n            return\n        if handler.get_status() < 400:\n            log_method = access_log.info\n        elif handler.get_status() < 500:\n            log_method = access_log.warning\n        else:\n            log_method = access_log.error\n        request_time = 1000.0 * handler.request.request_time()\n        log_method(\n            \"%d %s %.2fms\",\n            handler.get_status(),\n            handler._request_summary(),\n            request_time,\n        )",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 23,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        application: Application,\n        request: httputil.HTTPServerRequest,\n        handler_class: Type[RequestHandler],\n        handler_kwargs: Optional[Dict[str, Any]],\n        path_args: Optional[List[bytes]],\n        path_kwargs: Optional[Dict[str, bytes]],\n    ) -> None:\n        self.application = application\n        self.connection = request.connection\n        self.request = request\n        self.handler_class = handler_class\n        self.handler_kwargs = handler_kwargs or {}\n        self.path_args = path_args or []\n        self.path_kwargs = path_kwargs or {}\n        self.chunks = []  # type: List[bytes]\n        self.stream_request_body = _has_stream_request_body(self.handler_class)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 17,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "execute",
      "sourceCode": "def execute(self) -> Optional[Awaitable[None]]:\n        # If template cache is disabled (usually in the debug mode),\n        # re-compile templates and reload static files on every\n        # request so you don't need to restart to see changes\n        if not self.application.settings.get(\"compiled_template_cache\", True):\n            with RequestHandler._template_loader_lock:\n                for loader in RequestHandler._template_loaders.values():\n                    loader.reset()\n        if not self.application.settings.get(\"static_hash_cache\", True):\n            static_handler_class = self.application.settings.get(\n                \"static_handler_class\", StaticFileHandler\n            )\n            static_handler_class.reset()\n\n        self.handler = self.handler_class(\n            self.application, self.request, **self.handler_kwargs\n        )\n        transforms = [t(self.request) for t in self.application.transforms]\n\n        if self.stream_request_body:\n            self.handler._prepared_future = Future()\n        # Note that if an exception escapes handler._execute it will be\n        # trapped in the Future it returns (which we are ignoring here,\n        # leaving it to be logged when the Future is GC'd).\n        # However, that shouldn't happen because _execute has a blanket\n        # except handler, and we cannot easily access the IOLoop here to\n        # call add_future (because of the requirement to remain compatible\n        # with WSGI)\n        fut = gen.convert_yielded(\n            self.handler._execute(transforms, *self.path_args, **self.path_kwargs)\n        )\n        fut.add_done_callback(lambda f: f.result())\n        # If we are streaming the request body, then execute() is finished\n        # when the handler has prepared to receive the body.  If not,\n        # it doesn't matter when execute() finishes (so we return None)\n        return self.handler._prepared_future",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 35,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        status_code: int = 500,\n        log_message: Optional[str] = None,\n        *args: Any,\n        **kwargs: Any,\n    ) -> None:\n        self.status_code = status_code\n        self._log_message = log_message\n        self.args = args\n        self.reason = kwargs.get(\"reason\", None)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get",
      "sourceCode": "async def get(self, path: str, include_body: bool = True) -> None:\n        # Set up our path instance variables.\n        self.path = self.parse_url_path(path)\n        del path  # make sure we don't refer to path instead of self.path again\n        absolute_path = self.get_absolute_path(self.root, self.path)\n        self.absolute_path = self.validate_absolute_path(self.root, absolute_path)\n        if self.absolute_path is None:\n            return\n\n        self.modified = self.get_modified_time()\n        self.set_headers()\n\n        if self.should_return_304():\n            self.set_status(304)\n            return\n\n        request_range = None\n        range_header = self.request.headers.get(\"Range\")\n        if range_header:\n            # As per RFC 2616 14.16, if an invalid Range header is specified,\n            # the request will be treated as if the header didn't exist.\n            request_range = httputil._parse_request_range(range_header)\n\n        size = self.get_content_size()\n        if request_range:\n            start, end = request_range\n            if start is not None and start < 0:\n                start += size\n                if start < 0:\n                    start = 0\n            if (\n                start is not None\n                and (start >= size or (end is not None and start >= end))\n            ) or end == 0:\n                # As per RFC 2616 14.35.1, a range is not satisfiable only: if\n                # the first requested byte is equal to or greater than the\n                # content, or when a suffix with length 0 is specified.\n                # https://tools.ietf.org/html/rfc7233#section-2.1\n                # A byte-range-spec is invalid if the last-byte-pos value is present\n                # and less than the first-byte-pos.\n                self.set_status(416)  # Range Not Satisfiable\n                self.set_header(\"Content-Type\", \"text/plain\")\n                self.set_header(\"Content-Range\", f\"bytes */{size}\")\n                return\n            if end is not None and end > size:\n                # Clients sometimes blindly use a large range to limit their\n                # download size; cap the endpoint at the actual file size.\n                end = size\n            # Note: only return HTTP 206 if less than the entire range has been\n            # requested. Not only is this semantically correct, but Chrome\n            # refuses to play audio if it gets an HTTP 206 in response to\n            # ``Range: bytes=0-``.\n            if size != (end or size) - (start or 0):\n                self.set_status(206)  # Partial Content\n                self.set_header(\n                    \"Content-Range\", httputil._get_content_range(start, end, size)\n                )\n        else:\n            start = end = None\n\n        if start is not None and end is not None:\n            content_length = end - start\n        elif end is not None:\n            content_length = end\n        elif start is not None:\n            content_length = size - start\n        else:\n            content_length = size\n        self.set_header(\"Content-Length\", content_length)\n\n        if include_body:\n            content = self.get_content(self.absolute_path, start, end)\n            if isinstance(content, bytes):\n                content = [content]\n            for chunk in content:\n                try:\n                    self.write(chunk)\n                    await self.flush()\n                except iostream.StreamClosedError:\n                    return\n        else:\n            assert self.request.method == \"HEAD\"",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 81,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "compute_etag",
      "sourceCode": "def compute_etag(self) -> Optional[str]:\n        \"\"\"Sets the ``Etag`` header based on static url version.\n\n        This allows efficient ``If-None-Match`` checks against cached\n        versions, and sends the correct ``Etag`` for a partial response\n        (i.e. the same ``Etag`` as the full file).\n\n        .. versionadded:: 3.1\n        \"\"\"\n        assert self.absolute_path is not None\n        version_hash = self._get_cached_version(self.absolute_path)\n        if not version_hash:\n            return None\n        return f'\"{version_hash}\"'",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "set_headers",
      "sourceCode": "def set_headers(self) -> None:\n        \"\"\"Sets the content and caching headers on the response.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        self.set_header(\"Accept-Ranges\", \"bytes\")\n        self.set_etag_header()\n\n        if self.modified is not None:\n            self.set_header(\"Last-Modified\", self.modified)\n\n        content_type = self.get_content_type()\n        if content_type:\n            self.set_header(\"Content-Type\", content_type)\n\n        cache_time = self.get_cache_time(self.path, self.modified, content_type)\n        if cache_time > 0:\n            self.set_header(\n                \"Expires\",\n                datetime.datetime.now(datetime.timezone.utc)\n                + datetime.timedelta(seconds=cache_time),\n            )\n            self.set_header(\"Cache-Control\", \"max-age=\" + str(cache_time))\n\n        self.set_extra_headers(self.path)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 24,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "should_return_304",
      "sourceCode": "def should_return_304(self) -> bool:\n        \"\"\"Returns True if the headers indicate that we should return 304.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        # If client sent If-None-Match, use it, ignore If-Modified-Since\n        if self.request.headers.get(\"If-None-Match\"):\n            return self.check_etag_header()\n\n        # Check the If-Modified-Since, and don't send the result if the\n        # content has not been modified\n        ims_value = self.request.headers.get(\"If-Modified-Since\")\n        if ims_value is not None:\n            try:\n                if_since = email.utils.parsedate_to_datetime(ims_value)\n            except Exception:\n                return False\n            if if_since.tzinfo is None:\n                if_since = if_since.replace(tzinfo=datetime.timezone.utc)\n            assert self.modified is not None\n            if if_since >= self.modified:\n                return True\n\n        return False",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 23,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_absolute_path",
      "sourceCode": "@classmethod\n    def get_absolute_path(cls, root: str, path: str) -> str:\n        \"\"\"Returns the absolute location of ``path`` relative to ``root``.\n\n        ``root`` is the path configured for this `StaticFileHandler`\n        (in most cases the ``static_path`` `Application` setting).\n\n        This class method may be overridden in subclasses.  By default\n        it returns a filesystem path, but other strings may be used\n        as long as they are unique and understood by the subclass's\n        overridden `get_content`.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        abspath = os.path.abspath(os.path.join(root, path))\n        return abspath",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "validate_absolute_path",
      "sourceCode": "def validate_absolute_path(self, root: str, absolute_path: str) -> Optional[str]:\n        \"\"\"Validate and return the absolute path.\n\n        ``root`` is the configured path for the `StaticFileHandler`,\n        and ``path`` is the result of `get_absolute_path`\n\n        This is an instance method called during request processing,\n        so it may raise `HTTPError` or use methods like\n        `RequestHandler.redirect` (return None after redirecting to\n        halt further processing).  This is where 404 errors for missing files\n        are generated.\n\n        This method may modify the path before returning it, but note that\n        any such modifications will not be understood by `make_static_url`.\n\n        In instance methods, this method's result is available as\n        ``self.absolute_path``.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        # os.path.abspath strips a trailing /.\n        # We must add it back to `root` so that we only match files\n        # in a directory named `root` instead of files starting with\n        # that prefix.\n        root = os.path.abspath(root)\n        if not root.endswith(os.path.sep):\n            # abspath always removes a trailing slash, except when\n            # root is '/'. This is an unusual case, but several projects\n            # have independently discovered this technique to disable\n            # Tornado's path validation and (hopefully) do their own,\n            # so we need to support it.\n            root += os.path.sep\n        # The trailing slash also needs to be temporarily added back\n        # the requested path so a request to root/ will match.\n        if not (absolute_path + os.path.sep).startswith(root):\n            raise HTTPError(403, \"%s is not in root static directory\", self.path)\n        if os.path.isdir(absolute_path) and self.default_filename is not None:\n            # need to look at the request.path here for when path is empty\n            # but there is some prefix to the path that was already\n            # trimmed by the routing\n            if not self.request.path.endswith(\"/\"):\n                if self.request.path.startswith(\"//\"):\n                    # A redirect with two initial slashes is a \"protocol-relative\" URL.\n                    # This means the next path segment is treated as a hostname instead\n                    # of a part of the path, making this effectively an open redirect.\n                    # Reject paths starting with two slashes to prevent this.\n                    # This is only reachable under certain configurations.\n                    raise HTTPError(\n                        403, \"cannot redirect path with two initial slashes\"\n                    )\n                self.redirect(self.request.path + \"/\", permanent=True)\n                return None\n            absolute_path = os.path.join(absolute_path, self.default_filename)\n        if not os.path.exists(absolute_path):\n            raise HTTPError(404)\n        if not os.path.isfile(absolute_path):\n            raise HTTPError(403, \"%s is not a file\", self.path)\n        return absolute_path",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 57,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_content",
      "sourceCode": "@classmethod\n    def get_content(\n        cls, abspath: str, start: Optional[int] = None, end: Optional[int] = None\n    ) -> Generator[bytes, None, None]:\n        \"\"\"Retrieve the content of the requested resource which is located\n        at the given absolute path.\n\n        This class method may be overridden by subclasses.  Note that its\n        signature is different from other overridable class methods\n        (no ``settings`` argument); this is deliberate to ensure that\n        ``abspath`` is able to stand on its own as a cache key.\n\n        This method should either return a byte string or an iterator\n        of byte strings.  The latter is preferred for large files\n        as it helps reduce memory fragmentation.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        with open(abspath, \"rb\") as file:\n            if start is not None:\n                file.seek(start)\n            if end is not None:\n                remaining = end - (start or 0)  # type: Optional[int]\n            else:\n                remaining = None\n            while True:\n                chunk_size = 64 * 1024\n                if remaining is not None and remaining < chunk_size:\n                    chunk_size = remaining\n                chunk = file.read(chunk_size)\n                if chunk:\n                    if remaining is not None:\n                        remaining -= len(chunk)\n                    yield chunk\n                else:\n                    if remaining is not None:\n                        assert remaining == 0\n                    return",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 37,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_content_version",
      "sourceCode": "@classmethod\n    def get_content_version(cls, abspath: str) -> str:\n        \"\"\"Returns a version string for the resource at the given path.\n\n        This class method may be overridden by subclasses.  The\n        default implementation is a SHA-512 hash of the file's contents.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        data = cls.get_content(abspath)\n        hasher = hashlib.sha512()\n        if isinstance(data, bytes):\n            hasher.update(data)\n        else:\n            for chunk in data:\n                hasher.update(chunk)\n        return hasher.hexdigest()",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 16,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_content_size",
      "sourceCode": "def get_content_size(self) -> int:\n        \"\"\"Retrieve the total size of the resource at the given path.\n\n        This method may be overridden by subclasses.\n\n        .. versionadded:: 3.1\n\n        .. versionchanged:: 4.0\n           This method is now always called, instead of only when\n           partial results are requested.\n        \"\"\"\n        stat_result = self._stat()\n        return stat_result.st_size",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_modified_time",
      "sourceCode": "def get_modified_time(self) -> Optional[datetime.datetime]:\n        \"\"\"Returns the time that ``self.absolute_path`` was last modified.\n\n        May be overridden in subclasses.  Should return a `~datetime.datetime`\n        object or None.\n\n        .. versionadded:: 3.1\n\n        .. versionchanged:: 6.4\n           Now returns an aware datetime object instead of a naive one.\n           Subclasses that override this method may return either kind.\n        \"\"\"\n        stat_result = self._stat()\n        # NOTE: Historically, this used stat_result[stat.ST_MTIME],\n        # which truncates the fractional portion of the timestamp. It\n        # was changed from that form to stat_result.st_mtime to\n        # satisfy mypy (which disallows the bracket operator), but the\n        # latter form returns a float instead of an int. For\n        # consistency with the past (and because we have a unit test\n        # that relies on this), we truncate the float here, although\n        # I'm not sure that's the right thing to do.\n        modified = datetime.datetime.fromtimestamp(\n            int(stat_result.st_mtime), datetime.timezone.utc\n        )\n        return modified",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 24,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_content_type",
      "sourceCode": "def get_content_type(self) -> str:\n        \"\"\"Returns the ``Content-Type`` header to be used for this request.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        assert self.absolute_path is not None\n        mime_type, encoding = mimetypes.guess_type(self.absolute_path)\n        # per RFC 6713, use the appropriate type for a gzip compressed file\n        if encoding == \"gzip\":\n            return \"application/gzip\"\n        # As of 2015-07-21 there is no bzip2 encoding defined at\n        # http://www.iana.org/assignments/media-types/media-types.xhtml\n        # So for that (and any other encoding), use octet-stream.\n        elif encoding is not None:\n            return \"application/octet-stream\"\n        elif mime_type is not None:\n            return mime_type\n        # if mime_type not detected, use application/octet-stream\n        else:\n            return \"application/octet-stream\"",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 19,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_cache_time",
      "sourceCode": "def get_cache_time(\n        self, path: str, modified: Optional[datetime.datetime], mime_type: str\n    ) -> int:\n        \"\"\"Override to customize cache control behavior.\n\n        Return a positive number of seconds to make the result\n        cacheable for that amount of time or 0 to mark resource as\n        cacheable for an unspecified amount of time (subject to\n        browser heuristics).\n\n        By default returns cache expiry of 10 years for resources requested\n        with ``v`` argument.\n        \"\"\"\n        return self.CACHE_MAX_AGE if \"v\" in self.request.arguments else 0",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "make_static_url",
      "sourceCode": "@classmethod\n    def make_static_url(\n        cls, settings: Dict[str, Any], path: str, include_version: bool = True\n    ) -> str:\n        \"\"\"Constructs a versioned url for the given path.\n\n        This method may be overridden in subclasses (but note that it\n        is a class method rather than an instance method).  Subclasses\n        are only required to implement the signature\n        ``make_static_url(cls, settings, path)``; other keyword\n        arguments may be passed through `~RequestHandler.static_url`\n        but are not standard.\n\n        ``settings`` is the `Application.settings` dictionary.  ``path``\n        is the static path being requested.  The url returned should be\n        relative to the current host.\n\n        ``include_version`` determines whether the generated URL should\n        include the query string containing the version hash of the\n        file corresponding to the given ``path``.\n\n        \"\"\"\n        url = settings.get(\"static_url_prefix\", \"/static/\") + path\n        if not include_version:\n            return url\n\n        version_hash = cls.get_version(settings, path)\n        if not version_hash:\n            return url\n\n        return f\"{url}?v={version_hash}\"",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 30,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "parse_url_path",
      "sourceCode": "def parse_url_path(self, url_path: str) -> str:\n        \"\"\"Converts a static URL path into a filesystem path.\n\n        ``url_path`` is the path component of the URL with\n        ``static_url_prefix`` removed.  The return value should be\n        filesystem path relative to ``static_path``.\n\n        This is the inverse of `make_static_url`.\n        \"\"\"\n        if os.path.sep != \"/\":\n            url_path = url_path.replace(\"/\", os.path.sep)\n        return url_path",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_version",
      "sourceCode": "@classmethod\n    def get_version(cls, settings: Dict[str, Any], path: str) -> Optional[str]:\n        \"\"\"Generate the version string to be used in static URLs.\n\n        ``settings`` is the `Application.settings` dictionary and ``path``\n        is the relative location of the requested asset on the filesystem.\n        The returned value should be a string, or ``None`` if no version\n        could be determined.\n\n        .. versionchanged:: 3.1\n           This method was previously recommended for subclasses to override;\n           `get_content_version` is now preferred as it allows the base\n           class to handle caching of the result.\n        \"\"\"\n        abs_path = cls.get_absolute_path(settings[\"static_path\"], path)\n        return cls._get_cached_version(abs_path)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "_get_cached_version",
      "sourceCode": "@classmethod\n    def _get_cached_version(cls, abs_path: str) -> Optional[str]:\n        with cls._lock:\n            hashes = cls._static_hashes\n            if abs_path not in hashes:\n                try:\n                    hashes[abs_path] = cls.get_content_version(abs_path)\n                except Exception:\n                    gen_log.error(\"Could not open static file %r\", abs_path)\n                    hashes[abs_path] = None\n            hsh = hashes.get(abs_path)\n            if hsh:\n                return hsh\n        return None",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "transform_first_chunk",
      "sourceCode": "def transform_first_chunk(\n        self,\n        status_code: int,\n        headers: httputil.HTTPHeaders,\n        chunk: bytes,\n        finishing: bool,\n    ) -> Tuple[int, httputil.HTTPHeaders, bytes]:\n        # TODO: can/should this type be inherited from the superclass?\n        if \"Vary\" in headers:\n            headers[\"Vary\"] += \", Accept-Encoding\"\n        else:\n            headers[\"Vary\"] = \"Accept-Encoding\"\n        if self._gzipping:\n            ctype = _unicode(headers.get(\"Content-Type\", \"\")).split(\";\")[0]\n            self._gzipping = (\n                self._compressible_type(ctype)\n                and (not finishing or len(chunk) >= self.MIN_LENGTH)\n                and (\"Content-Encoding\" not in headers)\n            )\n        if self._gzipping:\n            headers[\"Content-Encoding\"] = \"gzip\"\n            self._gzip_value = BytesIO()\n            self._gzip_file = gzip.GzipFile(\n                mode=\"w\", fileobj=self._gzip_value, compresslevel=self.GZIP_LEVEL\n            )\n            chunk = self.transform_chunk(chunk, finishing)\n            if \"Content-Length\" in headers:\n                # The original content length is no longer correct.\n                # If this is the last (and only) chunk, we can set the new\n                # content-length; otherwise we remove it and fall back to\n                # chunked encoding.\n                if finishing:\n                    headers[\"Content-Length\"] = str(len(chunk))\n                else:\n                    del headers[\"Content-Length\"]\n        return status_code, headers, chunk",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 35,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "transform_chunk",
      "sourceCode": "def transform_chunk(self, chunk: bytes, finishing: bool) -> bytes:\n        if self._gzipping:\n            self._gzip_file.write(chunk)\n            if finishing:\n                self._gzip_file.close()\n            else:\n                self._gzip_file.flush()\n            chunk = self._gzip_value.getvalue()\n            self._gzip_value.truncate(0)\n            self._gzip_value.seek(0)\n        return chunk",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "authenticated",
      "sourceCode": "def authenticated(\n    method: Callable[..., Optional[Awaitable[None]]],\n) -> Callable[..., Optional[Awaitable[None]]]:\n    \"\"\"Decorate methods with this to require that the user be logged in.\n\n    If the user is not logged in, they will be redirected to the configured\n    `login url <RequestHandler.get_login_url>`.\n\n    If you configure a login url with a query parameter, Tornado will\n    assume you know what you're doing and use it as-is.  If not, it\n    will add a `next` parameter so the login page knows where to send\n    you once you're logged in.\n    \"\"\"\n\n    @functools.wraps(method)\n    def wrapper(  # type: ignore\n        self: RequestHandler, *args, **kwargs\n    ) -> Optional[Awaitable[None]]:\n        if not self.current_user:\n            if self.request.method in (\"GET\", \"HEAD\"):\n                url = self.get_login_url()\n                if \"?\" not in url:\n                    if urllib.parse.urlsplit(url).scheme:\n                        # if login url is absolute, make next absolute too\n                        next_url = self.request.full_url()\n                    else:\n                        assert self.request.uri is not None\n                        next_url = self.request.uri\n                    url += \"?\" + urlencode(dict(next=next_url))\n                self.redirect(url)\n                return None\n            raise HTTPError(403)\n        return method(self, *args, **kwargs)\n\n    return wrapper",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 34,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "wrapper",
      "sourceCode": "@functools.wraps(method)\n    def wrapper(  # type: ignore\n        self: RequestHandler, *args, **kwargs\n    ) -> Optional[Awaitable[None]]:\n        if not self.current_user:\n            if self.request.method in (\"GET\", \"HEAD\"):\n                url = self.get_login_url()\n                if \"?\" not in url:\n                    if urllib.parse.urlsplit(url).scheme:\n                        # if login url is absolute, make next absolute too\n                        next_url = self.request.full_url()\n                    else:\n                        assert self.request.uri is not None\n                        next_url = self.request.uri\n                    url += \"?\" + urlencode(dict(next=next_url))\n                self.redirect(url)\n                return None\n            raise HTTPError(403)\n        return method(self, *args, **kwargs)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 18,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "render",
      "sourceCode": "def render(self, path: str, **kwargs: Any) -> bytes:\n        def set_resources(**kwargs) -> str:  # type: ignore\n            if path not in self._resource_dict:\n                self._resource_list.append(kwargs)\n                self._resource_dict[path] = kwargs\n            else:\n                if self._resource_dict[path] != kwargs:\n                    raise ValueError(\n                        \"set_resources called with different \"\n                        \"resources for the same template\"\n                    )\n            return \"\"\n\n        return self.render_string(path, set_resources=set_resources, **kwargs)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "set_resources",
      "sourceCode": "def set_resources(**kwargs) -> str:  # type: ignore\n            if path not in self._resource_dict:\n                self._resource_list.append(kwargs)\n                self._resource_dict[path] = kwargs\n            else:\n                if self._resource_dict[path] != kwargs:\n                    raise ValueError(\n                        \"set_resources called with different \"\n                        \"resources for the same template\"\n                    )\n            return \"\"",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "create_signed_value",
      "sourceCode": "def create_signed_value(\n    secret: _CookieSecretTypes,\n    name: str,\n    value: Union[str, bytes],\n    version: Optional[int] = None,\n    clock: Optional[Callable[[], float]] = None,\n    key_version: Optional[int] = None,\n) -> bytes:\n    if version is None:\n        version = DEFAULT_SIGNED_VALUE_VERSION\n    if clock is None:\n        clock = time.time\n\n    timestamp = utf8(str(int(clock())))\n    value = base64.b64encode(utf8(value))\n    if version == 1:\n        assert not isinstance(secret, dict)\n        signature = _create_signature_v1(secret, name, value, timestamp)\n        value = b\"|\".join([value, timestamp, signature])\n        return value\n    elif version == 2:\n        # The v2 format consists of a version number and a series of\n        # length-prefixed fields \"%d:%s\", the last of which is a\n        # signature, all separated by pipes.  All numbers are in\n        # decimal format with no leading zeros.  The signature is an\n        # HMAC-SHA256 of the whole string up to that point, including\n        # the final pipe.\n        #\n        # The fields are:\n        # - format version (i.e. 2; no length prefix)\n        # - key version (integer, default is 0)\n        # - timestamp (integer seconds since epoch)\n        # - name (not encoded; assumed to be ~alphanumeric)\n        # - value (base64-encoded)\n        # - signature (hex-encoded; no length prefix)\n        def format_field(s: Union[str, bytes]) -> bytes:\n            return utf8(\"%d:\" % len(s)) + utf8(s)\n\n        to_sign = b\"|\".join(\n            [\n                b\"2\",\n                format_field(str(key_version or 0)),\n                format_field(timestamp),\n                format_field(name),\n                format_field(value),\n                b\"\",\n            ]\n        )\n\n        if isinstance(secret, dict):\n            assert (\n                key_version is not None\n            ), \"Key version must be set when sign key dict is used\"\n            assert version >= 2, \"Version must be at least 2 for key version support\"\n            secret = secret[key_version]\n\n        signature = _create_signature_v2(secret, to_sign)\n        return to_sign + signature\n    else:\n        raise ValueError(\"Unsupported version %d\" % version)",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 59,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "_get_version",
      "sourceCode": "def _get_version(value: bytes) -> int:\n    # Figures out what version value is.  Version 1 did not include an\n    # explicit version field and started with arbitrary base64 data,\n    # which makes this tricky.\n    m = _signed_value_version_re.match(value)\n    if m is None:\n        version = 1\n    else:\n        try:\n            version = int(m.group(1))\n            if version > 999:\n                # Certain payloads from the version-less v1 format may\n                # be parsed as valid integers.  Due to base64 padding\n                # restrictions, this can only happen for numbers whose\n                # length is a multiple of 4, so we can treat all\n                # numbers up to 999 as versions, and for the rest we\n                # fall back to v1 format.\n                version = 1\n        except ValueError:\n            version = 1\n    return version",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 20,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "decode_signed_value",
      "sourceCode": "def decode_signed_value(\n    secret: _CookieSecretTypes,\n    name: str,\n    value: Union[None, str, bytes],\n    max_age_days: float = 31,\n    clock: Optional[Callable[[], float]] = None,\n    min_version: Optional[int] = None,\n) -> Optional[bytes]:\n    if clock is None:\n        clock = time.time\n    if min_version is None:\n        min_version = DEFAULT_SIGNED_VALUE_MIN_VERSION\n    if min_version > 2:\n        raise ValueError(\"Unsupported min_version %d\" % min_version)\n    if not value:\n        return None\n\n    value = utf8(value)\n    version = _get_version(value)\n\n    if version < min_version:\n        return None\n    if version == 1:\n        assert not isinstance(secret, dict)\n        return _decode_signed_value_v1(secret, name, value, max_age_days, clock)\n    elif version == 2:\n        return _decode_signed_value_v2(secret, name, value, max_age_days, clock)\n    else:\n        return None",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 28,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "_decode_signed_value_v1",
      "sourceCode": "def _decode_signed_value_v1(\n    secret: Union[str, bytes],\n    name: str,\n    value: bytes,\n    max_age_days: float,\n    clock: Callable[[], float],\n) -> Optional[bytes]:\n    parts = utf8(value).split(b\"|\")\n    if len(parts) != 3:\n        return None\n    signature = _create_signature_v1(secret, name, parts[0], parts[1])\n    if not hmac.compare_digest(parts[2], signature):\n        gen_log.warning(\"Invalid cookie signature %r\", value)\n        return None\n    timestamp = int(parts[1])\n    if timestamp < clock() - max_age_days * 86400:\n        gen_log.warning(\"Expired cookie %r\", value)\n        return None\n    if timestamp > clock() + 31 * 86400:\n        # _cookie_signature does not hash a delimiter between the\n        # parts of the cookie, so an attacker could transfer trailing\n        # digits from the payload to the timestamp without altering the\n        # signature.  For backwards compatibility, sanity-check timestamp\n        # here instead of modifying _cookie_signature.\n        gen_log.warning(\"Cookie timestamp in future; possible tampering %r\", value)\n        return None\n    if parts[1].startswith(b\"0\"):\n        gen_log.warning(\"Tampered cookie %r\", value)\n        return None\n    try:\n        return base64.b64decode(parts[0])\n    except Exception:\n        return None",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 32,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "_decode_fields_v2",
      "sourceCode": "def _decode_fields_v2(value: bytes) -> Tuple[int, bytes, bytes, bytes, bytes]:\n    def _consume_field(s: bytes) -> Tuple[bytes, bytes]:\n        length, _, rest = s.partition(b\":\")\n        n = int(length)\n        field_value = rest[:n]\n        # In python 3, indexing bytes returns small integers; we must\n        # use a slice to get a byte string as in python 2.\n        if rest[n : n + 1] != b\"|\":\n            raise ValueError(\"malformed v2 signed value field\")\n        rest = rest[n + 1 :]\n        return field_value, rest\n\n    rest = value[2:]  # remove version number\n    key_version, rest = _consume_field(rest)\n    timestamp, rest = _consume_field(rest)\n    name_field, rest = _consume_field(rest)\n    value_field, passed_sig = _consume_field(rest)\n    return int(key_version), timestamp, name_field, value_field, passed_sig",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 17,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "_decode_signed_value_v2",
      "sourceCode": "def _decode_signed_value_v2(\n    secret: _CookieSecretTypes,\n    name: str,\n    value: bytes,\n    max_age_days: float,\n    clock: Callable[[], float],\n) -> Optional[bytes]:\n    try:\n        (\n            key_version,\n            timestamp_bytes,\n            name_field,\n            value_field,\n            passed_sig,\n        ) = _decode_fields_v2(value)\n    except ValueError:\n        return None\n    signed_string = value[: -len(passed_sig)]\n\n    if isinstance(secret, dict):\n        try:\n            secret = secret[key_version]\n        except KeyError:\n            return None\n\n    expected_sig = _create_signature_v2(secret, signed_string)\n    if not hmac.compare_digest(passed_sig, expected_sig):\n        return None\n    if name_field != utf8(name):\n        return None\n    timestamp = int(timestamp_bytes)\n    if timestamp < clock() - max_age_days * 86400:\n        # The signature has expired.\n        return None\n    try:\n        return base64.b64decode(value_field)\n    except Exception:\n        return None",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 37,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "get_signature_key_version",
      "sourceCode": "def get_signature_key_version(value: Union[str, bytes]) -> Optional[int]:\n    value = utf8(value)\n    version = _get_version(value)\n    if version < 2:\n        return None\n    try:\n        key_version, _, _, _, _ = _decode_fields_v2(value)\n    except ValueError:\n        return None\n\n    return key_version",
      "importString": "import base64\nimport binascii\nimport datetime\nimport email.utils\nimport functools\nimport gzip\nimport hashlib\nimport hmac\nimport http.cookies\nfrom tornado.routing import (\nAnyMatches\nDefaultHostMatches\nHostMatches\nReversibleRouter\nRule\nReversibleRuleRouter\nURLSpec\n_RuleList\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\nfrom typing import (\nDict\nAny\nUnion\nOptional\nAwaitable\nTuple\nList\nCallable\nIterable\nGenerator\nType\nTypeVar\ncast\noverload\n)\nfrom types import TracebackType\nimport typing",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/web.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        ping_interval: Optional[float] = None,\n        ping_timeout: Optional[float] = None,\n        max_message_size: int = _default_max_message_size,\n        compression_options: Optional[Dict[str, Any]] = None,\n    ) -> None:\n        self.ping_interval = ping_interval\n        self.ping_timeout = ping_timeout\n        self.max_message_size = max_message_size\n        self.compression_options = compression_options",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        application: tornado.web.Application,\n        request: httputil.HTTPServerRequest,\n        **kwargs: Any,\n    ) -> None:\n        super().__init__(application, request, **kwargs)\n        self.ws_connection = None  # type: Optional[WebSocketProtocol]\n        self.close_code = None  # type: Optional[int]\n        self.close_reason = None  # type: Optional[str]\n        self._on_close_called = False",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "get",
      "sourceCode": "async def get(self, *args: Any, **kwargs: Any) -> None:\n        self.open_args = args\n        self.open_kwargs = kwargs\n\n        # Upgrade header should be present and should be equal to WebSocket\n        if self.request.headers.get(\"Upgrade\", \"\").lower() != \"websocket\":\n            self.set_status(400)\n            log_msg = 'Can \"Upgrade\" only to \"WebSocket\".'\n            self.finish(log_msg)\n            gen_log.debug(log_msg)\n            return\n\n        # Connection header should be upgrade.\n        # Some proxy servers/load balancers\n        # might mess with it.\n        headers = self.request.headers\n        connection = map(\n            lambda s: s.strip().lower(), headers.get(\"Connection\", \"\").split(\",\")\n        )\n        if \"upgrade\" not in connection:\n            self.set_status(400)\n            log_msg = '\"Connection\" must be \"Upgrade\".'\n            self.finish(log_msg)\n            gen_log.debug(log_msg)\n            return\n\n        # Handle WebSocket Origin naming convention differences\n        # The difference between version 8 and 13 is that in 8 the\n        # client sends a \"Sec-Websocket-Origin\" header and in 13 it's\n        # simply \"Origin\".\n        if \"Origin\" in self.request.headers:\n            origin = self.request.headers.get(\"Origin\")\n        else:\n            origin = self.request.headers.get(\"Sec-Websocket-Origin\", None)\n\n        # If there was an origin header, check to make sure it matches\n        # according to check_origin. When the origin is None, we assume it\n        # did not come from a browser and that it can be passed on.\n        if origin is not None and not self.check_origin(origin):\n            self.set_status(403)\n            log_msg = \"Cross origin websockets not allowed\"\n            self.finish(log_msg)\n            gen_log.debug(log_msg)\n            return\n\n        self.ws_connection = self.get_websocket_protocol()\n        if self.ws_connection:\n            await self.ws_connection.accept_connection(self)\n        else:\n            self.set_status(426, \"Upgrade Required\")\n            self.set_header(\"Sec-WebSocket-Version\", \"7, 8, 13\")",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 50,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "ping_interval",
      "sourceCode": "@property\n    def ping_interval(self) -> Optional[float]:\n        \"\"\"The interval for sending websocket pings.\n\n        If this is non-zero, the websocket will send a ping every\n        ping_interval seconds.\n        The client will respond with a \"pong\". The connection can be configured\n        to timeout on late pong delivery using ``websocket_ping_timeout``.\n\n        Set ``websocket_ping_interval = 0`` to disable pings.\n\n        Default: ``0``\n        \"\"\"\n        return self.settings.get(\"websocket_ping_interval\", None)",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "ping_timeout",
      "sourceCode": "@property\n    def ping_timeout(self) -> Optional[float]:\n        \"\"\"Timeout if no pong is received in this many seconds.\n\n        To be used in combination with ``websocket_ping_interval > 0``.\n        If a ping response (a \"pong\") is not received within\n        ``websocket_ping_timeout`` seconds, then the websocket connection\n        will be closed.\n\n        This can help to clean up clients which have disconnected without\n        cleanly closing the websocket connection.\n\n        Note, the ping timeout cannot be longer than the ping interval.\n\n        Set ``websocket_ping_timeout = 0`` to disable the ping timeout.\n\n        Default: equal to the ``ping_interval``.\n\n        .. versionchanged:: 6.5.0\n           Default changed from the max of 3 pings or 30 seconds.\n           The ping timeout can no longer be configured longer than the\n           ping interval.\n        \"\"\"\n        return self.settings.get(\"websocket_ping_timeout\", None)",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 23,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "max_message_size",
      "sourceCode": "@property\n    def max_message_size(self) -> int:\n        \"\"\"Maximum allowed message size.\n\n        If the remote peer sends a message larger than this, the connection\n        will be closed.\n\n        Default is 10MiB.\n        \"\"\"\n        return self.settings.get(\n            \"websocket_max_message_size\", _default_max_message_size\n        )",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "write_message",
      "sourceCode": "def write_message(\n        self, message: Union[bytes, str, Dict[str, Any]], binary: bool = False\n    ) -> \"Future[None]\":\n        \"\"\"Sends the given message to the client of this Web Socket.\n\n        The message may be either a string or a dict (which will be\n        encoded as json).  If the ``binary`` argument is false, the\n        message will be sent as utf8; in binary mode any byte string\n        is allowed.\n\n        If the connection is already closed, raises `WebSocketClosedError`.\n        Returns a `.Future` which can be used for flow control.\n\n        .. versionchanged:: 3.2\n           `WebSocketClosedError` was added (previously a closed connection\n           would raise an `AttributeError`)\n\n        .. versionchanged:: 4.3\n           Returns a `.Future` which can be used for flow control.\n\n        .. versionchanged:: 5.0\n           Consistently raises `WebSocketClosedError`. Previously could\n           sometimes raise `.StreamClosedError`.\n        \"\"\"\n        if self.ws_connection is None or self.ws_connection.is_closing():\n            raise WebSocketClosedError()\n        if isinstance(message, dict):\n            message = tornado.escape.json_encode(message)\n        return self.ws_connection.write_message(message, binary=binary)",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 28,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "select_subprotocol",
      "sourceCode": "def select_subprotocol(self, subprotocols: List[str]) -> Optional[str]:\n        \"\"\"Override to implement subprotocol negotiation.\n\n        ``subprotocols`` is a list of strings identifying the\n        subprotocols proposed by the client.  This method may be\n        overridden to return one of those strings to select it, or\n        ``None`` to not select a subprotocol.\n\n        Failure to select a subprotocol does not automatically abort\n        the connection, although clients may close the connection if\n        none of their proposed subprotocols was selected.\n\n        The list may be empty, in which case this method must return\n        None. This method is always called exactly once even if no\n        subprotocols were proposed so that the handler can be advised\n        of this fact.\n\n        .. versionchanged:: 5.1\n\n           Previously, this method was called with a list containing\n           an empty string instead of an empty list if no subprotocols\n           were proposed by the client.\n        \"\"\"\n        return None",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 23,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "get_compression_options",
      "sourceCode": "def get_compression_options(self) -> Optional[Dict[str, Any]]:\n        \"\"\"Override to return compression options for the connection.\n\n        If this method returns None (the default), compression will\n        be disabled.  If it returns a dict (even an empty one), it\n        will be enabled.  The contents of the dict may be used to\n        control the following compression options:\n\n        ``compression_level`` specifies the compression level.\n\n        ``mem_level`` specifies the amount of memory used for the internal compression state.\n\n         These parameters are documented in detail here:\n         https://docs.python.org/3.13/library/zlib.html#zlib.compressobj\n\n        .. versionadded:: 4.1\n\n        .. versionchanged:: 4.5\n\n           Added ``compression_level`` and ``mem_level``.\n        \"\"\"\n        # TODO: Add wbits option.\n        return None",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 22,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "ping",
      "sourceCode": "def ping(self, data: Union[str, bytes] = b\"\") -> None:\n        \"\"\"Send ping frame to the remote end.\n\n        The data argument allows a small amount of data (up to 125\n        bytes) to be sent as a part of the ping message. Note that not\n        all websocket implementations expose this data to\n        applications.\n\n        Consider using the ``websocket_ping_interval`` application\n        setting instead of sending pings manually.\n\n        .. versionchanged:: 5.1\n\n           The data argument is now optional.\n\n        \"\"\"\n        data = utf8(data)\n        if self.ws_connection is None or self.ws_connection.is_closing():\n            raise WebSocketClosedError()\n        self.ws_connection.write_ping(data)",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 19,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "on_close",
      "sourceCode": "def on_close(self) -> None:\n        \"\"\"Invoked when the WebSocket is closed.\n\n        If the connection was closed cleanly and a status code or reason\n        phrase was supplied, these values will be available as the attributes\n        ``self.close_code`` and ``self.close_reason``.\n\n        .. versionchanged:: 4.0\n\n           Added ``close_code`` and ``close_reason`` attributes.\n        \"\"\"\n        pass",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 11,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "close",
      "sourceCode": "def close(self, code: Optional[int] = None, reason: Optional[str] = None) -> None:\n        \"\"\"Closes this Web Socket.\n\n        Once the close handshake is successful the socket will be closed.\n\n        ``code`` may be a numeric status code, taken from the values\n        defined in `RFC 6455 section 7.4.1\n        <https://tools.ietf.org/html/rfc6455#section-7.4.1>`_.\n        ``reason`` may be a textual message about why the connection is\n        closing.  These values are made available to the client, but are\n        not otherwise interpreted by the websocket protocol.\n\n        .. versionchanged:: 4.0\n\n           Added the ``code`` and ``reason`` arguments.\n        \"\"\"\n        if self.ws_connection:\n            self.ws_connection.close(code, reason)\n            self.ws_connection = None",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 18,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "check_origin",
      "sourceCode": "def check_origin(self, origin: str) -> bool:\n        \"\"\"Override to enable support for allowing alternate origins.\n\n        The ``origin`` argument is the value of the ``Origin`` HTTP\n        header, the url responsible for initiating this request.  This\n        method is not called for clients that do not send this header;\n        such requests are always allowed (because all browsers that\n        implement WebSockets support this header, and non-browser\n        clients do not have the same cross-site security concerns).\n\n        Should return ``True`` to accept the request or ``False`` to\n        reject it. By default, rejects all requests with an origin on\n        a host other than this one.\n\n        This is a security protection against cross site scripting attacks on\n        browsers, since WebSockets are allowed to bypass the usual same-origin\n        policies and don't use CORS headers.\n\n        .. warning::\n\n           This is an important security measure; don't disable it\n           without understanding the security implications. In\n           particular, if your authentication is cookie-based, you\n           must either restrict the origins allowed by\n           ``check_origin()`` or implement your own XSRF-like\n           protection for websocket connections. See `these\n           <https://www.christian-schneider.net/CrossSiteWebSocketHijacking.html>`_\n           `articles\n           <https://devcenter.heroku.com/articles/websocket-security>`_\n           for more.\n\n        To accept all cross-origin traffic (which was the default prior to\n        Tornado 4.0), simply override this method to always return ``True``::\n\n            def check_origin(self, origin):\n                return True\n\n        To allow connections from any subdomain of your site, you might\n        do something like::\n\n            def check_origin(self, origin):\n                parsed_origin = urllib.parse.urlparse(origin)\n                return parsed_origin.netloc.endswith(\".mydomain.com\")\n\n        .. versionadded:: 4.0\n\n        \"\"\"\n        parsed_origin = urlparse(origin)\n        origin = parsed_origin.netloc\n        origin = origin.lower()\n\n        host = self.request.headers.get(\"Host\")\n\n        # Check to see that origin matches host directly, including ports\n        return origin == host",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 54,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "set_nodelay",
      "sourceCode": "def set_nodelay(self, value: bool) -> None:\n        \"\"\"Set the no-delay flag for this stream.\n\n        By default, small messages may be delayed and/or combined to minimize\n        the number of packets sent.  This can sometimes cause 200-500ms delays\n        due to the interaction between Nagle's algorithm and TCP delayed\n        ACKs.  To reduce this delay (at the expense of possibly increasing\n        bandwidth usage), call ``self.set_nodelay(True)`` once the websocket\n        connection is established.\n\n        See `.BaseIOStream.set_nodelay` for additional details.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        assert self.ws_connection is not None\n        self.ws_connection.set_nodelay(value)",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "get_websocket_protocol",
      "sourceCode": "def get_websocket_protocol(self) -> Optional[\"WebSocketProtocol\"]:\n        websocket_version = self.request.headers.get(\"Sec-WebSocket-Version\")\n        if websocket_version in (\"7\", \"8\", \"13\"):\n            params = _WebSocketParams(\n                ping_interval=self.ping_interval,\n                ping_timeout=self.ping_timeout,\n                max_message_size=self.max_message_size,\n                compression_options=self.get_compression_options(),\n            )\n            return WebSocketProtocol13(self, False, params)\n        return None",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 10,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "_detach_stream",
      "sourceCode": "def _detach_stream(self) -> IOStream:\n        # disable non-WS methods\n        for method in [\n            \"write\",\n            \"redirect\",\n            \"set_header\",\n            \"set_cookie\",\n            \"set_status\",\n            \"flush\",\n            \"finish\",\n        ]:\n            setattr(self, method, _raise_not_supported_for_websockets)\n        return self.detach()",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 12,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "_run_callback",
      "sourceCode": "def _run_callback(\n        self, callback: Callable, *args: Any, **kwargs: Any\n    ) -> \"Optional[Future[Any]]\":\n        \"\"\"Runs the given callback with exception handling.\n\n        If the callback is a coroutine, returns its Future. On error, aborts the\n        websocket connection and returns None.\n        \"\"\"\n        try:\n            result = callback(*args, **kwargs)\n        except Exception:\n            self.handler.log_exception(*sys.exc_info())\n            self._abort()\n            return None\n        else:\n            if result is not None:\n                result = gen.convert_yielded(result)\n                assert self.stream is not None\n                self.stream.io_loop.add_future(result, lambda f: f.result())\n            return result",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 19,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        persistent: bool,\n        max_wbits: Optional[int],\n        compression_options: Optional[Dict[str, Any]] = None,\n    ) -> None:\n        if max_wbits is None:\n            max_wbits = zlib.MAX_WBITS\n        # There is no symbolic constant for the minimum wbits value.\n        if not (8 <= max_wbits <= zlib.MAX_WBITS):\n            raise ValueError(\n                \"Invalid max_wbits value %r; allowed range 8-%d\",\n                max_wbits,\n                zlib.MAX_WBITS,\n            )\n        self._max_wbits = max_wbits\n\n        if (\n            compression_options is None\n            or \"compression_level\" not in compression_options\n        ):\n            self._compression_level = tornado.web.GZipContentEncoding.GZIP_LEVEL\n        else:\n            self._compression_level = compression_options[\"compression_level\"]\n\n        if compression_options is None or \"mem_level\" not in compression_options:\n            self._mem_level = 8\n        else:\n            self._mem_level = compression_options[\"mem_level\"]\n\n        if persistent:\n            self._compressor = self._create_compressor()  # type: Optional[_Compressor]\n        else:\n            self._compressor = None",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 33,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        persistent: bool,\n        max_wbits: Optional[int],\n        max_message_size: int,\n        compression_options: Optional[Dict[str, Any]] = None,\n    ) -> None:\n        self._max_message_size = max_message_size\n        if max_wbits is None:\n            max_wbits = zlib.MAX_WBITS\n        if not (8 <= max_wbits <= zlib.MAX_WBITS):\n            raise ValueError(\n                \"Invalid max_wbits value %r; allowed range 8-%d\",\n                max_wbits,\n                zlib.MAX_WBITS,\n            )\n        self._max_wbits = max_wbits\n        if persistent:\n            self._decompressor = (\n                self._create_decompressor()\n            )  # type: Optional[_Decompressor]\n        else:\n            self._decompressor = None",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 22,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        handler: \"_WebSocketDelegate\",\n        mask_outgoing: bool,\n        params: _WebSocketParams,\n    ) -> None:\n        WebSocketProtocol.__init__(self, handler)\n        self.mask_outgoing = mask_outgoing\n        self.params = params\n        self._final_frame = False\n        self._frame_opcode = None\n        self._masked_frame = None\n        self._frame_mask = None  # type: Optional[bytes]\n        self._frame_length = None\n        self._fragmented_message_buffer = None  # type: Optional[bytearray]\n        self._fragmented_message_opcode = None\n        self._waiting = None  # type: object\n        self._compression_options = params.compression_options\n        self._decompressor = None  # type: Optional[_PerMessageDeflateDecompressor]\n        self._compressor = None  # type: Optional[_PerMessageDeflateCompressor]\n        self._frame_compressed = None  # type: Optional[bool]\n        # The total uncompressed size of all messages received or sent.\n        # Unicode messages are encoded to utf8.\n        # Only for testing; subject to change.\n        self._message_bytes_in = 0\n        self._message_bytes_out = 0\n        # The total size of all packets received or sent.  Includes\n        # the effect of compression, frame overhead, and control frames.\n        self._wire_bytes_in = 0\n        self._wire_bytes_out = 0\n        self._received_pong = False  # type: bool\n        self.close_code = None  # type: Optional[int]\n        self.close_reason = None  # type: Optional[str]\n        self._ping_coroutine = None  # type: Optional[asyncio.Task]",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 33,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "accept_connection",
      "sourceCode": "async def accept_connection(self, handler: WebSocketHandler) -> None:\n        try:\n            self._handle_websocket_headers(handler)\n        except ValueError:\n            handler.set_status(400)\n            log_msg = \"Missing/Invalid WebSocket headers\"\n            handler.finish(log_msg)\n            gen_log.debug(log_msg)\n            return\n\n        try:\n            await self._accept_connection(handler)\n        except asyncio.CancelledError:\n            self._abort()\n            return\n        except ValueError:\n            gen_log.debug(\"Malformed WebSocket request received\", exc_info=True)\n            self._abort()\n            return",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 18,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "_accept_connection",
      "sourceCode": "async def _accept_connection(self, handler: WebSocketHandler) -> None:\n        subprotocol_header = handler.request.headers.get(\"Sec-WebSocket-Protocol\")\n        if subprotocol_header:\n            subprotocols = [s.strip() for s in subprotocol_header.split(\",\")]\n        else:\n            subprotocols = []\n        self.selected_subprotocol = handler.select_subprotocol(subprotocols)\n        if self.selected_subprotocol:\n            assert self.selected_subprotocol in subprotocols\n            handler.set_header(\"Sec-WebSocket-Protocol\", self.selected_subprotocol)\n\n        extensions = self._parse_extensions_header(handler.request.headers)\n        for ext in extensions:\n            if ext[0] == \"permessage-deflate\" and self._compression_options is not None:\n                # TODO: negotiate parameters if compression_options\n                # specifies limits.\n                self._create_compressors(\"server\", ext[1], self._compression_options)\n                if (\n                    \"client_max_window_bits\" in ext[1]\n                    and ext[1][\"client_max_window_bits\"] is None\n                ):\n                    # Don't echo an offered client_max_window_bits\n                    # parameter with no value.\n                    del ext[1][\"client_max_window_bits\"]\n                handler.set_header(\n                    \"Sec-WebSocket-Extensions\",\n                    httputil._encode_header(\"permessage-deflate\", ext[1]),\n                )\n                break\n\n        handler.clear_header(\"Content-Type\")\n        handler.set_status(101)\n        handler.set_header(\"Upgrade\", \"websocket\")\n        handler.set_header(\"Connection\", \"Upgrade\")\n        handler.set_header(\"Sec-WebSocket-Accept\", self._challenge_response(handler))\n        handler.finish()\n\n        self.stream = handler._detach_stream()\n\n        self.start_pinging()\n        try:\n            open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n            if open_result is not None:\n                await open_result\n        except Exception:\n            handler.log_exception(*sys.exc_info())\n            self._abort()\n            return\n\n        await self._receive_frame_loop()",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 49,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "_process_server_headers",
      "sourceCode": "def _process_server_headers(\n        self, key: Union[str, bytes], headers: httputil.HTTPHeaders\n    ) -> None:\n        \"\"\"Process the headers sent by the server to this client connection.\n\n        'key' is the websocket handshake challenge/response key.\n        \"\"\"\n        assert headers[\"Upgrade\"].lower() == \"websocket\"\n        assert headers[\"Connection\"].lower() == \"upgrade\"\n        accept = self.compute_accept_value(key)\n        assert headers[\"Sec-Websocket-Accept\"] == accept\n\n        extensions = self._parse_extensions_header(headers)\n        for ext in extensions:\n            if ext[0] == \"permessage-deflate\" and self._compression_options is not None:\n                self._create_compressors(\"client\", ext[1])\n            else:\n                raise ValueError(\"unsupported extension %r\", ext)\n\n        self.selected_subprotocol = headers.get(\"Sec-WebSocket-Protocol\", None)",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 19,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "_get_compressor_options",
      "sourceCode": "def _get_compressor_options(\n        self,\n        side: str,\n        agreed_parameters: Dict[str, Any],\n        compression_options: Optional[Dict[str, Any]] = None,\n    ) -> Dict[str, Any]:\n        \"\"\"Converts a websocket agreed_parameters set to keyword arguments\n        for our compressor objects.\n        \"\"\"\n        options = dict(\n            persistent=(side + \"_no_context_takeover\") not in agreed_parameters\n        )  # type: Dict[str, Any]\n        wbits_header = agreed_parameters.get(side + \"_max_window_bits\", None)\n        if wbits_header is None:\n            options[\"max_wbits\"] = zlib.MAX_WBITS\n        else:\n            options[\"max_wbits\"] = int(wbits_header)\n        options[\"compression_options\"] = compression_options\n        return options",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 18,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "_create_compressors",
      "sourceCode": "def _create_compressors(\n        self,\n        side: str,\n        agreed_parameters: Dict[str, Any],\n        compression_options: Optional[Dict[str, Any]] = None,\n    ) -> None:\n        # TODO: handle invalid parameters gracefully\n        allowed_keys = {\n            \"server_no_context_takeover\",\n            \"client_no_context_takeover\",\n            \"server_max_window_bits\",\n            \"client_max_window_bits\",\n        }\n        for key in agreed_parameters:\n            if key not in allowed_keys:\n                raise ValueError(\"unsupported compression parameter %r\" % key)\n        other_side = \"client\" if (side == \"server\") else \"server\"\n        self._compressor = _PerMessageDeflateCompressor(\n            **self._get_compressor_options(side, agreed_parameters, compression_options)\n        )\n        self._decompressor = _PerMessageDeflateDecompressor(\n            max_message_size=self.params.max_message_size,\n            **self._get_compressor_options(\n                other_side, agreed_parameters, compression_options\n            ),\n        )",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 25,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "_write_frame",
      "sourceCode": "def _write_frame(\n        self, fin: bool, opcode: int, data: bytes, flags: int = 0\n    ) -> \"Future[None]\":\n        data_len = len(data)\n        if opcode & 0x8:\n            # All control frames MUST have a payload length of 125\n            # bytes or less and MUST NOT be fragmented.\n            if not fin:\n                raise ValueError(\"control frames may not be fragmented\")\n            if data_len > 125:\n                raise ValueError(\"control frame payloads may not exceed 125 bytes\")\n        if fin:\n            finbit = self.FIN\n        else:\n            finbit = 0\n        frame = struct.pack(\"B\", finbit | opcode | flags)\n        if self.mask_outgoing:\n            mask_bit = 0x80\n        else:\n            mask_bit = 0\n        if data_len < 126:\n            frame += struct.pack(\"B\", data_len | mask_bit)\n        elif data_len <= 0xFFFF:\n            frame += struct.pack(\"!BH\", 126 | mask_bit, data_len)\n        else:\n            frame += struct.pack(\"!BQ\", 127 | mask_bit, data_len)\n        if self.mask_outgoing:\n            mask = os.urandom(4)\n            data = mask + _websocket_mask(mask, data)\n        frame += data\n        self._wire_bytes_out += len(frame)\n        return self.stream.write(frame)",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 31,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "write_message",
      "sourceCode": "def write_message(\n        self, message: Union[str, bytes, Dict[str, Any]], binary: bool = False\n    ) -> \"Future[None]\":\n        \"\"\"Sends the given message to the client of this Web Socket.\"\"\"\n        if binary:\n            opcode = 0x2\n        else:\n            opcode = 0x1\n        if isinstance(message, dict):\n            message = tornado.escape.json_encode(message)\n        message = tornado.escape.utf8(message)\n        assert isinstance(message, bytes)\n        self._message_bytes_out += len(message)\n        flags = 0\n        if self._compressor:\n            message = self._compressor.compress(message)\n            flags |= self.RSV1\n        # For historical reasons, write methods in Tornado operate in a semi-synchronous\n        # mode in which awaiting the Future they return is optional (But errors can\n        # still be raised). This requires us to go through an awkward dance here\n        # to transform the errors that may be returned while presenting the same\n        # semi-synchronous interface.\n        try:\n            fut = self._write_frame(True, opcode, message, flags=flags)\n        except StreamClosedError:\n            raise WebSocketClosedError()\n\n        async def wrapper() -> None:\n            try:\n                await fut\n            except StreamClosedError:\n                raise WebSocketClosedError()\n\n        return asyncio.ensure_future(wrapper())",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 33,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "_receive_frame",
      "sourceCode": "async def _receive_frame(self) -> None:\n        # Read the frame header.\n        data = await self._read_bytes(2)\n        header, mask_payloadlen = struct.unpack(\"BB\", data)\n        is_final_frame = header & self.FIN\n        reserved_bits = header & self.RSV_MASK\n        opcode = header & self.OPCODE_MASK\n        opcode_is_control = opcode & 0x8\n        if self._decompressor is not None and opcode != 0:\n            # Compression flag is present in the first frame's header,\n            # but we can't decompress until we have all the frames of\n            # the message.\n            self._frame_compressed = bool(reserved_bits & self.RSV1)\n            reserved_bits &= ~self.RSV1\n        if reserved_bits:\n            # client is using as-yet-undefined extensions; abort\n            self._abort()\n            return\n        is_masked = bool(mask_payloadlen & 0x80)\n        payloadlen = mask_payloadlen & 0x7F\n\n        # Parse and validate the length.\n        if opcode_is_control and payloadlen >= 126:\n            # control frames must have payload < 126\n            self._abort()\n            return\n        if payloadlen < 126:\n            self._frame_length = payloadlen\n        elif payloadlen == 126:\n            data = await self._read_bytes(2)\n            payloadlen = struct.unpack(\"!H\", data)[0]\n        elif payloadlen == 127:\n            data = await self._read_bytes(8)\n            payloadlen = struct.unpack(\"!Q\", data)[0]\n        new_len = payloadlen\n        if self._fragmented_message_buffer is not None:\n            new_len += len(self._fragmented_message_buffer)\n        if new_len > self.params.max_message_size:\n            self.close(1009, \"message too big\")\n            self._abort()\n            return\n\n        # Read the payload, unmasking if necessary.\n        if is_masked:\n            self._frame_mask = await self._read_bytes(4)\n        data = await self._read_bytes(payloadlen)\n        if is_masked:\n            assert self._frame_mask is not None\n            data = _websocket_mask(self._frame_mask, data)\n\n        # Decide what to do with this frame.\n        if opcode_is_control:\n            # control frames may be interleaved with a series of fragmented\n            # data frames, so control frames must not interact with\n            # self._fragmented_*\n            if not is_final_frame:\n                # control frames must not be fragmented\n                self._abort()\n                return\n        elif opcode == 0:  # continuation frame\n            if self._fragmented_message_buffer is None:\n                # nothing to continue\n                self._abort()\n                return\n            self._fragmented_message_buffer.extend(data)\n            if is_final_frame:\n                opcode = self._fragmented_message_opcode\n                data = bytes(self._fragmented_message_buffer)\n                self._fragmented_message_buffer = None\n        else:  # start of new data message\n            if self._fragmented_message_buffer is not None:\n                # can't start new message until the old one is finished\n                self._abort()\n                return\n            if not is_final_frame:\n                self._fragmented_message_opcode = opcode\n                self._fragmented_message_buffer = bytearray(data)\n\n        if is_final_frame:\n            handled_future = self._handle_message(opcode, data)\n            if handled_future is not None:\n                await handled_future",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 81,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "_handle_message",
      "sourceCode": "def _handle_message(self, opcode: int, data: bytes) -> \"Optional[Future[None]]\":\n        \"\"\"Execute on_message, returning its Future if it is a coroutine.\"\"\"\n        if self.client_terminated:\n            return None\n\n        if self._frame_compressed:\n            assert self._decompressor is not None\n            try:\n                data = self._decompressor.decompress(data)\n            except _DecompressTooLargeError:\n                self.close(1009, \"message too big after decompression\")\n                self._abort()\n                return None\n\n        if opcode == 0x1:\n            # UTF-8 data\n            self._message_bytes_in += len(data)\n            try:\n                decoded = data.decode(\"utf-8\")\n            except UnicodeDecodeError:\n                self._abort()\n                return None\n            return self._run_callback(self.handler.on_message, decoded)\n        elif opcode == 0x2:\n            # Binary data\n            self._message_bytes_in += len(data)\n            return self._run_callback(self.handler.on_message, data)\n        elif opcode == 0x8:\n            # Close\n            self.client_terminated = True\n            if len(data) >= 2:\n                self.close_code = struct.unpack(\">H\", data[:2])[0]\n            if len(data) > 2:\n                self.close_reason = to_unicode(data[2:])\n            # Echo the received close code, if any (RFC 6455 section 5.5.1).\n            self.close(self.close_code)\n        elif opcode == 0x9:\n            # Ping\n            try:\n                self._write_frame(True, 0xA, data)\n            except StreamClosedError:\n                self._abort()\n            self._run_callback(self.handler.on_ping, data)\n        elif opcode == 0xA:\n            # Pong\n            self._received_pong = True\n            return self._run_callback(self.handler.on_pong, data)\n        else:\n            self._abort()\n        return None",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 49,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "close",
      "sourceCode": "def close(self, code: Optional[int] = None, reason: Optional[str] = None) -> None:\n        \"\"\"Closes the WebSocket connection.\"\"\"\n        if not self.server_terminated:\n            if not self.stream.closed():\n                if code is None and reason is not None:\n                    code = 1000  # \"normal closure\" status code\n                if code is None:\n                    close_data = b\"\"\n                else:\n                    close_data = struct.pack(\">H\", code)\n                if reason is not None:\n                    close_data += utf8(reason)\n                try:\n                    self._write_frame(True, 0x8, close_data)\n                except StreamClosedError:\n                    self._abort()\n            self.server_terminated = True\n        if self.client_terminated:\n            if self._waiting is not None:\n                self.stream.io_loop.remove_timeout(self._waiting)\n                self._waiting = None\n            self.stream.close()\n        elif self._waiting is None:\n            # Give the client a few seconds to complete a clean shutdown,\n            # otherwise just close the connection.\n            self._waiting = self.stream.io_loop.add_timeout(\n                self.stream.io_loop.time() + 5, self._abort\n            )\n        if self._ping_coroutine:\n            self._ping_coroutine.cancel()\n            self._ping_coroutine = None",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 30,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "ping_timeout",
      "sourceCode": "@property\n    def ping_timeout(self) -> float:\n        timeout = self.params.ping_timeout\n        if timeout is not None:\n            if self.ping_interval and timeout > self.ping_interval:\n                de_dupe_gen_log(\n                    # Note: using de_dupe_gen_log to prevent this message from\n                    # being duplicated for each connection\n                    logging.WARNING,\n                    f\"The websocket_ping_timeout ({timeout}) cannot be longer\"\n                    f\" than the websocket_ping_interval ({self.ping_interval}).\"\n                    f\"\\nSetting websocket_ping_timeout={self.ping_interval}\",\n                )\n                return self.ping_interval\n            return timeout\n        return self.ping_interval",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 15,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "periodic_ping",
      "sourceCode": "async def periodic_ping(self) -> None:\n        \"\"\"Send a ping and wait for a pong if ping_timeout is configured.\n\n        Called periodically if the websocket_ping_interval is set and non-zero.\n        \"\"\"\n        interval = self.ping_interval\n        timeout = self.ping_timeout\n\n        await asyncio.sleep(interval)\n\n        while True:\n            # send a ping\n            self._received_pong = False\n            ping_time = IOLoop.current().time()\n            self.write_ping(b\"\")\n\n            # wait until the ping timeout\n            await asyncio.sleep(timeout)\n\n            # make sure we received a pong within the timeout\n            if timeout > 0 and not self._received_pong:\n                self.close(reason=\"ping timed out\")\n                return\n\n            # wait until the next scheduled ping\n            await asyncio.sleep(IOLoop.current().time() - ping_time + interval)",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 25,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "__init__",
      "sourceCode": "def __init__(\n        self,\n        request: httpclient.HTTPRequest,\n        on_message_callback: Optional[Callable[[Union[None, str, bytes]], None]] = None,\n        compression_options: Optional[Dict[str, Any]] = None,\n        ping_interval: Optional[float] = None,\n        ping_timeout: Optional[float] = None,\n        max_message_size: int = _default_max_message_size,\n        subprotocols: Optional[List[str]] = None,\n        resolver: Optional[Resolver] = None,\n    ) -> None:\n        self.connect_future = Future()  # type: Future[WebSocketClientConnection]\n        self.read_queue = Queue(1)  # type: Queue[Union[None, str, bytes]]\n        self.key = base64.b64encode(os.urandom(16))\n        self._on_message_callback = on_message_callback\n        self.close_code = None  # type: Optional[int]\n        self.close_reason = None  # type: Optional[str]\n        self.params = _WebSocketParams(\n            ping_interval=ping_interval,\n            ping_timeout=ping_timeout,\n            max_message_size=max_message_size,\n            compression_options=compression_options,\n        )\n\n        scheme, sep, rest = request.url.partition(\":\")\n        scheme = {\"ws\": \"http\", \"wss\": \"https\"}[scheme]\n        request.url = scheme + sep + rest\n        request.headers.update(\n            {\n                \"Upgrade\": \"websocket\",\n                \"Connection\": \"Upgrade\",\n                \"Sec-WebSocket-Key\": to_unicode(self.key),\n                \"Sec-WebSocket-Version\": \"13\",\n            }\n        )\n        if subprotocols is not None:\n            request.headers[\"Sec-WebSocket-Protocol\"] = \",\".join(subprotocols)\n        if compression_options is not None:\n            # Always offer to let the server set our max_wbits (and even though\n            # we don't offer it, we will accept a client_no_context_takeover\n            # from the server).\n            # TODO: set server parameters for deflate extension\n            # if requested in self.compression_options.\n            request.headers[\"Sec-WebSocket-Extensions\"] = (\n                \"permessage-deflate; client_max_window_bits\"\n            )\n\n        # Websocket connection is currently unable to follow redirects\n        request.follow_redirects = False\n\n        self.tcp_client = TCPClient(resolver=resolver)\n        super().__init__(\n            None,\n            request,\n            lambda: None,\n            self._on_http_response,\n            104857600,\n            self.tcp_client,\n            65536,\n            104857600,\n        )",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 60,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "close",
      "sourceCode": "def close(self, code: Optional[int] = None, reason: Optional[str] = None) -> None:\n        \"\"\"Closes the websocket connection.\n\n        ``code`` and ``reason`` are documented under\n        `WebSocketHandler.close`.\n\n        .. versionadded:: 3.2\n\n        .. versionchanged:: 4.0\n\n           Added the ``code`` and ``reason`` arguments.\n        \"\"\"\n        if self.protocol is not None:\n            self.protocol.close(code, reason)\n            self.protocol = None",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "headers_received",
      "sourceCode": "async def headers_received(\n        self,\n        start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n        headers: httputil.HTTPHeaders,\n    ) -> None:\n        assert isinstance(start_line, httputil.ResponseStartLine)\n        if start_line.code != 101:\n            await super().headers_received(start_line, headers)\n            return\n\n        if self._timeout is not None:\n            self.io_loop.remove_timeout(self._timeout)\n            self._timeout = None\n\n        self.headers = headers\n        self.protocol = self.get_websocket_protocol()\n        self.protocol._process_server_headers(self.key, self.headers)\n        self.protocol.stream = self.connection.detach()\n\n        IOLoop.current().add_callback(self.protocol._receive_frame_loop)\n        self.protocol.start_pinging()\n\n        # Once we've taken over the connection, clear the final callback\n        # we set on the http request.  This deactivates the error handling\n        # in simple_httpclient that would otherwise interfere with our\n        # ability to see exceptions.\n        self.final_callback = None  # type: ignore\n\n        future_set_result_unless_cancelled(self.connect_future, self)",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 28,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "write_message",
      "sourceCode": "def write_message(\n        self, message: Union[str, bytes, Dict[str, Any]], binary: bool = False\n    ) -> \"Future[None]\":\n        \"\"\"Sends a message to the WebSocket server.\n\n        If the stream is closed, raises `WebSocketClosedError`.\n        Returns a `.Future` which can be used for flow control.\n\n        .. versionchanged:: 5.0\n           Exception raised on a closed stream changed from `.StreamClosedError`\n           to `WebSocketClosedError`.\n        \"\"\"\n        if self.protocol is None:\n            raise WebSocketClosedError(\"Client connection has been closed\")\n        return self.protocol.write_message(message, binary=binary)",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 14,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "read_message",
      "sourceCode": "def read_message(\n        self,\n        callback: Optional[Callable[[\"Future[Union[None, str, bytes]]\"], None]] = None,\n    ) -> Awaitable[Union[None, str, bytes]]:\n        \"\"\"Reads a message from the WebSocket server.\n\n        If on_message_callback was specified at WebSocket\n        initialization, this function will never return messages\n\n        Returns a future whose result is the message, or None\n        if the connection is closed.  If a callback argument\n        is given it will be called with the future when it is\n        ready.\n        \"\"\"\n\n        awaitable = self.read_queue.get()\n        if callback is not None:\n            self.io_loop.add_future(asyncio.ensure_future(awaitable), callback)\n        return awaitable",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 18,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "ping",
      "sourceCode": "def ping(self, data: bytes = b\"\") -> None:\n        \"\"\"Send ping frame to the remote end.\n\n        The data argument allows a small amount of data (up to 125\n        bytes) to be sent as a part of the ping message. Note that not\n        all websocket implementations expose this data to\n        applications.\n\n        Consider using the ``ping_interval`` argument to\n        `websocket_connect` instead of sending pings manually.\n\n        .. versionadded:: 5.1\n\n        \"\"\"\n        data = utf8(data)\n        if self.protocol is None:\n            raise WebSocketClosedError()\n        self.protocol.write_ping(data)",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 17,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "websocket_connect",
      "sourceCode": "def websocket_connect(\n    url: Union[str, httpclient.HTTPRequest],\n    callback: Optional[Callable[[\"Future[WebSocketClientConnection]\"], None]] = None,\n    connect_timeout: Optional[float] = None,\n    on_message_callback: Optional[Callable[[Union[None, str, bytes]], None]] = None,\n    compression_options: Optional[Dict[str, Any]] = None,\n    ping_interval: Optional[float] = None,\n    ping_timeout: Optional[float] = None,\n    max_message_size: int = _default_max_message_size,\n    subprotocols: Optional[List[str]] = None,\n    resolver: Optional[Resolver] = None,\n) -> \"Awaitable[WebSocketClientConnection]\":\n    \"\"\"Client-side websocket support.\n\n    Takes a url and returns a Future whose result is a\n    `WebSocketClientConnection`.\n\n    ``compression_options`` is interpreted in the same way as the\n    return value of `.WebSocketHandler.get_compression_options`.\n\n    The connection supports two styles of operation. In the coroutine\n    style, the application typically calls\n    `~.WebSocketClientConnection.read_message` in a loop::\n\n        conn = yield websocket_connect(url)\n        while True:\n            msg = yield conn.read_message()\n            if msg is None: break\n            # Do something with msg\n\n    In the callback style, pass an ``on_message_callback`` to\n    ``websocket_connect``. In both styles, a message of ``None``\n    indicates that the connection has been closed.\n\n    ``subprotocols`` may be a list of strings specifying proposed\n    subprotocols. The selected protocol may be found on the\n    ``selected_subprotocol`` attribute of the connection object\n    when the connection is complete.\n\n    .. versionchanged:: 3.2\n       Also accepts ``HTTPRequest`` objects in place of urls.\n\n    .. versionchanged:: 4.1\n       Added ``compression_options`` and ``on_message_callback``.\n\n    .. versionchanged:: 4.5\n       Added the ``ping_interval``, ``ping_timeout``, and ``max_message_size``\n       arguments, which have the same meaning as in `WebSocketHandler`.\n\n    .. versionchanged:: 5.0\n       The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n\n    .. versionchanged:: 5.1\n       Added the ``subprotocols`` argument.\n\n    .. versionchanged:: 6.3\n       Added the ``resolver`` argument.\n\n    .. deprecated:: 6.5\n       The ``callback`` argument is deprecated and will be removed in Tornado 7.0.\n       Use the returned Future instead. Note that ``on_message_callback`` is not\n       deprecated and may still be used.\n    \"\"\"\n    if isinstance(url, httpclient.HTTPRequest):\n        assert connect_timeout is None\n        request = url\n        # Copy and convert the headers dict/object (see comments in\n        # AsyncHTTPClient.fetch)\n        request.headers = httputil.HTTPHeaders(request.headers)\n    else:\n        request = httpclient.HTTPRequest(url, connect_timeout=connect_timeout)\n    request = cast(\n        httpclient.HTTPRequest,\n        httpclient._RequestProxy(request, httpclient.HTTPRequest._DEFAULTS),\n    )\n    conn = WebSocketClientConnection(\n        request,\n        on_message_callback=on_message_callback,\n        compression_options=compression_options,\n        ping_interval=ping_interval,\n        ping_timeout=ping_timeout,\n        max_message_size=max_message_size,\n        subprotocols=subprotocols,\n        resolver=resolver,\n    )\n    if callback is not None:\n        warnings.warn(\n            \"The callback argument to websocket_connect is deprecated. \"\n            \"Use the returned Future instead.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        IOLoop.current().add_future(conn.connect_future, callback)\n    return conn.connect_future",
      "importString": "import abc\nimport base64\nimport functools\nimport hashlib\nimport logging\nimport os\nimport sys\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport warnings\nimport zlib\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import gen_log, app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import (\nTYPE_CHECKING\ncast\nAny\nOptional\nDict\nUnion\nList\nAwaitable\nCallable\nTuple\nType\n)\nfrom types import TracebackType",
      "lineNum": 93,
      "relativeDocumentPath": "tornado/websocket.py"
    },
    {
      "symbolName": "handle_request",
      "sourceCode": "async def handle_request(self, request: httputil.HTTPServerRequest) -> None:\n        data = {}  # type: Dict[str, Any]\n        response = []  # type: List[bytes]\n\n        def start_response(\n            status: str,\n            headers: List[Tuple[str, str]],\n            exc_info: Optional[\n                Tuple[\n                    \"Optional[Type[BaseException]]\",\n                    Optional[BaseException],\n                    Optional[TracebackType],\n                ]\n            ] = None,\n        ) -> Callable[[bytes], Any]:\n            data[\"status\"] = status\n            data[\"headers\"] = headers\n            return response.append\n\n        loop = IOLoop.current()\n        app_response = await loop.run_in_executor(\n            self.executor,\n            self.wsgi_application,\n            self.environ(request),\n            start_response,\n        )\n        try:\n            app_response_iter = iter(app_response)\n\n            def next_chunk() -> Optional[bytes]:\n                try:\n                    return next(app_response_iter)\n                except StopIteration:\n                    # StopIteration is special and is not allowed to pass through\n                    # coroutines normally.\n                    return None\n\n            while True:\n                chunk = await loop.run_in_executor(self.executor, next_chunk)\n                if chunk is None:\n                    break\n                response.append(chunk)\n        finally:\n            if hasattr(app_response, \"close\"):\n                app_response.close()  # type: ignore\n        body = b\"\".join(response)\n        if not data:\n            raise Exception(\"WSGI app did not call start_response\")\n\n        status_code_str, reason = data[\"status\"].split(\" \", 1)\n        status_code = int(status_code_str)\n        headers = data[\"headers\"]  # type: List[Tuple[str, str]]\n        header_set = {k.lower() for (k, v) in headers}\n        body = escape.utf8(body)\n        if status_code != 304:\n            if \"content-length\" not in header_set:\n                headers.append((\"Content-Length\", str(len(body))))\n            if \"content-type\" not in header_set:\n                headers.append((\"Content-Type\", \"text/html; charset=UTF-8\"))\n        if \"server\" not in header_set:\n            headers.append((\"Server\", \"TornadoServer/%s\" % tornado.version))\n\n        start_line = httputil.ResponseStartLine(\"HTTP/1.1\", status_code, reason)\n        header_obj = httputil.HTTPHeaders()\n        for key, value in headers:\n            header_obj.add(key, value)\n        assert request.connection is not None\n        request.connection.write_headers(start_line, header_obj, chunk=body)\n        request.connection.finish()\n        self._log(status_code, request)",
      "importString": "import concurrent.futures\nfrom io import BytesIO\nimport tornado\nimport sys\n\nfrom tornado.concurrent import dummy_executor\nfrom tornado import escape\nfrom tornado import httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import access_log\n\nfrom typing import List, Tuple, Optional, Callable, Any, Dict\nfrom types import TracebackType\nimport typing",
      "lineNum": 69,
      "relativeDocumentPath": "tornado/wsgi.py"
    },
    {
      "symbolName": "start_response",
      "sourceCode": "def start_response(\n            status: str,\n            headers: List[Tuple[str, str]],\n            exc_info: Optional[\n                Tuple[\n                    \"Optional[Type[BaseException]]\",\n                    Optional[BaseException],\n                    Optional[TracebackType],\n                ]\n            ] = None,\n        ) -> Callable[[bytes], Any]:\n            data[\"status\"] = status\n            data[\"headers\"] = headers\n            return response.append",
      "importString": "import concurrent.futures\nfrom io import BytesIO\nimport tornado\nimport sys\n\nfrom tornado.concurrent import dummy_executor\nfrom tornado import escape\nfrom tornado import httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import access_log\n\nfrom typing import List, Tuple, Optional, Callable, Any, Dict\nfrom types import TracebackType\nimport typing",
      "lineNum": 13,
      "relativeDocumentPath": "tornado/wsgi.py"
    },
    {
      "symbolName": "environ",
      "sourceCode": "def environ(self, request: httputil.HTTPServerRequest) -> Dict[str, Any]:\n        \"\"\"Converts a `tornado.httputil.HTTPServerRequest` to a WSGI environment.\n\n        .. versionchanged:: 6.3\n           No longer a static method.\n        \"\"\"\n        hostport = request.host.split(\":\")\n        if len(hostport) == 2:\n            host = hostport[0]\n            port = int(hostport[1])\n        else:\n            host = request.host\n            port = 443 if request.protocol == \"https\" else 80\n        environ = {\n            \"REQUEST_METHOD\": request.method,\n            \"SCRIPT_NAME\": \"\",\n            \"PATH_INFO\": to_wsgi_str(\n                escape.url_unescape(request.path, encoding=None, plus=False)\n            ),\n            \"QUERY_STRING\": request.query,\n            \"REMOTE_ADDR\": request.remote_ip,\n            \"SERVER_NAME\": host,\n            \"SERVER_PORT\": str(port),\n            \"SERVER_PROTOCOL\": request.version,\n            \"wsgi.version\": (1, 0),\n            \"wsgi.url_scheme\": request.protocol,\n            \"wsgi.input\": BytesIO(escape.utf8(request.body)),\n            \"wsgi.errors\": sys.stderr,\n            \"wsgi.multithread\": self.executor is not dummy_executor,\n            \"wsgi.multiprocess\": True,\n            \"wsgi.run_once\": False,\n        }\n        if \"Content-Type\" in request.headers:\n            environ[\"CONTENT_TYPE\"] = request.headers.pop(\"Content-Type\")\n        if \"Content-Length\" in request.headers:\n            environ[\"CONTENT_LENGTH\"] = request.headers.pop(\"Content-Length\")\n        for key, value in request.headers.items():\n            environ[\"HTTP_\" + key.replace(\"-\", \"_\").upper()] = value\n        return environ",
      "importString": "import concurrent.futures\nfrom io import BytesIO\nimport tornado\nimport sys\n\nfrom tornado.concurrent import dummy_executor\nfrom tornado import escape\nfrom tornado import httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import access_log\n\nfrom typing import List, Tuple, Optional, Callable, Any, Dict\nfrom types import TracebackType\nimport typing",
      "lineNum": 38,
      "relativeDocumentPath": "tornado/wsgi.py"
    },
    {
      "symbolName": "_log",
      "sourceCode": "def _log(self, status_code: int, request: httputil.HTTPServerRequest) -> None:\n        if status_code < 400:\n            log_method = access_log.info\n        elif status_code < 500:\n            log_method = access_log.warning\n        else:\n            log_method = access_log.error\n        request_time = 1000.0 * request.request_time()\n        assert request.method is not None\n        assert request.uri is not None\n        summary = (\n            request.method  # type: ignore[operator]\n            + \" \"\n            + request.uri\n            + \" (\"\n            + request.remote_ip\n            + \")\"\n        )\n        log_method(\"%d %s %.2fms\", status_code, summary, request_time)",
      "importString": "import concurrent.futures\nfrom io import BytesIO\nimport tornado\nimport sys\n\nfrom tornado.concurrent import dummy_executor\nfrom tornado import escape\nfrom tornado import httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.log import access_log\n\nfrom typing import List, Tuple, Optional, Callable, Any, Dict\nfrom types import TracebackType\nimport typing",
      "lineNum": 18,
      "relativeDocumentPath": "tornado/wsgi.py"
    }
  ]